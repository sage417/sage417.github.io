{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"about","text":"to be continue…","link":"/about/index.html"},{"title":"404","text":"","link":"/404/index.html"}],"posts":[{"title":"AbstractQueuedSynchronizer解析","text":"AbstractQueuedSynchronizer 数据结构123456789101112131415161718 /** * Head of the wait queue , lazily initialized . Except for * initialization , it is modified only via method setHead . Note : * If head exists , its waitStatus is guaranteed not to be * CANCELLED . */ private transient volatile Node head; /** * Tail of the wait queue , lazily initialized . Modified only via * method enq to add new wait node . */ private transient volatile Node tail; /** * The synchronization state . */ private volatile int state; 稍微注意下在线程争用锁是才会初始化链表 AbstractQueuedSynchronizer.Node 数据结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * Status field , taking on only the values : * SIGNAL : The successor of this node is ( or will soon be ) * blocked ( via park ), so the current node must * unpark its successor when it releases or * cancels . To avoid races , acquire methods must * first indicate they need a signal , * then retry the atomic acquire , and then , * on failure , block . * CANCELLED : This node is cancelled due to timeout or interrupt . * Nodes never leave this state . In particular , * a thread with cancelled node never again blocks . * CONDITION : This node is currently on a condition queue . * It will not be used as a sync queue node * until transferred , at which time the status * will be set to 0. ( Use of this value here has * nothing to do with the other uses of the * field , but simplifies mechanics .) * PROPAGATE : A releaseShared should be propagated to other * nodes . This is set ( for head node only ) in * doReleaseShared to ensure propagation * continues , even if other operations have * since intervened . * 0: None of the above * * The values are arranged numerically to simplify use . * Non - negative values mean that a node doesn ' t need to * signal . So , most code doesn ' t need to check for particular * values , just for sign . * * The field is initialized to 0 for normal sync nodes , and * CONDITION for condition nodes . It is modified using CAS * ( or when possible , unconditional volatile writes ). */ volatile int waitStatus; /** * Link to predecessor node that current node / thread relies on * for checking waitStatus . Assigned during enqueuing , and nulled * out ( for sake of GC ) only upon dequeuing . Also , upon * cancellation of a predecessor , we short - circuit while * finding a non - cancelled one , which will always exist * because the head node is never cancelled : A node becomes * head only as a result of successful acquire . A * cancelled thread never succeeds in acquiring , and a thread only * cancels itself , not any other node . */ volatile Node prev; /** * Link to the successor node that the current node / thread * unparks upon release . Assigned during enqueuing , adjusted * when bypassing cancelled predecessors , and nulled out ( for * sake of GC ) when dequeued . The enq operation does not * assign next field of a predecessor until after attachment , * so seeing a null next field does not necessarily mean that * node is at end of queue . However , if a next field appears * to be null , we can scan prev ' s from the tail to * double - check . The next field of cancelled nodes is set to * point to the node itself instead of null , to make life * easier for isOnSyncQueue . */ volatile Node next; /** * The thread that enqueued this node . Initialized on * construction and nulled out after use . */ volatile Thread thread; /** * Link to next node waiting on condition , or the special * value SHARED . Because condition queues are accessed only * when holding in exclusive mode , we just need a simple * linked queue to hold nodes while they are waiting on * conditions . They are then transferred to the queue to * re - acquire . And because conditions can only be exclusive , * we save a field by using special value to indicate shared * mode . */ Node nextWaiter; AbstractQueuedSynchronizer** 的数据结构（盗用的图） AbstractQueuedSynchronizer 做了什么 ?内部维护state和CLH队列，负责在资源争用时线程入队，资源释放时唤醒队列中线程。 而实现类只需要实现 什么条件获取资源成功 和 什么条件释放资源 成功就可以了 所以，最简单的CountDownLatch使用AbstractQueuedSynchronizer实现非常简单： 申明AbstractQueuedSynchronizer的state数量（比如十个） await方法尝试获取资源，如果state&gt;0表示获取失败（ **什么条件获取资源成功** ，CountDownLatch实现），获取失败线程休眠（AbstractQueuedSynchronizer负责） countDown方法state-1，如果state==0表示资源释放成功( **什么条件释放资源成功** ，CountDownLatch实现)，唤醒队列中所有线程（AbstractQueuedSynchronizer负责） AbstractQueuedSynchronizer 怎么做的?顺着ReentrantLock lock、unlock看一遍我们就大致总结出AbstractQueuedSynchronizer工作原理了 先简单介绍下ReentrantLock特性：可重入，中断，有超时机制。 ReentrantLock lock() 流程 ( 再盗图 ) 黄色表示ReentrantLock实现，绿色表示AbstractQueuedSynchronizer内部实现 lock方法入口 直接调用 AbstractQueuedSynchronizer.acquire方法 tryAcquire addWaiter acquireQueued AbstractQueuedSynchronizer.acquire12345**public** final void acquire ( int arg) { **if** (! tryAcquire (arg) &amp;&amp; acquireQueued ( addWaiter ( Node . EXCLUSIVE ), arg)) selfInterrupt (); } 获取的锁的逻辑：直接获取成功则返回，如果没有获取成功入队休眠（对就是这么简单） 下面我们仔细一个一个方法看 ReentrantLock.tryAcquire我这里贴的时非公平的所获取，公平和不公平的区别在于公平锁老老实实的会进入队列排队，非公平锁会先检查资源是否可用，如果可用不管队列中的情况直接尝试获取锁。 123456789101112131415161718final boolean nonfairTryAcquire ( int acquires) { final Thread current = Thread . currentThread (); int c = getState (); if (c == 0 ) { if ( compareAndSetState ( 0 , acquires)) { setExclusiveOwnerThread (current); return true ; } } else if (current == getExclusiveOwnerThread ()) { int nextc = c + acquires; if (nextc &lt; 0 ) // overflow throw new Error ( &quot;Maximum lock count exceeded&quot; ); setState (nextc); return true ; } return false ; } ReentrantLock.tryAcquire读取到state==0时尝试占用锁，并保证同一线程可以重复占用。其他情况下获取资源失败。如果获取成功就没啥事了，不过关键不就是锁争用的时候是如何处理的吗？ AbstractQueuedSynchronizer.addWaiter(Node.EXCLUSIVE)12345678910111213141516private Node addWaiter ( Node mode) { Node node = new Node (mode); for (;;) { Node oldTail = tail; if (oldTail != null ) { node. setPrevRelaxed (oldTail); if ( compareAndSetTail (oldTail, node)) { oldTail. next = node; return node; } } else { initializeSyncQueue (); } } } 一旦锁争用，一定会初始化队列（因为排队的线程需要前驱节点唤醒，所以要初始化一个前驱节点），之后自旋成为队列尾节点。 简单来说就是获取不到锁就放进队列里维护起来，等锁释放的时候再用。 这里还有一个 很具有参考性的小细节 ：先设置新节点的前驱结点，自旋成为尾节点后设置前驱的后驱 AbstractQueuedSynchronizer.acquireQueued1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253final boolean acquireQueued ( final Node node, int arg) { boolean interrupted = false ; try { for (;;) { final Node p = node. predecessor (); if (p == head &amp;&amp; tryAcquire (arg)) { setHead (node); p. next = null ; // help GC return interrupted; } if ( shouldParkAfterFailedAcquire (p, node)) interrupted |= parkAndCheckInterrupt (); } } catch ( Throwable t) { cancelAcquire (node); if (interrupted) selfInterrupt (); throw t; } } private static boolean shouldParkAfterFailedAcquire ( Node pred, Node node) { int ws = pred. waitStatus ; if (ws == Node . SIGNAL ) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true ; if (ws &gt; 0 ) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node. prev = pred = pred. prev ; } while (pred. waitStatus &gt; 0 ); pred. next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ pred. compareAndSetWaitStatus (ws, Node . SIGNAL ); } return false ; } private final boolean parkAndCheckInterrupt () { LockSupport . park ( this ); return Thread . interrupted (); } 前面只是维护下链表数据结构，这里负责找到合适的唤醒前驱，然后让线程休眠。 这里主要是一个循环过程： 检查是否能获取到锁，获取到则返回 失败则寻找前面最近的未放弃争用的前驱，把前驱的waitStatus设置为-1，并把放弃争用的节点抛弃 检查是否能休眠 使用Usafe.park休眠（不是wait） ReentrantLock lock 总结 ReentrantLock unlock()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public final boolean release ( int arg) { if ( tryRelease (arg)) { Node h = head; if (h != null &amp;&amp; h. waitStatus != 0 ) unparkSuccessor (h); return true ; } return false ; } protected final boolean tryRelease ( int releases) { int c = getState () - releases; if ( Thread . currentThread () != getExclusiveOwnerThread ()) throw new IllegalMonitorStateException (); boolean free = false ; if (c == 0 ) { free = true ; setExclusiveOwnerThread ( null ); } setState (c); return free; } private void unparkSuccessor ( Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node. waitStatus ; if (ws &lt; 0 ) node. compareAndSetWaitStatus (ws, 0 ); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node. next ; if (s == null || s. waitStatus &gt; 0 ) { s = null ; for ( Node p = tail; p != node &amp;&amp; p != null ; p = p. prev ) if (p. waitStatus &lt;= 0 ) s = p; } if (s != null ) LockSupport . unpark (s. thread ); } unlock的代码特别简单： 每unlock一次state-1 state == 0 时资源成功释放 如果释放成功，唤醒第二个节点 如果第二个节点没引用或者放弃争用，从队尾开始寻找可以唤醒的线程","link":"/2018/07/02/2018/2018-07-02-AbstractQueuedSynchronizer%E8%A7%A3%E6%9E%90/"},{"title":"2018下半年书单","text":"经济金融类： 《斯坦福极简经济学》分微观和宏观经济学 没有教科书式的介绍 比较好读，推荐 《随机漫步的傻瓜》 经验之谈 观点可以接受 《买晾衣杆的小贩为何不会倒》 贴近生活 过于简单 不推荐 《富爸爸 穷爸爸》小白入门首选 推荐 《小岛经济学》 深入浅出 最后映射中国和美国关系 后面有点看不懂 推荐 小说类： 《解忧杂货店》 个人感觉一般 后半部分剧情我都猜到了 《人间失格》 遭受到了社会的毒打 很现实 有点致郁 心里承受能力低的不推荐 《三体》 第一部可以的，后面一部不如一部 但是比起其他网上大众喜欢的爽文好多了 技术类： 《java编程的逻辑》 温故而知新，基础好的不用看了 小白推荐 《kafka权威指南》正在看 但是真的写的不错 推荐 《mybatis从入门到精通》 一般般，只有入门吧 《netty权威指南》 一般般 《redis设计与实现》 真设计与实现 推荐 《深入理解java虚拟机》多读几遍也不为过 推荐 《SpringBoot实战》 读的比较早没影响了 不推荐 《算法图解》 程序=数据结构+算法 小白推荐（我就是小白） 心理类： 《乌合之众》 人在小范围为私利行动 在民族范畴会抛开私利做出些过于崇高或粗鲁的行为 推荐 《原生家庭》 一个人受童年家庭的影响是最大的，这本书能看懂是一回事，能做好是另一回事","link":"/2018/09/04/2018/2018-09-04-2018%E4%B8%8B%E5%8D%8A%E5%B9%B4%E4%B9%A6%E5%8D%95/"},{"title":"《重构-改善既有代码设计》读书笔记","text":"1.1 一个简单的例子一个计算顾客租赁影片费用的程序，能容易写成面条式的代码（流水账）：顾客类调用影片类和租赁时长计算费用 对机器来言只要能运行正确没有好代码和坏代码之分，但是对（维护的）人来说很难找到修改点，容易引入bug 1.2重构前先写测试保证重构结果利用单元测试保证重构正确性 1.3以微小的步伐修改程序，保证问题快速发现解决不要为修改变量名感到羞耻，只有写出人能理解的代码才是好程序员 重构完可能 性能变差，但同时会带来更多的机会来优化 1.4干货－用多态代替switchswitch需要关心具体条件，多态具有switch不具备的优势：不需要关心具体类型 2.1重构的定义重构：不改变运行结果下 提高理解性 降低修改成本 2.2重构的原因 代码结构的流失是累积性的，越难看懂代码设计意图，越难保护其设计 消除重复代码，方便修改 我们编写代码时很容易忘记读者的感受，造成他人时间的浪费 重构时犯错可以加深对代码意图的理解，可以帮助发现bug 好的结构设计是加速开发的根本 2.3重构的时机 添加功能时重构，在修改过程中把结构理清，也可以更简单的添加功能 修复错误时重构 复审代码时重构 2.4 重构的价值程序有两面价值，今天可以为你做什么和明天可以为你做什么为了满足明天的需要，你会遇到： 难以阅读，逻辑重复 添加新功能许修改以前代码 复杂的条件逻辑等代码 而你希望看到的是： 容易阅读，所有逻辑在唯一指定地点， 新的修改不会危及现有行为 尽可能简单表达逻辑条件 重构就是把程序转变为这些特征的工具 2.5如何告诉（对付）经理很多经理都是进度驱动，所以更加需要重构带来的好处，所以不要告诉他们 他们不会理解的 2.5.1引入间接层与重构的关系间接层优点： 允许逻辑共享 增加解释意图和实现的机会－多了类名和函数名 隔离变化 多态封装条件逻辑 2.5.2何时不应该重构 软件根本不工作 最后期限已近 未完成的重构可以称之为债务，迟早要还 2.5.3重构与预先设计的关系重构可以节约不必要的时间精力花在预先设计上，让软件设计向简化发展 3代码的坏味道 重复代码 过长函数 过大类，过长参数 修改一处程序的原因过多/一个原因修改过多的程序 数据依赖过多 重复的字段和参数 总是放在一起的字段 switch语句 平行继承关系 不是所有分支下都需要的临时变量 过度耦合调用链 不必要的委托 失血数据类 频繁重写父类方法 过多注释 4~12具体如何做自己看书吧","link":"/2018/09/08/2018/2018-09-08-%E3%80%8A%E9%87%8D%E6%9E%84-%E6%94%B9%E5%96%84%E6%97%A2%E6%9C%89%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"title":"根据权限查询时避免角色切换的一种思路","text":"1. 问题背景权限系统现状UC权限系统基于角色访问控制技术RBAC（Role Based Access Control） 。具体来说，就是赋予用户某个角色，角色给与角色对应的权限能访问及操作不同范围的资源。 什么是数据权限代表一个角色对应某个权限所能操作的数据范围，比如gitlab组管理员能看到组下的所有项目代码，我们可以这样配置： 创建组管理员 分配给组管理员查看项目代码的权限 查看项目代码权限设置约束条件，约束为自己组下的项目 实际产生遇到的问题对绝大多数简单的系统来说一个用户对应一个系统只会有一个角色，一个角色只有一个数据权限范围（即使有多个，也可以合并成一个）。但是随着产品的功能迭代，用户的变更和系统设计的原因，总有一些特殊且重要的用户在同一个系统中拥有多个角色。在多角色和数据权限的组合下，一个用户可以拥有复数的数据权限范围。 考虑到实现复杂性，大多数系统选择使用角色切换的手段简化系统实现，同时对用户暴露出了他们不熟悉的角色这一概念，造成这些用户在系统使用中的各种不便。 本文重点讨论在避免角色切换的前提下，进行多角色数据范围查询的一种思路。 具体需要解决的需求我们的数据报表后台，不同的角色拥有不同的数据查看范围（不同角色所能看到的员工数据字段也各不相同），例如： 薪酬管理员：查看非高职级员工数据 高级薪酬管理员： 查看高职级员工数据 长期激励管理员：查看有长期激励员工数据 等等 简单来说，拥有长期激励管理员和高级薪酬管理员的用户能否直接看到高职级员工数据和长期激励员工数据？至少在直觉上是可行的。 2.多角色数据范围查询直觉的做法单角色单数据范围可以使用一句sql查询出结果，那多角色多数据范围是不是使用多句sql查询出结果合并就可以了？ 深入思考 多角色数据范围对行的影响 查询条件合并还是结果合并？ —-结果合并 如何排序？ —–外部排序，或先内部排序,limit,再外部排序 有重复数据怎么办？ —-使用groupby去重 查询性能有影响吗？—-有 具体体现： 1234567select * from ((select id, sortvalue from table_1 where t_name = 'a' order by sortvalue desc limit 20) -- 先内部排序,limitunion all -- 结果合并(select id, sortvalue from table_1 where t_name = 'b' order by sortvalue desc limit 20) -- 先内部排序,limitorder by sortvalue desc -- 外部排序) a group by id -- 使用groupby去重limit 10, 10 深入思考 多角色数据范围对列的影响 薪酬管理员： 查看员工薪酬字段 长期激励管理员：查看员工长期激励字段 如何解决？方法有很多！ 综合思考，给出一种解决方案123graph LR A(查询行及角色信息) --&gt; B(根据角色查询对应列字段) B --&gt; C(结果) 步骤： 查询多角色数据范围下的数据，附带角色信息 1234567select id, GROUP_CONCAT(a.role) as roles from ((select id, 'role_a' as role from table_1 where sortvalue &gt; 10 order by `sortvalue` desc limit 2)union all(select id, 'role_b' as role from table_1 where sortvalue &gt; 20 order by `sortvalue` desc limit 2) order by `sortvalue` desc ) a group by idlimit 0, 2 结果： id roles 1 薪酬管理员 5 薪酬管理员，长期激励管理员 根据每一行不同的角色，查询出可见的字段，例如id=1的行只能查看ROLE_B对应字段，而id=5的行可以看到ROLE_A,ROLE_B对应的两个角色的字段 3.总结和延伸多角色数据范围写操作？遍历角色直到找到满足条件的权限即可。 收获自己不行动，等于等着被别人安排哈哈 还有疑问？自己想。还可以点这里","link":"/2018/11/06/2018/2018-11-06-%E6%A0%B9%E6%8D%AE%E6%9D%83%E9%99%90%E6%9F%A5%E8%AF%A2%E6%97%B6%E9%81%BF%E5%85%8D%E8%A7%92%E8%89%B2%E5%88%87%E6%8D%A2%E7%9A%84%E4%B8%80%E7%A7%8D%E6%80%9D%E8%B7%AF/"},{"title":"再谈最长公共子串","text":"序言这次遇到贝壳花名的需求，需要使用最长公共子串对花名做校验。这种算法在面试题中算是必会题，各种四层循环，三层循环，两层循环的代码在我脑中闪过，但是今天就是要带你实现不一样的最长公共子串！ 教科书式实现使用动态规划，两层循环，使用二维数组存储状态，时间复杂度O(n^2^)，空间复杂度O(n^2^)或O(2n) 一张图解释原理： 12345678910111213141516 先 横 向 处 理 +---------------------------&gt; e a b c b c f + +---+---+---+---+---+---+---+ | a | 0 | 1 | 0 | 0 | 0 | 0 | 0 |纵 | +---------------------------+向 | b | 0 | 0 | 2 | 0 | 1 | 0 | 0 |累 | +---------------------------+加 | c | 0 | 0 | 0 | 3 | 0 | 2 | 0 | | +---------------------------+ | d | 0 | 0 | 0 | 0 | 0 | 0 | 0 | | +---------------------------+ | e | 1 | 0 | 0 | 0 | 0 | 0 | 0 | v +---+---+---+---+---+---+---+ e a b c b c f 优化空间复杂度至O(1)从上图可以发现，在纵向累加时实际只需要左上方的计数器即可, O(n^2^)的空间白白被浪费了,最优的空间复杂度应该是O(1)。那么该如何处理呢？ 一张图解释原理： e a b c b c f +---+ +---+---+---+---+---+---+---+ a | 0 | | 1 | 0 | 0 | 0 | 0 | 0 | a +-------+ +-----------------------+ b | 0 | 0 | | 2 | 0 | 1 | 0 | 0 | b +-----------+ --------------------+ c | 0 | 0 | 0 | | 3 | 0 | 2 | 0 | c +---------------+ ----------------+ d | 0 | 0 | 0 | 0 | | 0 | 0 | 0 | d +-------------------+ +-----------+ e | 1 | 0 | 0 | 0 | 0 | | 0 | 0 | e +---+---+---+---+---+-------+ +---+---+ e a b c b c f 答案就是沿着等长对着线处理。 有意思的代码抽象大家可以根据上面思路写一下，一般会把算法分成两部分：处理长方形的左下部分和处理长方形的右上部分，两部分都是双层循环，时间复杂度和空间负载度已经变为了O(n^2^) ，O(1)。 肯定有人已经发现自己的代码处理左下角的代码和处理右上角的代码不能复用，一个是从中间向左下角处理，一个是从中间向右上角处理，明明很类似，但是就是没发合并。 那么有没有方法把这两部分处理抽象成公共代码呢？不卖关子了，直接上图： 1234567891011121314151617 + e | +--+ e a b c b c f a | 1|+---+---+---+---+---+---+---+ +-----+ | 1 | 0 | 0 | 0 | 0 | 0 | a b | 0| 2| +-----------------------+ +--------+ | 2 | 0 | 1 | 0 | 0 | b c | 0| 0| 3| --------------------+ 翻 折 +-----------+ | 3 | 0 | 2 | 0 | c +------------&gt; b | 0| 1| 0| 0| ----------------+ +--------------+ | 0 | 0 | 0 | d c | 0| 0| 2| 0| 0| +-----------+ +--------------+ | 0 | 0 | e f | 0| 0| 0| 0| 0| +---+---+ +--------------+ a b c d e 如果你想使用公共代码同时实现处理左下角和右上角是不可能的了。所以你需要把右上角的三角翻折，然后你就得到了两个三角： 1234567891011121314151617 + e | +--+ a | 1| +---+ +-----+a | 0 | b | 0| 2| +-------+ +--------+b | 0 | 0 | c | 0| 0| 3| +-----------+ +-----------+c | 0 | 0 | 0 | b | 0| 1| 0| 0| +---------------+ +--------------+d | 0 | 0 | 0 | 0 | c | 0| 0| 2| 0| 0| +-------------------+ +--------------+e | 1 | 0 | 0 | 0 | 0 | f | 0| 0| 0| 0| 0| +---+---+---+---+---+------ +--------------+ e a b c b c f a b c d e 这样就变成了处理两遍左下角了，代码也可以完美复用！！！ 最终实现我的完整思考过程已经分析完毕，这样沿对着线处理还有一个小小的优点：提前结束搜索。这一点大家可以自行思考，这里不做过多解释。 直接干货上场： 1234567891011121314151617181920212223242526272829public class Solution { /** * @param A: A string * @param B: A string * @return: the length of the longest common substring. */ public int longestCommonSubstring(String A, String B) { // write your code here char[] achars = A.toCharArray(), bchars = B.toCharArray(); return getMaxLength(bchars, achars, getMaxLength(achars, bchars, 0, 0), 1); } private static int getMaxLength(char[] s1, char[] s2, int maxLength, int startIndex) { for (int start = startIndex; start &lt; s1.length; start++) { int upper = Math.min(s2.length, s1.length - start); // if (upper &lt;= maxLength) break; //提前结束搜索 for (int currentLineLength = 0, x = 0, y = start; x &lt; upper; x++, y++) { if (s1[y] == s2[x]) maxLength = Math.max(maxLength, ++currentLineLength); else { // if (upper - x - 1 &lt;= maxLength) break; //提前结束搜索 currentLineLength = 0; }; } } return maxLength; }} 结尾怎么样，经历这次优化过程是否感觉自己对最长公共子串的认识又更深了一步呢？虽然不能保证是首创（也可能是首创？），但是这次一步一步真切思考优化直到获得成果让我无比兴奋。 说了这么多，我就是要给我们贝壳招聘开发组打个广告&gt;_&gt;，期待更多爱思考优秀的同学加入！ ![](/Users/sage/Desktop/屏幕快照 2018-11-10 13.33.20.png)","link":"/2018/11/11/2018/2018-11-11-%E5%86%8D%E8%B0%88%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E4%B8%B2/"},{"title":"构建大型支付系统时分布式架构的关键点","text":"SLA在构建大型系统时，常常会遇到各种错误。在计划构建一个系统时，定义系统的“健康状态”十分重要。 “健康状态”必须是可度量的，一般做法是使用SLAs来度量系统的“健康状态”。最常见的SLA为 可达性 从时间维度衡量（99.999%可达性，每年下线50分钟） 准确性 对于数据的丢失或失真是否可以接受？可以达到多少百分比？对于支付系统来说，不接受任何数据的丢失和失真 容量 系统支持并发 延迟 响应延迟，一般衡量95%请求的响应时间和99%请求响应时间 确保新系统比被替代系统“更好”，可以使用上面四个SLA指标来衡量，可达性是最重要的需求。 水平和垂直伸缩随着新业务的增长，负载也会增加。最常见的伸缩策略是垂直和水平伸缩。 水平伸缩就是增加更多的机器或节点，对于分布式系统来说水平伸缩是最常有的方式。 垂直伸缩基本上就是买更大/好的机器。 一致性可达性对于任何系统都是很重要的，但是分布式系统一般都构建在低可达性的机器上（比如：服务的可达性要求99.999% 机器的可达性为99.9%）。简单的做法是维护一组机器组成集群，这样服务的可达性不依赖单独的机器。 一致性是在高可用系统中最需要关心的。一个一致性系统在所有的节点上看到和返回的数据在同一时间是相同的。如果使用一组机器来组成集群，它们还需要互相发送消息来保持同步，但是发送消息可能失败，这样一些节点就会因为不一致而不可达。 一致性有多个模型，在分布式系统最常用的是强一致性，弱一致性和最终一致性。一般来说，一致性要求越低，系统可以工作的更快，但是返回的数据不一定是最新的。 系统中的数据需要是一致的，但是到底是怎样的一致？对于一些系统，需要强一致性，比如一次支付必须是强一致的存储下来。对于没那么重要的部分，最终一致性是可以考虑的权衡。比如列出最近的交易。 数据持久性持久性表示一旦数据成功添加到数据存储，它就永远可以访问到。不同的分布式数据库拥有不同级别的数据持久性。一般使用副本来增加数据持久性。 对于支付系统来说，数据不允许丢失。我们构建的分布式数据存储需要支持集群级别的数据持久型。目前Cassandra, MongoDB, HDFS和Dynamodb 都支持多种级别的数据持久性。 消息保持与持久性分布式系统中的节点执行计算，存储数据，互相发送消息。发送消息的关键是消息的可靠到达。对于关键系统，经常需要消息零丢失。 对于分布式系统，发送消息一般石油分布式消息服务发送，如RabbitMQ，Kafka。这些消息服务支持不同级别的消息投递可靠性。 消息保持表示当节点处理消息失败时，在错误被解决前消息一直被保持着。消息的持久性一般在消息队列层被使用。如果在消息发送的时候队列或节点下线了，那在它们重新上线是还能接收到消息。 在支付系统中我们需要每一条消息投递一次，在构建系统中保证投递一次和投递至少一次在实现上是有区别的。最后我们使用了kafka来保证投递至少一次。 幂等性在分布式系统中，很多东西都可能出错，连接会丢包或超时，客户端经常会重试这些请求。一个幂等的系统保证无论多少特定的请求被执行，一个请求实际的操作只会执行一次。比如支付请求，如果客户端请求支付并且请求已经成功，但是客户端超时了，客户端是能够重试相同的请求的。对于一个幂等的系统，一个个人的支付是不能被收取两次的。 对幂等的设计，分布式系统需要某种分布式锁机制。假设我们想要使用乐观锁来实现幂等性，这时系统需要强一致性的锁来执行操作，我们可以使用同一个版本的乐观锁来检查是否有启动了额外的操作。 根据系统的一致性和操作的类型，有很多方式来实现幂等性。在设计分布式系统时，幂等性时最容易忽略的。在支付系统中，幂等操作时最重要的，它避免了双花和双收问题。消息系统已经保证了消息至少消费一次，我们只需要保证所有重复的消息保证幂等性即可。我们选择使用乐观锁，并使用强一致性存储作为乐观锁的数据源。 分片和法定人数分布式系统经常需要存储大量的数据，远超一台节点的容量。一般的解决方案时使用分片，数据使用某种hash算法被水平分区。尽管很多分布式数据库屏蔽了分片的实现，但是分片还是挺有意思的，特别是关于重新分片。 许多分布式系统在多个拥有数据和统计信息。为保证对数据操作的一致性，使用基于投票的方式是不行的，只有超过一定数量的节点操作成功，这个操作才是成功的，这个叫做法定人数。 Actor模型描述分布式系统最普遍的做法是使用Actor模型，还有一种方法是CSP。 Actor模型基于actor互相发送消息并作出回应。每一个actor只能做少量的动作，创建其他actors, 发送消息或者决定如何处理下个消息。通过这些简单的规则，复杂的分布式系统可以被准确描述，可以在actor崩溃后自我修复。 使用akka提供了标准的分布式模型，避免我们重复造轮子。 反应式架构当构建大型分布式系统时，目标常常是它们的弹性，伸缩性，和扩展性。反应式架构是在这个领域最流行和最通用的方案。","link":"/2018/11/19/2018/2018-11-19-%E6%9E%84%E5%BB%BA%E5%A4%A7%E5%9E%8B%E6%94%AF%E4%BB%98%E7%B3%BB%E7%BB%9F%E6%97%B6%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E7%9A%84%E5%85%B3%E9%94%AE%E7%82%B9/"},{"title":"[感悟] 2018我的所见所闻所感","text":"1. 我就喜欢写代码行不行？如果刚刚投入工作，工作还无法完全胜任，那我的建议是多写写代码，打怪升级完成自己的年度绩效。 如果已经能够胜任当前工作，下一步应该集中在提效上。这一步和之前自己积累的经验和知识密不可分，只有真正了解代码懂代码，才能从同龄人中的“熟练工”脱颖而出，两者的提效虽然结果一样，但是本质却完全不一样。 如果已经摆脱了熟练工的称号，实际上已经完成了自我提效，提前完成自己的本职任务，下一步可以计划推动团队的效率。 如果太过专注技术，专心自己的一亩三分田，相当于给自己设限成毕业两三年的水平。这种人应该被打上不胜任的标签，在寒冬中很容易被优化掉。专注技术还有一个误区，就是容易把“实施细节”和“技术”两者混淆，特别在软件行业“实施细节”很容易随时代改变，基本三年就会大变样，而“技术”类似于“知识”不会过时。看到这里大家可以自己思考下，自己学到的到底是“实施细节”还是真正的“技术”。 2.如何推动团队进步恭喜你跨过了第一道坎，推动团队进步不是一个人的事，一般推动团队分为两部分：个人影响团队，团队自我驱动。 个人影响团队比较简单，就是把自我提效所积累的经验和知识共享给整个团队，完成的手段可以是博客分享，会议分享，文档分享。 团队自我驱动，实际上我把整个团队拟作了一个人，一个人找出别人的缺点很容易，但是找出一个团队的问题却没那么容易，同时也会受到公司和领导的局限，比如一些项目管理的领导就是二传手，只催你进度的那种，这时候就需要你主动找他讨论。 如何找到团队的缺点？可以通过下面两个大类的套路：管理手段和技术手段。 管理手段可以从知识管理、代码规范、需求分析三处着手： 知识管理： 建立知识库，避免重复的培训，重复的解答问题 代码规范：借助代码缺陷检查工具，具体到负责人提升代码规范 需求分析：避免低效，无效会议，避免各种妥协下产生的需求 技术手段比较简单： 重构升级：弃用老的架构，拥抱新技术，带领团队提升技术 内部造轮子：内部定制工具，帮助团队高效完成任务 找到了团队的缺点接下来可以制定度量，衡量团队的推进程度，可以从两个角度进行度量： 跟自己比较：比如这次做需求提测bug数减少，需求delay少了，满足需求不需要上线只要配置上线，等等 和别的团队比较：这个比较凶残，我也不知道用什么度量比，但是有的大公司就是这样做的。 3.总结与晋升从发现缺点到最后得到成果完成团队推进目标，是时候写个ppt在领导面前吹一波了，这个就不用我教了。","link":"/2018/12/21/2018/2018-12-21-2018%E6%88%91%E7%9A%84%E6%89%80%E8%A7%81%E6%89%80%E9%97%BB%E6%89%80%E6%84%9F/"},{"title":"代码外的生存之道-读书笔记-职业篇","text":"职业发展的驱动力应该来自自身，工作属于公司，职业生涯属于自己。 第一要务 拥有正确的心态大多数人形成的错误的心态: 认为在为公司打工，没有把自己的职业生涯当作生意来看待。铭记在心，开始积极主动的管理自己的职业生涯吧。 像企业一样思考自己能提供什么:自己的能力就是创造软件自己需要做什么: 持续不断地改进和完善自己的产品 传达自己的价值，和千万同行的独特之处 一头扎进工作不可能非同凡响，你应该： 专注于你正在提供怎样的服务， 以及如何营销这项服务； 想方设 提升你的服务； 思考你可以专注为哪一 特定类型的客户或行业提供特定的服务； 集中精力成为一位专家，专门为某一特定类型的客户提供专业的整体服务（ 记住， 作为一个软件开发 人员， 你 只有真正专注 于一类客户，才能找到非常好的工作）。 更好的宣传自己的产品，更好的找到你的客户 第二要务 设定自己的目标无论因为何种原因你没有为自己的职业生涯设定目标， 现在都是时候设定目标了。 不是明天， 也不是下周， 就是现在。 没有明确的方向， 你走的每一步都是徒劳的。 如何设定目标？先在心中树立一个大目标，然后分解成多个小目标 追踪你的目标定期核对自己的目标，必要时还要调整。 人际交往能力","link":"/2018/12/27/2018/2018-12-27-%E4%BB%A3%E7%A0%81%E5%A4%96%E7%9A%84%E7%94%9F%E5%AD%98%E4%B9%8B%E9%81%93-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E8%81%8C%E4%B8%9A%E7%AF%87/"},{"title":"[片段] Mybatis ResultSetHandler实践","text":"这次拦截的方法是handleResultSets(Statement stmt)，用来批量解密用@Encrypted注解的String字段，可能还有一些坑。 12345678910111213141516171819202122232425262728293031323334353637@Overridepublic List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException { ErrorContext.instance().activity(&quot;handling results&quot;).object(mappedStatement.getId()); final List&lt;Object&gt; multipleResults = new ArrayList&lt;Object&gt;(); int resultSetCount = 0; ResultSetWrapper rsw = getFirstResultSet(stmt); List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) { ResultMap resultMap = resultMaps.get(resultSetCount); handleResultSet(rsw, resultMap, multipleResults, null); rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; } String[] resultSets = mappedStatement.getResultSets(); if (resultSets != null) { while (rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) { ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) { String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = configuration.getResultMap(nestedResultMapId); handleResultSet(rsw, resultMap, null, parentMapping); } rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; } } return collapseSingleResultList(multipleResults);} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123package app.pooi.common.encrypt;import app.pooi.common.encrypt.anno.CipherSpi;import app.pooi.common.encrypt.anno.Encrypted;import lombok.Getter;import org.apache.ibatis.executor.resultset.ResultSetHandler;import org.apache.ibatis.plugin.*;import org.apache.ibatis.reflection.MetaObject;import org.apache.ibatis.reflection.SystemMetaObject;import java.lang.reflect.Field;import java.sql.Statement;import java.util.*;import java.util.function.Function;import java.util.logging.Logger;import java.util.stream.Collectors;@Intercepts({ @Signature(type = ResultSetHandler.class, method = &quot;handleResultSets&quot;, args = {Statement.class}),})public class EncryptInterceptor implements Interceptor { private static final Logger logger = Logger.getLogger(EncryptInterceptor.class.getName()); private CipherSpi cipherSpi; public EncryptInterceptor(CipherSpi cipherSpi) { this.cipherSpi = cipherSpi; } @Override public Object intercept(Invocation invocation) throws Throwable { final Object proceed = invocation.proceed(); if (proceed == null) { return proceed; } List&lt;?&gt; results = (List&lt;?&gt;) proceed; if (results.isEmpty()) { return proceed; } final Object first = results.iterator().next(); final Class&lt;?&gt; modelClazz = first.getClass(); final List&lt;String&gt; fieldsNeedDecrypt = Arrays.stream(modelClazz.getDeclaredFields()) .filter(f -&gt; f.getAnnotation(Encrypted.class) != null) .filter(f -&gt; { boolean isString = f.getType() == String.class; if (!isString) { logger.warning(f.getName() + &quot;is not String, actual type is &quot; + f.getType().getSimpleName() + &quot; ignored&quot;); } return isString; }) .map(Field::getName) .collect(Collectors.toList()); final List&lt;List&lt;String&gt;&gt; partition = partition(fieldsNeedDecrypt, 20); for (Object r : results) { final MetaObject metaObject = SystemMetaObject.forObject(r); for (List&lt;String&gt; fields : partition) { final Map&lt;String, String&gt; fieldValueMap = fields.stream().collect(Collectors.toMap(Function.identity(), f -&gt; (String) metaObject.getValue(f))); final ArrayList&lt;String&gt; values = new ArrayList&lt;&gt;(fieldValueMap.values()); Map&lt;String, String&gt; decryptValues = cipherSpi.decrypt(values); fieldValueMap.entrySet() .stream() .map(e -&gt; Tuple2.of(e.getKey(), decryptValues.getOrDefault(e.getValue(), &quot;&quot;))) .forEach(e -&gt; metaObject.setValue(e.getT1(), e.getT2())); } } return results; } private &lt;T&gt; List&lt;List&lt;T&gt;&gt; partition(List&lt;T&gt; list, int batchCount) { if (!(batchCount &gt; 0)) { throw new IllegalArgumentException(&quot;batch count must greater than zero&quot;); } List&lt;List&lt;T&gt;&gt; partitionList = new ArrayList&lt;&gt;(list.size() / (batchCount + 1)); for (int i = 0; i &lt; list.size(); i += batchCount) { partitionList.add(list.stream().skip(i).limit(batchCount).collect(Collectors.toList())); } return partitionList; } @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } @Override public void setProperties(Properties properties) { }}@Getterclass Tuple2&lt;T1, T2&gt; { private final T1 t1; private final T2 t2; Tuple2(T1 t1, T2 t2) { this.t1 = t1; this.t2 = t2; } static &lt;T1, T2&gt; Tuple2&lt;T1, T2&gt; of(T1 t1, T2 t2) { return new Tuple2&lt;&gt;(t1, t2); }}","link":"/2019/01/09/2019/2019-01-09-Mybatis_ResultSetHandler%E5%AE%9E%E8%B7%B5/"},{"title":"[片段] Java收集方法参数+Spring DataBinder","text":"收集参数目前是使用了spring aop 来拦截方法调用，把方法参数包装成Map形式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface CollectArguments {}@Aspectpublic class ArgumentsCollector { private static final ThreadLocal&lt;Map&lt;String, Object&gt;&gt; ARGUMENTS = ThreadLocal.withInitial(ImmutableMap::of); static Map&lt;String, Object&gt; getArgs() { return ARGUMENTS.get(); } private Object[] args(Object[] args, int exceptLength) { if (exceptLength == args.length) { return args; } return Arrays.copyOf(args, exceptLength); } @Pointcut(&quot;@annotation(CollectArguments)&quot;) void collectArgumentsAnnotationPointCut() { } @Before(&quot;collectArgumentsAnnotationPointCut()&quot;) public void doAccessCheck(JoinPoint joinPoint) { final String[] parameterNames = ((MethodSignature) joinPoint.getSignature()).getParameterNames(); final Object[] args = args(joinPoint.getArgs(), parameterNames.length); ARGUMENTS.set(Collections.unmodifiableMap((IntStream.range(0, parameterNames.length - 1) .mapToObj(idx -&gt; Tuple2.of(parameterNames[idx], args[idx])) .collect(HashMap::new, (m, t) -&gt; m.put(t.getT1(), t.getT2()), HashMap::putAll)))); } @After(&quot;collectArgumentsAnnotationPointCut()&quot;) public void remove() { ARGUMENTS.remove(); } @Data private static class Tuple2&lt;T1, T2&gt; { private T1 t1; private T2 t2; Tuple2(T1 t1, T2 t2) { this.t1 = t1; this.t2 = t2; } public static &lt;T1, T2&gt; Tuple2&lt;T1, T2&gt; of(T1 t1, T2 t2) { return new Tuple2&lt;&gt;(t1, t2); } }} 通过Map构造对象123456789101112public class BinderUtil { BinderUtil() { } @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; T getTarget(Class&lt;T&gt; beanClazz) { final DataBinder binder = new DataBinder(BeanUtils.instantiate(beanClazz)); binder.bind(new MutablePropertyValues(ArgumentsCollector.getArgs())); return (T) binder.getTarget(); }}","link":"/2019/01/22/2019/2019-01-22-Java%E6%94%B6%E9%9B%86%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0+Spring_DataBinder/"},{"title":"[片段] 使用TypeToken在运行期保存泛型信息","text":"一般来说可以使用getGenericSuperclass 获取子类范型信息，但是泛型有嵌套的话想获取完整信息还是有点复杂的。例如：Message&lt;List&gt; 有两个泛型信息。 guava中有强大的TypeToken帮助你保存复杂泛型信息，可以参考： 123ParameterizedTypeReference&lt;Message&lt;T&gt;&gt; responseTypeRef = ParameterizedTypeReferenceBuilder.fromTypeToken( new TypeToken&lt;Message&lt;T&gt;&gt;() {}.where(new TypeParameter&lt;T&gt;() {}, new TypeToken&lt;List&lt;OrgSugVOV1&gt;&gt;() {})); 如果需要在spring框架中使用，需要一个适配器： 123456789101112131415161718192021222324252627282930313233343536public class ParameterizedTypeReferenceBuilder { public static &lt;T&gt; ParameterizedTypeReference&lt;T&gt; fromTypeToken(TypeToken&lt;T&gt; typeToken) { return new TypeTokenParameterizedTypeReference&lt;&gt;(typeToken); } private static class TypeTokenParameterizedTypeReference&lt;T&gt; extends ParameterizedTypeReference&lt;T&gt; { private final Type type; private TypeTokenParameterizedTypeReference(TypeToken&lt;T&gt; typeToken) { this.type = typeToken.getType(); } @Override public Type getType() { return type; } @Override public boolean equals(Object obj) { return (this == obj || (obj instanceof ParameterizedTypeReference &amp;&amp; this.type.equals(((ParameterizedTypeReference&lt;?&gt;) obj).getType()))); } @Override public int hashCode() { return this.type.hashCode(); } @Override public String toString() { return &quot;ParameterizedTypeReference&lt;&quot; + this.type + &quot;&gt;&quot;; } }} 关于java的泛型我就不多做吐槽了。","link":"/2019/02/26/2019/2019-02-26-%E4%BD%BF%E7%94%A8TypeToken%E5%9C%A8%E8%BF%90%E8%A1%8C%E6%9C%9F%E4%BF%9D%E5%AD%98%E6%B3%9B%E5%9E%8B%E4%BF%A1%E6%81%AF/"},{"title":"[片段] @CreatedBy &#x2F; @ModifiedBy 拦截器实现","text":"拦截器实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package app.pooi.common.entity;import app.pooi.common.entity.anno.CreatedBy;import app.pooi.common.entity.anno.ModifiedBy;import lombok.Data;import org.apache.ibatis.executor.Executor;import org.apache.ibatis.mapping.MappedStatement;import org.apache.ibatis.plugin.Intercepts;import org.apache.ibatis.plugin.Invocation;import org.apache.ibatis.plugin.Plugin;import org.apache.ibatis.plugin.Signature;import java.util.Arrays;import java.util.Properties;import java.util.function.Supplier;@Data@Intercepts({ @Signature(type = Executor.class, method = &quot;update&quot;, args = {MappedStatement.class, Object.class}),})public class EntityInterceptor implements org.apache.ibatis.plugin.Interceptor { private Supplier&lt;Long&gt; auditorAware; @Override public Object intercept(Invocation invocation) throws Throwable { Executor executor = (Executor) invocation.getTarget(); MappedStatement ms = (MappedStatement) invocation.getArgs()[0]; Object o = invocation.getArgs()[1]; Arrays.stream(o.getClass().getDeclaredFields()) .forEach(field -&gt; { final CreatedBy createdBy = field.getAnnotation(CreatedBy.class); final ModifiedBy modifiedBy = field.getAnnotation(ModifiedBy.class); if (createdBy != null || modifiedBy != null) { field.setAccessible(true); try { field.set(o, auditorAware.get()); } catch (IllegalAccessException ignore) { } } }); return invocation.proceed(); } @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } @Override public void setProperties(Properties properties) { }} 配置： 1234567891011121314@Configurationstatic class MybatisInterceptorConfig { @Bean public Interceptor[] configurationCustomizer(CipherSpi cipherSpi) { final EntityInterceptor entityInterceptor = new EntityInterceptor(); entityInterceptor.setAuditorAware(() -&gt; { final String header = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest().getHeader(XHeaders.LOGIN_USER_ID); return Long.valueOf(header); }); return new Interceptor[]{new DecryptInterceptor(cipherSpi), entityInterceptor}; }}","link":"/2019/02/11/2019/2019-02-11-@CreatedBy%20_@ModifiedBy_%E6%8B%A6%E6%88%AA%E5%99%A8%E5%AE%9E%E7%8E%B0/"},{"title":"[片段] 使用redis创建简易搜索引擎（核心篇）","text":"支持and查询、多选、多字段排序分页，缺少的功能：or 条件 核心类，有一些测试代码，将就一下。另外需要spring-data-redis 2.0版本以上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383package app.pooi.redissearch.search;import app.pooi.redissearch.search.anno.CreateIndex;import app.pooi.redissearch.search.anno.Field;import com.google.common.collect.Lists;import com.google.common.collect.Sets;import lombok.Data;import org.apache.commons.lang3.ArrayUtils;import org.springframework.dao.DataAccessException;import org.springframework.data.redis.connection.RedisZSetCommands;import org.springframework.data.redis.core.*;import org.springframework.data.redis.hash.Jackson2HashMapper;import org.springframework.stereotype.Service;import org.springframework.web.bind.annotation.*;import reactor.util.function.Tuple2;import reactor.util.function.Tuples;import java.util.*;import java.util.concurrent.TimeUnit;import java.util.function.Consumer;import java.util.function.Function;import java.util.regex.Matcher;import java.util.regex.Pattern;import java.util.stream.Collectors;import java.util.stream.Stream;import static app.pooi.redissearch.search.SearchCore.Util.*;@RestController@Servicepublic class SearchCore { private StringRedisTemplate redisTemplate; private Jackson2HashMapper hashMapper = new Jackson2HashMapper(true); @Data private static class Person { private Long id; private String name; private Integer age; private Long ctime; } @PostMapping(&quot;/person&quot;) @CreateIndex( index = &quot;person&quot;, documentId = &quot;#p0.id&quot;, fields = { @Field(propertyName = &quot;name&quot;, value = &quot;#p0.name&quot;), @Field(propertyName = &quot;age&quot;, value = &quot;#p0.age&quot;, sort = true), @Field(propertyName = &quot;ctime&quot;, value = &quot;#p0.ctime&quot;, sort = true) }) Person addPerson(Person person) { return person; } public SearchCore(StringRedisTemplate redisTemplate) { this.redisTemplate = redisTemplate; } public void indexMeta(String index, Map&lt;String, FieldMeta&gt; fieldMeta) { this.redisTemplate.opsForHash().putAll(genIdxMetaName(index), hashMapper.toHash(fieldMeta)); } @PostMapping(&quot;/index&quot;) public int indexDocument( final String index, final String field, final String documentId, final String document) { return this.indexDocument(index, field, documentId, document, doc -&gt; Lists.newArrayList(doc.split(&quot;&quot;))); } public int indexDocument( final String index, final String field, final String documentId, final String document, final Function&lt;String, List&lt;String&gt;&gt; tokenizer) { final List&lt;String&gt; tokens = tokenizer != null ? tokenizer.apply(document) : Collections.singletonList(document); final String docKey = genDocIdxName(index, documentId); final List&lt;Object&gt; results = redisTemplate.executePipelined(new SessionCallback&lt;Integer&gt;() { @Override public Integer execute(RedisOperations operations) throws DataAccessException { final StringRedisTemplate template = (StringRedisTemplate) operations; final String[] idxs = tokens.stream() .map(word -&gt; genIdxName(index, field, word)) .peek(idx -&gt; ((StringRedisTemplate) operations).opsForSet().add(idx, documentId)) .toArray(String[]::new); template.opsForSet().add(docKey, idxs); return null; } }); return results.size(); } public int indexSortField( final String index, final String field, final String documentId, final Double document) { final String docKey = genDocIdxName(index, documentId); final List&lt;Object&gt; results = redisTemplate.executePipelined(new SessionCallback&lt;Integer&gt;() { @Override public Integer execute(RedisOperations operations) throws DataAccessException { final StringRedisTemplate template = (StringRedisTemplate) operations; final String idxName = genSortIdxName(index, field); template.opsForZSet().add(idxName, documentId, document); template.opsForSet().add(docKey, idxName); return null; } }); return results.size(); } @DeleteMapping(&quot;/index&quot;) public int deleteDocumentIndex(final String index, final String documentId) { final String docKey = genDocIdxName(index, documentId); final Boolean hasKey = redisTemplate.hasKey(docKey); if (!hasKey) { return 0; } final List&lt;Object&gt; results = redisTemplate.executePipelined(new SessionCallback&lt;Integer&gt;() { @Override public Integer execute(RedisOperations operations) throws DataAccessException { final Set&lt;String&gt; idx = redisTemplate.opsForSet().members(docKey); ((StringRedisTemplate) operations).delete(idx); ((StringRedisTemplate) operations).delete(docKey); return null; } }); return results.size(); } @PatchMapping(&quot;/index&quot;) public int updateDocumentIndex(final String index, final String field, final String documentId, final String document) { this.deleteDocumentIndex(index, documentId); return this.indexDocument(index, field, documentId, document); } public int updateSortField(final String index, final String field, final String documentId, final Double document) { this.deleteDocumentIndex(index, documentId); return this.indexSortField(index, field, documentId, document); } private Consumer&lt;SetOperations&lt;String, String&gt;&gt; operateAndStore(String method, String key, Collection&lt;String&gt; keys, String destKey) { switch (method) { case &quot;intersectAndStore&quot;: return (so) -&gt; so.intersectAndStore(key, keys, destKey); case &quot;unionAndStore&quot;: return (so) -&gt; so.unionAndStore(key, keys, destKey); case &quot;differenceAndStore&quot;: return (so) -&gt; so.differenceAndStore(key, keys, destKey); default: return so -&gt; { }; } } private Consumer&lt;ZSetOperations&lt;String, String&gt;&gt; zOperateAndStore(String method, String key, Collection&lt;String&gt; keys, String destKey, final RedisZSetCommands.Weights weights) { switch (method) { case &quot;intersectAndStore&quot;: return (so) -&gt; so.intersectAndStore(key, keys, destKey, RedisZSetCommands.Aggregate.SUM, weights); case &quot;unionAndStore&quot;: return (so) -&gt; so.unionAndStore(key, keys, destKey, RedisZSetCommands.Aggregate.SUM, weights); default: return so -&gt; { }; } } private String common(String index, String method, List&lt;String&gt; keys, long ttl) { final String destKey = Util.genQueryIdxName(index); redisTemplate.executePipelined(new SessionCallback&lt;String&gt;() { @Override public &lt;K, V&gt; String execute(RedisOperations&lt;K, V&gt; operations) throws DataAccessException { operateAndStore(method, keys.stream().limit(1L).findFirst().get(), keys.stream().skip(1L).collect(Collectors.toList()), destKey) .accept(((StringRedisTemplate) operations).opsForSet()); ((StringRedisTemplate) operations).expire(destKey, ttl, TimeUnit.SECONDS); return null; } }); return destKey; } public String intersect(String index, List&lt;String&gt; keys, long ttl) { return common(index, &quot;intersectAndStore&quot;, keys, ttl); } public String union(String index, List&lt;String&gt; keys, long ttl) { return common(index, &quot;unionAndStore&quot;, keys, ttl); } public String diff(String index, List&lt;String&gt; keys, long ttl) { return common(index, &quot;differenceAndStore&quot;, keys, ttl); } private static Tuple2&lt;Set&lt;Tuple2&lt;String, String&gt;&gt;, Set&lt;Tuple2&lt;String, String&gt;&gt;&gt; parse(String query) { final Pattern pattern = Pattern.compile(&quot;[+-]?([\\\\w\\\\d]+):(\\\\S+)&quot;); final Matcher matcher = pattern.matcher(query); Set&lt;Tuple2&lt;String, String&gt;&gt; unwant = Sets.newHashSet(); Set&lt;Tuple2&lt;String, String&gt;&gt; want = Sets.newHashSet(); while (matcher.find()) { String word = matcher.group(); String prefix = null; if (word.length() &gt; 1) { prefix = word.substring(0, 1); } final Tuple2&lt;String, String&gt; t = Tuples.of(matcher.group(1), matcher.group(2)); if (&quot;-&quot;.equals(prefix)) { unwant.add(t); } else { want.add(t); } } return Tuples.of(want, unwant); } public String query( String index, String query) { final Tuple2&lt;Set&lt;Tuple2&lt;String, String&gt;&gt;, Set&lt;Tuple2&lt;String, String&gt;&gt;&gt; parseResult = parse(query); final Set&lt;Tuple2&lt;String, String&gt;&gt; want = parseResult.getT1(); final Set&lt;Tuple2&lt;String, String&gt;&gt; unwant = parseResult.getT2(); if (want.isEmpty()) { return &quot;&quot;; } final Map&lt;String, FieldMeta&gt; entries = (Map&lt;String, FieldMeta&gt;) hashMapper.fromHash(redisTemplate.&lt;String, Object&gt;opsForHash().entries(genIdxMetaName(index))); // union final List&lt;Tuple2&lt;String, String&gt;&gt; unionFields = want.stream() .filter(w -&gt; w.getT2().contains(&quot;,&quot;)) .filter(w -&gt; &quot;true&quot;.equals(entries.get(w.getT1()).getSort())) .collect(Collectors.toList()); final List&lt;String&gt; unionIdx = unionFields.stream() .flatMap(w -&gt; Arrays.stream(w.getT2().split(&quot;,&quot;)).map(value -&gt; Tuples.of(w.getT1(), value))) .map(w -&gt; genIdxName(index, w.getT1(), w.getT2())) .collect(Collectors.toList()); final String unionResultId = unionIdx.isEmpty() ? &quot;&quot; : this.union(index, unionIdx, 30L); want.removeAll(unionFields); // intersect final List&lt;String&gt; intersectIdx = want.stream() .flatMap(t -&gt; { if (&quot;true&quot;.equals(entries.get(t.getT1()).getSort())) return Stream.of(t); return Arrays.stream(t.getT2().split(&quot;&quot;)).map(value -&gt; Tuples.of(t.getT1(), value)); }) .map(w -&gt; genIdxName(index, w.getT1(), w.getT2())) .collect(Collectors.toList()); if (!unionResultId.isEmpty()) intersectIdx.add(unionResultId); String intersectResult = this.intersect(index, intersectIdx, 30L); // diff return unwant.isEmpty() ? intersectResult : this.diff(index, Stream.concat(Stream.of(intersectResult), unwant.stream().map(w -&gt; genIdxName(index, w.getT1(), w.getT2()))).collect(Collectors.toList()), 30L); } @GetMapping(&quot;/query/{index}&quot;) public Set&lt;String&gt; queryAndSort( @PathVariable(&quot;index&quot;) String index, @RequestParam(&quot;param&quot;) String query, @RequestParam(&quot;sort&quot;) String sort, Integer start, Integer stop ) { final String[] sorts = sort.split(&quot; &quot;); final Map&lt;String, Integer&gt; map = Arrays.stream(sorts).collect( Collectors.toMap(f -&gt; { if (f.startsWith(&quot;+&quot;) || f.startsWith(&quot;-&quot;)) { f = f.substring(1); } return genSortIdxName(&quot;person&quot;, f); }, field -&gt; field.startsWith(&quot;-&quot;) ? -1 : 1) ); final int[] weights = map.values() .stream() .mapToInt(Integer::intValue) .toArray();// if (!sort.startsWith(&quot;+&quot;) &amp;&amp; !sort.startsWith(&quot;-&quot;)) {// sort = &quot;+&quot; + sort;// }// boolean desc = sort.startsWith(&quot;-&quot;);// sort = sort.substring(1); String queryId = this.query(index, query); Long size; if (queryId.length() == 0 || (size = redisTemplate.opsForSet().size(queryId)) == null || size == 0) { return Collections.emptySet(); } final String resultId = genQueryIdxName(index);// String sortField = sort; redisTemplate.executePipelined(new SessionCallback&lt;Object&gt;() { @Override public &lt;K, V&gt; Object execute(RedisOperations&lt;K, V&gt; operations) throws DataAccessException { final StringRedisTemplate template = (StringRedisTemplate) operations;// template.opsForZSet().intersectAndStore(genSortIdxName(index, sortField), queryId, resultId); SearchCore.this.zOperateAndStore(&quot;intersectAndStore&quot;, map.keySet().stream().limit(1L).findFirst().get(), Stream.concat(map.keySet().stream().skip(1L), Stream.of(queryId)).collect(Collectors.toList()), resultId, RedisZSetCommands.Weights.of(ArrayUtils.add(weights, 0))).accept(template.opsForZSet());// template.opsForZSet().size(resultId); template.expire(resultId, 30L, TimeUnit.SECONDS); return null; } }); // sort return redisTemplate.opsForZSet().range(resultId, start, stop); } static class Util { private Util() { } static String genIdxMetaName(String index) { return String.format(&quot;meta:idx:%s&quot;, index); } static String genIdxName(String index, String field, String value) { return String.format(&quot;idx:%s:%s:%s&quot;, index, field, value); } static String genSortIdxName(String index, String field) { return String.format(&quot;idx:%s:%s&quot;, index, field); } static String genQueryIdxName(String index) { return String.format(&quot;idx:%s:q:%s&quot;, index, UUID.randomUUID().toString()); } static String genDocIdxName(String index, String documentId) { return String.format(&quot;doc:%s:%s&quot;, index, documentId); } }} 辅助类 123456789101112131415161718import lombok.Data;@Datapublic class FieldMeta { private String sort = &quot;false&quot;; private String splitFun = &quot;&quot;; public FieldMeta() { } public FieldMeta(boolean sort) { this.sort = Boolean.toString(sort); }} 做一个轻量级的搜索还是可以的。","link":"/2019/03/11/2019/2019-03-11-%5B%E7%89%87%E6%AE%B5%5D%E4%BD%BF%E7%94%A8redis%E5%88%9B%E5%BB%BA%E7%AE%80%E6%98%93%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E(%E6%A0%B8%E5%BF%83%E7%AF%87)/"},{"title":"[片段] SpringBoot Mybatis配置","text":"纯记录，供自己参考🤣。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140private final MybatisProperties properties;private final Interceptor[] interceptors;private final ResourceLoader resourceLoader;private final DatabaseIdProvider databaseIdProvider;private final List&lt;ConfigurationCustomizer&gt; configurationCustomizers;public DataSourceConfig(MybatisProperties properties, ObjectProvider&lt;Interceptor[]&gt; interceptorsProvider, ResourceLoader resourceLoader, ObjectProvider&lt;DatabaseIdProvider&gt; databaseIdProvider, ObjectProvider&lt;List&lt;ConfigurationCustomizer&gt;&gt; configurationCustomizersProvider) { this.properties = properties; this.interceptors = interceptorsProvider.getIfAvailable(); this.resourceLoader = resourceLoader; this.databaseIdProvider = databaseIdProvider.getIfAvailable(); this.configurationCustomizers = configurationCustomizersProvider.getIfAvailable();}/** * 普通数据源 * 主数据源，必须配置，spring启动时会执行初始化数据操作（无论是否真的需要），选择查找DataSource class类型的数据源 * * @return {@link DataSource} */@Primary@Bean(name = BEANNAME_DATASOURCE_COMMON)@ConfigurationProperties(prefix = &quot;com.lianjia.confucius.bridge.boot.datasource.common&quot;)public DataSource createDataSourceCommon() { return DataSourceBuilder.create().build();}/** * 只读数据源 * * @return {@link DataSource} */@Bean(name = BEANNAME_DATASOURCE_READONLY)@ConfigurationProperties(prefix = &quot;com.lianjia.confucius.bridge.boot.datasource.readonly&quot;)public DataSource createDataSourceReadonly() { return DataSourceBuilder.create().build();}private SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception { SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); factory.setDataSource(dataSource); factory.setVfs(SpringBootVFS.class); if (StringUtils.hasText(this.properties.getConfigLocation())) { factory.setConfigLocation(this.resourceLoader.getResource(this.properties.getConfigLocation())); } org.apache.ibatis.session.Configuration configuration = this.properties.getConfiguration(); if (configuration == null &amp;&amp; !StringUtils.hasText(this.properties.getConfigLocation())) { configuration = new org.apache.ibatis.session.Configuration(); } if (configuration != null &amp;&amp; !CollectionUtils.isEmpty(this.configurationCustomizers)) { for (ConfigurationCustomizer customizer : this.configurationCustomizers) { customizer.customize(configuration); } } factory.setConfiguration(configuration); if (this.properties.getConfigurationProperties() != null) { factory.setConfigurationProperties(this.properties.getConfigurationProperties()); } if (!ObjectUtils.isEmpty(this.interceptors)) { factory.setPlugins(this.interceptors); } if (this.databaseIdProvider != null) { factory.setDatabaseIdProvider(this.databaseIdProvider); } if (StringUtils.hasLength(this.properties.getTypeAliasesPackage())) { factory.setTypeAliasesPackage(this.properties.getTypeAliasesPackage()); } if (StringUtils.hasLength(this.properties.getTypeHandlersPackage())) { factory.setTypeHandlersPackage(this.properties.getTypeHandlersPackage()); } if (!ObjectUtils.isEmpty(this.properties.resolveMapperLocations())) { factory.setMapperLocations(this.properties.resolveMapperLocations()); } return factory.getObject();}public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) { ExecutorType executorType = this.properties.getExecutorType(); if (executorType != null) { return new SqlSessionTemplate(sqlSessionFactory, executorType); } else { return new SqlSessionTemplate(sqlSessionFactory); }}@Bean@Primarypublic SqlSessionFactory primarySqlSessionFactory() throws Exception { return this.sqlSessionFactory(this.createDataSourceCommon());}@Beanpublic SqlSessionFactory secondarySqlSessionFactory() throws Exception { return this.sqlSessionFactory(this.createDataSourceReadonly());}/** * 实例普通的 sqlSession * * @return SqlSession * @throws Exception when any exception occured */@Bean(name = BEANNAME_SQLSESSION_COMMON)public SqlSession initSqlSessionCommon() throws Exception { return this.sqlSessionTemplate(this.primarySqlSessionFactory());}/** * 实例只读的 sqlSession * * @return SqlSession * @throws Exception when any exception occured */@Bean(name = BEANNAME_SQLSESSION_READONLY)public SqlSession initSqlSessionReadonly() throws Exception { return this.sqlSessionTemplate(this.secondarySqlSessionFactory());}@MapperScan(annotationClass = PrimaryMapper.class, sqlSessionTemplateRef = BEANNAME_SQLSESSION_COMMON, basePackageClasses = ITalentApplicationSpringBootStart.class)static class PrimaryMapperConfiguration {}@MapperScan(annotationClass = SecondaryMapper.class, sqlSessionTemplateRef = BEANNAME_SQLSESSION_READONLY, basePackageClasses = ITalentApplicationSpringBootStart.class)static class SecondaryMapperConfiguration {}","link":"/2019/03/13/2019/2019-03-13-SpringBoot_Mybatis%E9%85%8D%E7%BD%AE/"},{"title":"[项目感悟] 读《再谈敏捷开发与延期风控》","text":"本人本身不太喜欢方法论，感觉都是套路，生搬硬套不适合自己，敏捷开发就是其中让我保持谨慎态度的方法论之一。 敏捷开发与Scrum对于一个项目来说，能够即快又好地完成当然是非常棒的，但是众所周知，受限于项目管理三要素：时间、质量、成本，只能折衷选择。因此「敏捷」作为一种方法论（虽然Agile自称为Culture）被提出，其中Scrum(/skrʌm/，一种球类比赛)是比较知名的实现类之一。 在Scum中，它主要强调将瀑布式开发流程转为多阶段小迭代，可以理解为CPU的多级流水线(Instruction pipeline)设计，流水线设计将CPU的计算逻辑拆分，实现了复用计算模块，进而提高了时钟频率，同时也引入了寄存器/分支预测等管理模块增加了复杂度。 类似于CPU流水线机制，敏捷开发本质是在保持时间、质量不变的情况下，通过投入管理成本降低开发过程的空转成本，进而提高时钟周期的方法。 用白话来说，可以把软件开放比作流水车间，把PM，SE比作流水线工人。 我见过的的假敏捷然而到了现实，由于各种原因，却很容易成为假敏捷 将工位的隔栏拆开变成网吧“敏捷岛” 强行将Release计划拆成一个月一版，将Sprint拆成2周就看作快速迭代，照着人月神话反着搞 招聘一堆无责任心的开发让你去“敏捷”，永远无法实现“全功能部队” 客户难沟通，PO低估工作量，SE设计缺陷，编码质量低等原因，最终导致延期上述任何一个问题，都可能导致最终项目一锅粥，导致高层焦虑，中层跑路，底层混日子的结果。 敏捷能够提供强大高效的方法论，但是前提是需要本身基础过硬的团队，敏捷只能帮助存在进步瓶颈的团队。如果项目已经空心化，债务多，这不是敏捷方法论应该解决的问题。","link":"/2019/04/01/2019/2019-04-01-%E8%AF%BB%E3%80%8A%E5%86%8D%E8%B0%88%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%E4%B8%8E%E5%BB%B6%E6%9C%9F%E9%A3%8E%E6%8E%A7%E3%80%8B/"},{"title":"[片段] Mybatis ResultSetHandler实践-续","text":"这次拦截的方法是handleResultSets(Statement stmt)，用来批量解密用@Encrypted注解的String字段。 上次的局限是只能批量解密一个对象的所有加密字段，对批量数据来说稍显不足，这个主要改进了这一点。 12345678910111213141516171819202122232425262728293031323334353637@Overridepublic List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException { ErrorContext.instance().activity(&quot;handling results&quot;).object(mappedStatement.getId()); final List&lt;Object&gt; multipleResults = new ArrayList&lt;Object&gt;(); int resultSetCount = 0; ResultSetWrapper rsw = getFirstResultSet(stmt); List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) { ResultMap resultMap = resultMaps.get(resultSetCount); handleResultSet(rsw, resultMap, multipleResults, null); rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; } String[] resultSets = mappedStatement.getResultSets(); if (resultSets != null) { while (rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) { ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) { String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = configuration.getResultMap(nestedResultMapId); handleResultSet(rsw, resultMap, null, parentMapping); } rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; } } return collapseSingleResultList(multipleResults);} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package app.pooi.common.encrypt;import app.pooi.common.encrypt.anno.CipherSpi;import app.pooi.common.encrypt.anno.Encrypted;import lombok.Getter;import org.apache.ibatis.executor.resultset.ResultSetHandler;import org.apache.ibatis.plugin.*;import org.apache.ibatis.reflection.MetaObject;import org.apache.ibatis.reflection.SystemMetaObject;import java.lang.reflect.Field;import java.sql.Statement;import java.util.*;import java.util.function.Function;import java.util.logging.Logger;import java.util.stream.Collectors;@Intercepts({ @Signature(type = ResultSetHandler.class, method = &quot;handleResultSets&quot;, args = {Statement.class}),})public class DecryptInterceptor implements Interceptor { private static final Logger logger = Logger.getLogger(DecryptInterceptor.class.getName()); private CipherSpi cipherSpi; public DecryptInterceptor(CipherSpi cipherSpi) { this.cipherSpi = cipherSpi; } @Override public Object intercept(Invocation invocation) throws Throwable { final Object proceed = invocation.proceed(); if (proceed == null) { return proceed; } List&lt;?&gt; results = (List&lt;?&gt;) proceed; if (results.isEmpty()) { return proceed; } final Object first = results.iterator().next(); final Class&lt;?&gt; modelClazz = first.getClass(); final List&lt;String&gt; decryptFields = getDecryptFields(modelClazz); if (decryptFields.isEmpty()) { return proceed; } final List&lt;List&lt;String&gt;&gt; secret = Flux.fromIterable(results) .map(SystemMetaObject::forObject) .flatMapIterable(mo -&gt; decryptFields.stream().map(mo::getValue).collect(Collectors.toList())) .cast(String.class) .buffer(1000) .collectList() .block(); final Map&lt;String, String&gt; secretMap = secret.stream() .map(secrets -&gt; { try { return cipherSpi.batchDecrypt(secrets); } catch (Exception e) { e.printStackTrace(); return Maps.&lt;String, String&gt;newHashMap(); } }).reduce(Maps.newHashMap(), (m1, m2) -&gt; { m1.putAll(m2); return m1; }); secretMap.put(&quot;&quot;, &quot;0&quot;); for (Object r : results) { final MetaObject metaObject = SystemMetaObject.forObject(r); decryptFields.forEach(f -&gt; metaObject.setValue(f, secretMap.get(metaObject.getValue(f)))); } return results; } @NotNull private List&lt;String&gt; getDecryptFields(Class&lt;?&gt; modelClazz) { return Arrays.stream(modelClazz.getDeclaredFields()) .filter(f -&gt; f.getAnnotation(Decrypted.class) != null) .filter(f -&gt; { boolean isString = f.getType() == String.class; if (!isString) { logger.warning(f.getName() + &quot;is not String, actual type is &quot; + f.getType().getSimpleName() + &quot; ignored&quot;); } return isString; }) .map(Field::getName) .collect(Collectors.toList()); } @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } @Override public void setProperties(Properties properties) { }}@Getterclass Tuple2&lt;T1, T2&gt; { private final T1 t1; private final T2 t2; Tuple2(T1 t1, T2 t2) { this.t1 = t1; this.t2 = t2; } static &lt;T1, T2&gt; Tuple2&lt;T1, T2&gt; of(T1 t1, T2 t2) { return new Tuple2&lt;&gt;(t1, t2); }}","link":"/2019/04/04/2019/2019-04-04-Mybatis_ResultSetHandler%E5%AE%9E%E8%B7%B5-%E7%BB%AD/"},{"title":"resilience4j-retry源码阅读","text":"resilience4j 源码还是比较清晰简单的，比较适合阅读。 放一张主要类的结构图： Retry入口Retry接口是提供重试功能的入口，主要提供了方法模版，具体校验结构，失败后处理由Context子类实现。 1234567891011121314151617181920212223/** * Creates a retryable supplier. * * @param retry the retry context * @param supplier the original function * @param &lt;T&gt; the type of results supplied by this supplier * @return a retryable function */static &lt;T&gt; Supplier&lt;T&gt; decorateSupplier(Retry retry, Supplier&lt;T&gt; supplier) { return () -&gt; { Retry.Context&lt;T&gt; context = retry.context(); do try { T result = supplier.get(); final boolean validationOfResult = context.onResult(result); if (!validationOfResult) { context.onSuccess(); return result; } } catch (RuntimeException runtimeException) { context.onRuntimeError(runtimeException); } while (true); };} 这里摘抄了一段核心代码，作用是循环直到context.onResult(result)返回true为止，需要留意context.onResult/onRuntimeError/onError可能执行多次， onSuccess只会执行一次，这里每次进入重试都是一个新的context对象。 Retry.ContextImpl1234567891011121314151617181920212223public boolean onResult(T result) { if (null != resultPredicate &amp;&amp; resultPredicate.test(result)) { int currentNumOfAttempts = numOfAttempts.incrementAndGet(); if (currentNumOfAttempts &gt;= maxAttempts) { return false; } else { waitIntervalAfterFailure(currentNumOfAttempts, null); return true; } } return false;}public void onRuntimeError(RuntimeException runtimeException) { if (exceptionPredicate.test(runtimeException)) { lastRuntimeException.set(runtimeException); throwOrSleepAfterRuntimeException(); } else { failedWithoutRetryCounter.increment(); publishRetryEvent(() -&gt; new RetryOnIgnoredErrorEvent(getName(), runtimeException)); throw runtimeException; }} 先关注onResult，它负责判断是否需要继续重试，如果通过校验或者重试超过此数，会停止重试。 onRuntimeError/onError, 负责把catch的异常存储在lastRuntimeException中。 12345678910public void onSuccess() { int currentNumOfAttempts = numOfAttempts.get(); if (currentNumOfAttempts &gt; 0) { succeededAfterRetryCounter.increment(); Throwable throwable = Option.of(lastException.get()).getOrElse(lastRuntimeException.get()); publishRetryEvent(() -&gt; new RetryOnSuccessEvent(getName(), currentNumOfAttempts, throwable)); } else { succeededWithoutRetryCounter.increment(); }} onSuccess负责统计和发送事件。 总结总体来说retry比较简单，需要注意的点有一个如果设置了结果校验，如果一直校验不通过，将返回未通过的结果，而不是返回失败。","link":"/2019/04/18/2019/2019-04-18-resilience4j-retry%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"title":"[项目] 根据权限查询时避免角色切换遇到的坑","text":"前情概要 1. 问题背景使用多个角色查询列表时，会遇到两个维度的不同点： 行维度：多个角色能够看到行的并集，sql需要多次查询取并集，之后还要去重分页排序 列维度：如果不同角色可见列不同，计算出当前行能看到列的并集 举一个例子： 假设存在一个登录员工拥有两个角色： 长期激励负责人：能看到拥有长期激励的人（行维度），能看到基本信息和长期激励信息（列维度） 薪酬负责人：能看到低职级的人（行维度），能看到基本信息和薪酬信息（列维度） 那么，在列表中他能看见： 基本信息 薪酬信息 长期激励信息 低职级/无长期激励 √ √ x 低职级/长期激励 √ √ √ 高职级/无长期激励 x x x 高职级/长期激励 √ x √ 2. 实际遇到的问题（困难重重）基本思路已经在前期概要里介绍，本人已经实践了一段时间，挖了两个深坑正在解决中。 性能问题（已解决）最开始的实现中数据是一条一条读取的，同时薪酬字段属于加密信息，使用了第三方微服务提供解密，读取字段多+解密字段多 导致了在百条分页的情况下接口在超时的边缘不断试探。。。 解决方案： 合并查询sql,批量查询数据 合并解密请求,批量调用解密微服务 因为之前为了方便我们解密使用了mybatis的TypeHandler做到字段隐式加解密，目前我们的做法是对于单条数据的加解密，还是保持原来的typeHandler做法，而对批量数据处理，重新写一套数据实体，同时使用mybatis的拦截器对查询的批量数据做批量解密的处理。具体做法可以参见我的另一片文章：【片段】 Mybatis ResultSetHandler 实践-续 批量查询带来的问题批量查询返回的列表中列字段都是一致的，而我们的需求是不同的行能看见不同的列字段，把批量查询出来的列表直接返回是有问题的，这个问题因为疏忽导致了线上的一次故障。 所以目前的思路是先做一次数据批量预取，之后在对列字段做处理，隐藏掉不能看见的字段。 3. 总结没有想到当时想解决权限查询时避免角色切换这个问题时会遇到这么多困难，想法是正确的，在实际执行时还是困难重重。值得欣慰的在最开始的时候思路和方向都是正确的，同时也把其中遇到的各种问题和心得记录了下来，经过层层积累，才到达现在的高度。 []: https://blog.yamato.moe/2018/11/06/2018-11-06-biz/ “根据权限查询时避免角色切换的一种思路”[]: https://blog.yamato.moe/2019/04/04/Mybatis%20ResultSetHandler_2019-04-04%20%E7%BB%AD/ “【片段】 Mybatis ResultSetHandler 实践-续”[]: https://blog.yamato.moe/2019/01/09/Mybatis%20ResultSetHandler_2019-01-09/ “【片段】 Mybatis ResultSetHandler 实践”","link":"/2019/05/17/2019/2019-05-17-%E6%A0%B9%E6%8D%AE%E6%9D%83%E9%99%90%E6%9F%A5%E8%AF%A2%E6%97%B6%E9%81%BF%E5%85%8D%E8%A7%92%E8%89%B2%E5%88%87%E6%8D%A2%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"},{"title":"IO Modle","text":"操作系统IO模型与Java IOJava IO模型和操作系统IO模型息息相关，之前阻塞/非阻塞，同步/非同步之间的关系一直分不清，所以很有必要了解下操作系统(linux)提供了哪些接口来进行IO。目前我们只需要了解即可，使用相关可以直接查看java io教程。 最基础的知识以使用IO读取数据为例，一般操作系统分为两个独立的阶段进行操作： 等待数据准备完成，可以是从磁盘拷贝到内核空间，或者是网卡接受到数据后拷贝到内核空间。 从内核空间将数据拷贝至请求数据的进程。如果是java可能还需从进程拷贝至jvm堆内存。 Blocking I/O Model这个是最常用的模型，望文生义就是阻塞IO，进行IO的两个阶段会都阻塞程序，直到读取到数据或者返回错误才会返回。 具体来说，通过调用系统recvfrom函数，而recvfrom函数会等到出错或者把数据拷贝到进程完成时才会返回。之后我们程序只需要处理错误或者处理数据就可以了。 阻塞模型对应java中绝大部分IO操作，比如网络请求api，io stream api，该模型优点在于简单直观，缺点在长时间阻塞很难支持大量并发IO请求。 Nonblocking I/O Model该模型在java中没有对应，所以这里只做简单介绍。 使用轮询方式调用系统recvfrom函数，recvfrom函数在第一阶段完成前一直返回错误，直到第一阶段完成后，阻塞至第二阶段完成。 这个模型稍显鸡肋，特点是在第一阶段是非阻塞的（进程不会被切换），代码相比阻塞模型来说也更复杂。 I/O Multiplexing Model非常著名的IO模型，可以支持大量并发IO。通过调用select或者pull并阻塞，而不是在实际调用系统IO时阻塞。使用select阻塞在第一阶段和Blocking I/O的阻塞不太一样，Blocking I/O阻塞在当前IO操作第一阶段，而I/O复用则可以注册多个I/O在select函数，当有一个I/O就绪时select函数就会返回，如果所有I/O处于第一阶段阻塞状态则select函数阻塞。 相比较Blocking I/O Model和Nonblocking I/O Model，I/O Multiplexing Model明显能在短时间内处理更多的I/O。如果使用多线程+Blocking I/O Model也能达到类似的效果，但是有可能消耗过多线程资源。 I/O Multiplexing Model对应java NIO的Selector等api Signal-Driven I/O Model该模型在java中没有对应，所以这里只做简单介绍。 该模型特点是第一阶段调用sigaction函数非阻塞返回，在第一阶段完成后发送信号SIGIO至进程，之后在signal handler中进行第二阶段处理。相当于对Nonblocking I/O Model的一种改进。 Asynchronous I/O ModelAsynchronous I/O Model相比较Signal-Driven I/O Model的区别在于通知的时机不同：Asynchronous I/O Model在第一和第二阶段都完成时通过信号通知进程操作完成。 Asynchronous I/O Model对应java中AsynchronousSocketChannel，AsynchronousServerSocketChannel 和 AsynchronousFileChannel等api。 各个模型比较","link":"/2019/05/20/2019/2019-05-20-IO-Modle/"},{"title":"LeetCode二叉树基础算法","text":"树的高度104. Maximum Depth of Binary Tree (Easy) 递归计算二叉树左右两边深度，取最大值。 12345678910111213141516171819/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int maxDepth(TreeNode root) { if (root == null) return 0; int left = maxDepth(root.left); int right = maxDepth(root.right); return Math.max(left, right) + 1; }} 平衡树110. Balanced Binary Tree (Easy) 递归遍历二叉树左右子树深度 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private boolean balance = true; public boolean isBalanced(TreeNode root) { visitTree(root); return balance; } private int visitTree(TreeNode root) { if (root == null) return 0; int left = visitTree(root.left); int right = visitTree(root.right); if (Math.abs(left - right) &gt; 1 ) this.balance = false; return Math.max(left, right) + 1; }} 两节点的最长路径543. Diameter of Binary Tree (Easy) 递归遍历二叉树左右子树深度， 路径就是两边子树深度之和 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private int max; public int diameterOfBinaryTree(TreeNode root) { deep(root); return max; } private int deep(TreeNode root) { if (root == null) return 0; int left = deep(root.left); int right = deep(root.right); max = Math.max(max,left+right); return Math.max(left, right) + 1; }} 翻转树226. Invert Binary Tree (Easy) 递归交换左右子树的引用 123456789101112131415161718/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode invertTree(TreeNode root) { if (root == null) return root; TreeNode right =root.right; root.right = invertTree(root.left); root.left = invertTree(right); return root; }} 归并两棵树617. Merge Two Binary Trees (Easy) 递归时如果其中一个节点是空，可以直接复用该节点。如果新建节点，需要拷贝节点的左右子树引用，递归时会用到。 1234567891011121314151617181920/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode mergeTrees(TreeNode t1, TreeNode t2) { if (t1 == null &amp;&amp; t2 == null ) return null; if (t1 == null) return t2; if (t2 == null) return t1; TreeNode root = new TreeNode(t1.val + t2.val); root.left = mergeTrees(t1.left, t2.left); root.right = mergeTrees(t1.right, t2.right); return root; }} 判断路径和是否等于一个数Leetcode : 112. Path Sum (Easy) 递归查询子树和是否等于目标和 12345678910111213141516/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public boolean hasPathSum(TreeNode root, int sum) { if (root == null) return false; if (root.val == sum &amp;&amp; root.left == null &amp;&amp; root.right == null) return true; return hasPathSum(root.left, sum - root.val) || hasPathSum(root.right, sum - root.val); }} 统计路径和等于一个数的路径数量437. Path Sum III (Easy) 双层递归 以当前节点为起点统计路径和 当前节点以下节点为起点统计路径和 以root为根节点的路径数量= 以root为起点统计路径和+root左节点为起点统计路径和+root右节点为起点统计路径和 123456789101112131415161718192021222324/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int pathSum(TreeNode root, int sum) { if (root == null) return 0; //结果数 等于 以当前root为父节点和 root以下为父节点结果数之和 return sum(root, sum) + pathSum(root.left, sum) + pathSum(root.right, sum); } // 计算以当前node为父节点能都多少路径数 private int sum(TreeNode node, int sum) { if (node == null) return 0; int count = 0; if (node.val == sum) count++; count += sum(node.left, sum - node.val) + sum(node.right, sum - node.val); return count; }} 子树572. Subtree of Another Tree (Easy) 12345678910111213141516171819202122/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public boolean isSubtree(TreeNode s, TreeNode t) { if (s == null) return false; return isSubRoot(s, t) || isSubtree(s.left, t) || isSubtree(s.right, t); } public boolean isSubRoot(TreeNode node, TreeNode t) { if (node == null &amp;&amp; t == null) return true; if (node == null || t == null) return false; if (node.val != t.val) return false; return isSubRoot(node.left, t.left) &amp;&amp; isSubRoot(node.right, t.right); }} 树的对称101. Symmetric Tree (Easy) 12345678910111213141516171819202122/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public boolean isSymmetric(TreeNode root) { if (root == null) return true; return isSymmetric(root.left, root.right); } public boolean isSymmetric(TreeNode left, TreeNode right) { if (left == null &amp;&amp; right == null) return true; if (left == null || right == null) return false; if (left.val != right.val) return false; return isSymmetric(left.left, right.right) &amp;&amp; isSymmetric(left.right, right.left); }} 最小路径111. Minimum Depth of Binary Tree (Easy) 和最大路径类似 123456789101112131415161718/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int minDepth(TreeNode root) { if (root == null) return 0; int left = minDepth(root.left); int right = minDepth(root.right); if (left == 0 || right == 0) return left + right + 1; return Math.min(left, right) + 1; }} 统计左叶子节点的和404. Sum of Left Leaves (Easy) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int sumOfLeftLeaves(TreeNode root) { if (root == null) return 0; if (root.left != null &amp;&amp; root.left.left == null &amp;&amp; root.left.right == null) return root.left.val + sumOfLeftLeaves(root.right); return sumOfLeftLeaves(root.left) + sumOfLeftLeaves(root.right); }}````#### 相同节点值的最大路径长度[687. Longest Univalue Path (Easy)](https://leetcode.com/problems/longest-univalue-path/)递归查找左右子树相同节点值最大路径，最大路径的计算：如果相等路径+1，如果不相等置为0。```java/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private int path = 0; public int longestUnivaluePath(TreeNode root) { visit(root); return path; } private int visit(TreeNode root) { if (root == null) return 0; int left = visit(root.left); int right = visit(root.right); left = (root.left != null &amp;&amp; root.val == root.left.val) ? left + 1 : 0; right = (root.right != null &amp;&amp; root.val == root.right.val)? right + 1 : 0; path = Math.max(path, left+right); return Math.max(left, right ); }} 间隔遍历337. House Robber III (Medium) 递归查询两种情况 如果从当前节点开始 从当前节点的子节点开始 1234567891011121314151617181920/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int rob(TreeNode root) { if (root == null) return 0; int val1 = root.val, val2 = 0; if (root.left != null) val1+= rob(root.left.left) + rob(root.left.right); if (root.right != null) val1+= rob(root.right.left) + rob(root.right.right); val2 = rob(root.left) + rob(root.right); return Math.max(val1, val2); }} 找出二叉树中第二小的节点Second Minimum Node In a Binary Tree (Easy) 第二小节点在子树节点上，如果子树值与根节点相等，继续向下查找 123456789101112131415161718192021/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int findSecondMinimumValue(TreeNode root) { if (root == null) return -1; if (root.left == null) return -1; int left = root.left.val, right = root.right.val; if (root.val == root.left.val) left = findSecondMinimumValue(root.left); if (root.val == root.right.val) right = findSecondMinimumValue(root.right); if (left != -1 &amp;&amp; right != -1) return Math.min(left, right); if (left &gt; -1) return left; return right; }} 二叉树的层平均值637. Average of Levels in Binary Tree (Easy) BFS 123456789101112131415161718192021222324252627282930/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public List&lt;Double&gt; averageOfLevels(TreeNode root) { List&lt;Double&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while(!queue.isEmpty()) { int count = queue.size(); double sum = 0d; for(int i = 0; i &lt; count; i++) { TreeNode node = queue.poll(); sum+= node.val; if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } ret.add(sum/count); } return ret; }} 找树左下角的值513. Find Bottom Left Tree Value (Easy) DFS 123456789101112131415161718192021222324252627282930/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private int val = 0; public int findBottomLeftValue(TreeNode root) { if (root == null) return val; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while(!queue.isEmpty()) { // 这一行的数量 int count = queue.size(); for (int i = 0; i &lt; count; i++) { TreeNode node = queue.poll(); if(i == 0) val = node.val; if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } } return val; }} 非递归实现二叉树的后序遍历入栈条件： 未访问过该节点出栈条件： 访问过该节点 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private List&lt;Integer&gt; res = new LinkedList&lt;&gt;(); private Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); private Set&lt;TreeNode&gt; visited = new HashSet&lt;&gt;(); public List&lt;Integer&gt; postorderTraversal(TreeNode root) { if (root == null) return res; stack.push(root); while (!stack.isEmpty()) { TreeNode node = stack.peek(); if ((node.left == null &amp;&amp; node.right == null) || visited.contains(node)) { TreeNode i = stack.pop(); res.add(i.val); } else { visited.add(node); if (node.right != null) stack.push(node.right); if (node.left != null) stack.push(node.left); } } return res; } private void visit(TreeNode root) { if(root == null) return; visit(root.left); visit(root.right); res.add(root.val); }} 非递归实现二叉树的前序遍历入栈条件： 无出栈条件： 直接出栈 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private List&lt;Integer&gt; res = new LinkedList&lt;&gt;(); private Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); public List&lt;Integer&gt; preorderTraversal(TreeNode root) { if (root == null) return res; stack.push(root); while (!stack.isEmpty()) { TreeNode node = stack.pop(); res.add(node.val); if (node.right != null) stack.push(node.right); if (node.left != null) stack.push(node.left); } return res; }} 非递归实现二叉树的中序遍历入栈条件： 未访问过该节点出栈条件： 访问过该节点入栈顺序: right -&gt; middle -&gt; left 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private List&lt;Integer&gt; res = new LinkedList&lt;&gt;(); private Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); private Set&lt;TreeNode&gt; visited = new HashSet&lt;&gt;(); public List&lt;Integer&gt; inorderTraversal(TreeNode root) { if (root == null) return res; push(root); while (!stack.isEmpty()) { TreeNode node = stack.pop(); if ((node.left == null &amp;&amp; node.right == null) || visited.contains(node)) { res.add(node.val); } else { push(node); } } return res; } private void push(TreeNode root) { if (root == null) return; visited.add(root); if (root.right != null) stack.push(root.right); stack.push(root); if (root.left != null) stack.push(root.left); }}","link":"/2019/06/15/2019/2019-06-15-LeetCode%E4%BA%8C%E5%8F%89%E6%A0%91%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"title":"季度总结 如何管理自我时间","text":"最近这个季度最近比较忙，算了下自己可以利用的空闲时间，忙时一天可能只有1到3个小时空闲时间，甚至一天没有空余时间。一周大约只有30小时时间是可以利用的，如果算上玩手机时间只会更短，如果再把这些时间再浪费掉，可能最近半年的成长就只有一些项目经验而已了。所幸平常关注的博客和《软技能》这本书里有提及一些关于自我时间管理相关内容，我简单实践了2个月，分享下这方面的心得感悟。 计划和休息《软技能》中作者是如何做计划的？ 季度计划 明确宏观目标，以及如何实现 月计划 估算当月能完成多少工作量 周计划 为每周安排必须完成的强制性任务 日计划 排除干扰，按需调整 休息 每隔一段时间休息，只做强制性任务 很惭愧，工作刚开始一两年我少有计划，单纯凭借好奇心学习到了不少东西。大约从去年写年度总结开始才刚刚做一些计划。目前我使用微软to-do跟踪自己的计划进度和deadline效果显著，治好了我的拖延症。 简单来说《软技能》中阐述的几个观点我感觉十分受益： 要有计划 完成计划时保持专注 使用番茄工作法可以保证保证一段时间的专注， 同时还可以确定自己的工作效率， 总结不足提高自身效率，从而帮助自己精确且高效的指定计划 只有你完成了计划的工作，接下来的休息时间才能安心 这边年读书情况这半年看的书比较少，但是刷题和博客总结写的多了些 技术类：《sql反模式》推荐， 应该叫数据库结构设计的最佳实践《软技能，代码之外的生存指南》 有很多事比代码更重要的多，推荐 心理类：《你的灯亮着吗》 解决问题前，先要搞清楚问题的本质。 一般般","link":"/2019/09/24/2019/2019-06-24-%E5%AD%A3%E5%BA%A6%E6%80%BB%E7%BB%93_%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E8%87%AA%E6%88%91%E6%97%B6%E9%97%B4/"},{"title":"LeetCode 二叉树排序树基础算法","text":"修剪二叉搜索树12345678910111213141516171819/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode trimBST(TreeNode root, int L, int R) { if (root == null) return null; if (root.val &lt; L) return trimBST(root.right, L, R); if (root.val &gt; R) return trimBST(root.left, L, R); root.left = trimBST(root.left, L, R); root.right = trimBST(root.right, L, R); return root; }} 二叉搜索树中第K小的元素12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private int cnt; private int val; public int kthSmallest(TreeNode root, int k) { search(root, k); return val; } private void search(TreeNode root, int k) { if (root == null) return; // kthSmallest(root.left, k); cnt++; if (cnt == k) { val = root.val; return; } kthSmallest(root.right, k); }} 把二叉搜索树转换为累加树1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private int sum; public TreeNode convertBST(TreeNode root) { // 中序遍历 但是是从右往左遍历 // visit(root); return root; } private void visit(TreeNode root) { if (root == null) return; visit(root.right); sum += root.val; root.val = sum; visit(root.left); }} 二叉搜索树的最近公共祖先12345678910111213141516171819/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { // 公共祖先在左边 if (root.val &gt; p.val &amp;&amp; root.val &gt; q.val) return lowestCommonAncestor(root.left, p, q); // 公共祖先在右边 if (root.val &lt; p.val &amp;&amp; root.val &lt; q.val) return lowestCommonAncestor(root.right, p, q); // 公共祖先在这 return root; }} 二叉树的最近公共祖先12345678910111213141516171819202122/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if (root == null || p == root || q == root) return root; TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); // 左右都是父节点， 上一级就是公共父节点 if(left != null &amp;&amp; right != null) return root; if (left == null &amp;&amp; right == null) return null; if (left != null) return left; return right; }} 将有序数组转换为二叉搜索树二叉树中序遍历 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode sortedArrayToBST(int[] nums) { return build(nums, 0, nums.length -1); } private TreeNode build(int[] nums, int start, int end) { if(start&gt; end) return null; TreeNode node = new TreeNode(nums[(start+end)/2]); node.left = build(nums, start, (start+end)/2 -1); node.right = build(nums, (start+end)/2+1, end); return node; }} 有序链表转换二叉搜索树链表转数组 1234567891011121314151617181920212223242526272829303132333435363738394041/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } *//** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode sortedListToBST(ListNode head) { List&lt;Integer&gt; list = new LinkedList(); ListNode now = head; while (now != null) { list.add(now.val); now = now.next; } return build(list, 0, list.size() - 1); } private TreeNode build(List&lt;Integer&gt; nums, int start, int end) { if(start&gt; end) return null; TreeNode node = new TreeNode(nums.get((start+end)/2)); node.left = build(nums, start, (start+end)/2 -1); node.right = build(nums, (start+end)/2+1, end); return node; }} 还可以使用双指针找到链表中间节点，缺点是重复遍历节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } *//** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode sortedListToBST(ListNode head) {// List&lt;Integer&gt; list = new LinkedList();// ListNode now = head;// while (now != null) {// list.add(now.val);// now = now.next;// } // return build(list, 0, list.size() - 1); return sortedListToBST(head, null); } private TreeNode sortedListToBST(ListNode head, ListNode tail) { if (head == tail) return null; ListNode mid = head, end = head; while (end != tail &amp;&amp; end.next != tail) { mid = mid.next; end = end.next.next; } TreeNode root = new TreeNode(mid.val); root.right = sortedListToBST(mid.next, tail); root.left = sortedListToBST(head, mid); return root; } private TreeNode build(List&lt;Integer&gt; nums, int start, int end) { if(start&gt; end) return null; TreeNode node = new TreeNode(nums.get((start+end)/2)); node.left = build(nums, start, (start+end)/2 -1); node.right = build(nums, (start+end)/2+1, end); return node; } } 两数之和 IV - 输入 BST自己写两次遍历搜索二叉树，注意要排除自身节点 123456789101112131415161718192021222324252627282930313233343536/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private boolean res; private TreeNode r; private TreeNode current; public boolean findTarget(TreeNode root, int k) { r = root; visit(root, k); return res; } private void visit(TreeNode root, int val) { if (root == null) return; visit(root.left, val); current = root; if (find(r, val - root.val)) {res = true; return;} visit(root.right, val); } private boolean find(TreeNode root, int value) { if (root == null) return false; if (root == current) return false; if (root.val == value ) return true; return (value &gt; root.val) ? find(root.right, value): find(root.left, value); }} 正经思路， 中序遍历转化为排序数组， 使用双指针查找 1234567891011121314151617181920212223242526272829303132333435363738/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { private List&lt;Integer&gt; res = new ArrayList&lt;&gt;(64); public boolean findTarget(TreeNode root, int k) { visitTree(root); int low = 0, high = res.size() - 1; while (low &lt; high) { int sum = res.get(low) + res.get(high); if (sum == k) return true; if (sum &lt; k) low++; else high--; } return false; } private void visitTree(TreeNode root) { if (root == null) return; visitTree(root.left); res.add(root.val); visitTree(root.right); }}","link":"/2019/06/15/2019/2019-06-30-LeetCode_%E4%BA%8C%E5%8F%89%E6%A0%91%E6%8E%92%E5%BA%8F%E6%A0%91%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"title":"[项目] 多角色权限展示数据的一种实现","text":"多角色权限如果遇到不同角色能看到不同的列可以怎么做 逐行读取 最简单的解决方法，实现简单。但是在微服务中调用接口次数太多，性能很差。 批量读取 实现较复杂，但是性能好很多，下面主要介绍这种方法的思路 批量读取以分页读取数据为例： 读取第一页数据，包含需要展示数据的id和所属权限（多个） 为什么需要所属权限这个字段呢？ 因为决定能否看到这行是有你所拥有的所有权限决定的，而决定能否看到哪个列是由这行所拥有的权限决定的。 如何获取该行所拥有的权限呢，我的做法是分不同的权限查询结果通过union 组合起来 将第一页数据原始顺序保存， 然后按行拥有权限分组 记录原始顺序是因为后面分组后会打乱， 为什么要分组？分组后同样的查询才能聚合在一起，可以简化代码 根据权限分组多次查询所需要的字段，然后将查询结果合并 这里我使用的graphql来选择需要查询的字段 最后还原成原来的顺序 可以使用guava Ordering工具类方便生成Compartor []: https://blog.yamato.moe/2018/11/06/2018-11-06-biz/ “根据权限查询时避免角色切换的一种思路”[]: https://blog.yamato.moe/2019/04/04/Mybatis%20ResultSetHandler_2019-04-04%20%E7%BB%AD/ “【片段】 Mybatis ResultSetHandler 实践-续”[]: https://blog.yamato.moe/2019/01/09/Mybatis%20ResultSetHandler_2019-01-09/ “【片段】 Mybatis ResultSetHandler 实践”","link":"/2019/07/29/2019/2019-07-29-%E5%A4%9A%E8%A7%92%E8%89%B2%E6%9D%83%E9%99%90%E5%B1%95%E7%A4%BA%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E7%A7%8D%E5%AE%9E%E7%8E%B0/"},{"title":"LeetCode 最长回文子串算法","text":"Manacher 算法 容易理解，实现起来也没什么大坑，复杂度还是 O(n)的， 花半个小时实现下很有意思 12345678910111213141516171819202122232425262728293031323334353637class Solution { public String longestPalindrome(String s) { StringBuilder sb = new StringBuilder(2 + 2 * s.length()); sb.append(&quot;^&quot;); for (int i = 0; i &lt; s.length(); i++) { sb.append(&quot;#&quot;).append(s.charAt(i)); } sb.append(&quot;#$&quot;); String s2 = sb.toString(); int maxStart = 1, max = 0, rC = 1, rR = 1; int[] p = new int[s2.length()]; for (int i = 1; i &lt; s2.length() - 1; i++ ) { p[i] = i &lt; rR ? Math.min(p[2 * rC - i], rR - i) : 0; while (s2.charAt(i+p[i]+1) == s2.charAt(i - p[i] - 1)) { p[i] = p[i]+1; } if (i + p[i] &gt; rR) { rC = i; rR = i + p[i]; } if (p[i] &gt; max) { maxStart = i - p[i]; max = p[i]; } } return s2.substring(maxStart,maxStart + 2*max+1).replace(&quot;#&quot;, &quot;&quot;); }}","link":"/2019/08/10/2019/2019-08-10-LeetCode_%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2%E7%AE%97%E6%B3%95/"},{"title":"LeetCode两个经典的排序算法","text":"LeetCode两个经典的排序算法这回是标题党， 记录下两个分而治之的排序算法（手写），分而治之的算法很容易改造成并行算法，肯定是未来的潮流， leetcode已通过， 两个算法都使用了原地(inplace)更新。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394class Solution { public List&lt;Integer&gt; sortArray(int[] nums) { // merge(nums, 0, nums.length - 1); sort(nums, 0, nums.length - 1); return IntStream.of(nums).boxed().collect(Collectors.toList()); } //-------------------归并排序-------------------// private void merge(int[] nums, int start, int end) { if (start &gt;= end) return; int midIdx = start + (end - start) / 2; merge(nums, start, midIdx); merge(nums, midIdx+1, end); concat(nums, start, midIdx, end); } private void concat(int[] nums, int start, int midIdx, int end) { int[] tmp = new int[end - start + 1]; int lp = start, rp = midIdx + 1, i = 0; while (lp &lt;= midIdx &amp;&amp; rp &lt;= end) { tmp[i++] = nums[lp] &lt; nums[rp] ? nums[lp++] : nums[rp++]; } while (lp &lt;= midIdx) { tmp[i++] = nums[lp++]; } while (rp &lt;= end) { tmp[i++] = nums[rp++]; } System.arraycopy(tmp, 0, nums, start, tmp.length); } // ------------------- 归并排序 链表 ---------------------// class Solution { public ListNode mergeKLists(ListNode[] lists) { if (lists.length == 0) return null; return merge(lists, 0 , lists.length - 1); } private ListNode merge(ListNode[] lists, int low, int high) { if (low == high) return lists[low]; int mid = (high - low) / 2 + low; return mergeLists( merge(lists, low, mid), merge(lists, mid+1, high)); } public ListNode mergeLists(ListNode node1, ListNode node2) { if (node1 == null) return node2; if (node2 == null) return node1; if (node1.val &lt; node2.val) { node1.next = mergeLists(node1.next, node2); return node1; } else { node2.next = mergeLists(node1, node2.next); return node2; } } } //-------------------快速排序-------------------// private void sort(int[] nums, int start, int end) { if (start &gt;= end) return; int bIdx = partition(nums, start, end); sort(nums, start, bIdx - 1); sort(nums, bIdx + 1, end); } private int partition(int[] nums, int start, int end) { int idx = start, base = nums[end]; for (int i = start; i &lt; end; i++) { if (nums[i] &lt; base) { swap(nums, idx++, i); } } swap(nums, idx, end); return idx; } private void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; }}","link":"/2019/11/20/2019/2019-11-20-LeetCode_%E4%B8%A4%E4%B8%AA%E7%BB%8F%E5%85%B8%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"title":"NoSql相对于关系型数据库的优势","text":"使用 NoSQL 提升写入性能数据库系统大多使用的是传统的机械磁盘，对于机械磁盘的访问方式有两种：一种是随机 IO；另一种是顺序 IO。随机 IO 就需要花费时间做昂贵的磁盘寻道，一般来说，它的读写效率要比顺序 IO 小两到三个数量级，所以我们想要提升写入的性能就要尽量减少随机 IO。 以 MySQL 的 InnoDB 存储引擎来说，更新 binlog、redolog、undolog 都是在做顺序 IO，而更新 datafile 和索引文件则是在做随机 IO，而为了减少随机 IO 的发生，关系数据库已经做了很多的优化，比如说写入时先写入内存，然后批量刷新到磁盘上，但是随机 IO 还是会发生。 索引在 InnoDB 引擎中是以 B+ 树方式来组织的，而 MySQL 主键是聚簇索引（一种索引类型，数据与索引数据放在一起），既然数据和索引数据放在一起，那么在数据插入或者更新的时候，我们需要找到要插入的位置，再把数据写到特定的位置上，这就产生了随机的 IO。而且一旦发生了页分裂，就不可避免会做数据的移动，也会极大地损耗写入性能。 NoSQL 数据库是怎么解决这个问题的呢？ 它们有多种的解决方式，这里我给你讲一种最常见的方案，就是很多 NoSQL 数据库都在使用的基于 LSM 树的存储引擎，这种算法使用最多，所以在这里着重剖析一下。 LSM 树（Log-Structured Merge Tree）牺牲了一定的读性能来换取写入数据的高性能，Hbase、Cassandra、LevelDB 都是用这种算法作为存储的引擎。 它的思想很简单，数据首先会写入到一个叫做 MemTable 的内存结构中，在 MemTable 中数据是按照写入的 Key 来排序的。为了防止 MemTable 里面的数据因为机器掉电或者重启而丢失，一般会通过写 Write Ahead Log 的方式将数据备份在磁盘上。 MemTable 在累积到一定规模时，它会被刷新生成一个新的文件，我们把这个文件叫做 SSTable（Sorted String Table）。当 SSTable 达到一定数量时，我们会将这些 SSTable 合并，减少文件的数量，因为 SSTable 都是有序的，所以合并的速度也很快。 当从 LSM 树里面读数据时，我们首先从 MemTable 中查找数据，如果数据没有找到，再从 SSTable 中查找数据。因为存储的数据都是有序的，所以查找的效率是很高的，只是因为数据被拆分成多个 SSTable，所以读取的效率会低于 B+ 树索引。 和 LSM 树类似的算法有很多，比如说 TokuDB 使用的名为 Fractal tree 的索引结构，它们的核心思想就是将随机 IO 变成顺序的 IO，从而提升写入的性能。 提升扩展性另外，在扩展性方面，很多 NoSQL 数据库也有着先天的优势。还是以你的垂直电商系统为例，你已经为你的电商系统增加了评论系统，开始你的评估比较乐观，觉得电商系统的评论量级不会增长很快，所以就为它分了 8 个库，每个库拆分成 16 张表。 但是评论系统上线之后，存储量级增长的异常迅猛，你不得不将数据库拆分成更多的库表，而数据也要重新迁移到新的库表中，过程非常痛苦，而且数据迁移的过程也非常容易出错。 这时，你考虑是否可以考虑使用 NoSQL 数据库来彻底解决扩展性的问题，经过调研你发现它们在设计之初就考虑到了分布式和大数据存储的场景，比如像 MongoDB 就有三个扩展性方面的特性。 其一是 Replica，也叫做副本集，你可以理解为主从分离，也就是通过将数据拷贝成多份来保证当主挂掉后数据不会丢失。同时呢，Replica 还可以分担读请求。Replica 中有主节点来承担写请求，并且把对数据变动记录到 oplog 里（类似于 binlog）；从节点接收到 oplog 后就会修改自身的数据以保持和主节点的一致。一旦主节点挂掉，MongoDB 会从从节点中选取一个节点成为主节点，可以继续提供写数据服务。 其二是 Shard，也叫做分片，你可以理解为分库分表，即将数据按照某种规则拆分成多份，存储在不同的机器上。MongoDB 的 Sharding 特性一般需要三个角色来支持，一个是 Shard Server，它是实际存储数据的节点，是一个独立的 Mongod 进程；二是 Config Server，也是一组 Mongod 进程，主要存储一些元信息，比如说哪些分片存储了哪些数据等；最后是 Route Server，它不实际存储数据，仅仅作为路由使用，它从 Config Server 中获取元信息后，将请求路由到正确的 Shard Server 中。 其三是负载均衡，就是当 MongoDB 发现 Shard 之间数据分布不均匀，会启动 Balancer 进程对数据做重新的分配，最终让不同 Shard Server 的数据可以尽量的均衡。当我们的 Shard Server 存储空间不足需要扩容时，数据会自动被移动到新的 Shard Server 上，减少了数据迁移和验证的成本。 你可以看到，NoSQL 数据库中内置的扩展性方面的特性可以让我们不再需要对数据库做分库分表和主从分离，也是对传统数据库一个良好的补充。","link":"/2019/12/01/2019/2019-12-01-NoSql%E7%9B%B8%E5%AF%B9%E4%BA%8E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%BC%98%E5%8A%BF/"},{"title":"缓存专题(三) Write Through（读穿 写穿）策略","text":"这个策略的核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据。这就好比你在汇报工作的时候只对你的直接上级汇报，再由你的直接上级汇报给他的上级，你是不能越级汇报的。 Write Through 的策略是这样的：先查询要写入的数据在缓存中是否已经存在，如果已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，如果缓存中数据不存在，我们把这种情况叫做“Write Miss（写失效）”。 一般来说，我们可以选择两种“Write Miss”方式：一个是“Write Allocate（按写分配）”，做法是写入缓存相应位置，再由缓存组件同步更新到数据库中；另一个是“No-write allocate（不按写分配）”，做法是不写入缓存中，而是直接更新到数据库中。 在 Write Through 策略中，我们一般选择“No-write allocate”方式，原因是无论采用哪种“Write Miss”方式，我们都需要同步将数据更新到数据库中，而“No-write allocate”方式相比“Write Allocate”还减少了一次缓存的写入，能够提升写入的性能。 Read Through 策略就简单一些，它的步骤是这样的：先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库中同步加载数据。 下面是 Read Through/Write Through 策略的示意图： Read Through/Write Through 策略的特点是由缓存节点而非用户来和数据库打交道，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库，或者自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略，比如说在上一节中提到的本地缓存 Guava Cache 中的 Loading Cache 就有 Read Through 策略的影子。 我们看到 Write Through 策略中写数据库是同步的，这对于性能来说会有比较大的影响，因为相比于写缓存，同步写数据库的延迟就要高很多了。那么我们可否异步地更新数据库？这就是我们接下来要提到的“Write Back”策略。 Write Back（写回）策略这个策略的核心思想是在写入数据时只写入缓存，并且把缓存块儿标记为“脏”的。而脏块儿只有被再次使用时才会将其中的数据写入到后端存储中。 需要注意的是，在“Write Miss”的情况下，我们采用的是“Write Allocate”的方式，也就是在写入后端存储的同时要写入缓存，这样我们在之后的写请求中都只需要更新缓存即可，而无需更新后端存储了，我将 Write back 策略的示意图放在了下面： 发现了吗？其实这种策略不能被应用到我们常用的数据库和缓存的场景中，它是计算机体系结构中的设计，比如我们在向磁盘中写数据时采用的就是这种策略。无论是操作系统层面的 Page Cache，还是日志的异步刷盘，亦或是消息队列中消息的异步写入磁盘，大多采用了这种策略。因为这个策略在性能上的优势毋庸置疑，它避免了直接写磁盘造成的随机写问题，毕竟写内存和写磁盘的随机 I/O 的延迟相差了几个数量级呢。 但因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏块儿数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 Page Cache 还没有来得及刷盘造成的。 当然，你依然可以在一些场景下使用这个策略，在使用时，我想给你的落地建议是：你在向低速设备写入数据的时候，可以在内存里先暂存一段时间的数据，甚至做一些统计汇总，然后定时地刷新到低速设备上。比如说，你在统计你的接口响应时间的时候，需要将每次请求的响应时间打印到日志中，然后监控系统收集日志后再做统计。但是如果每次请求都打印日志无疑会增加磁盘 I/O，那么不如把一段时间的响应时间暂存起来，经过简单的统计平均耗时，每个耗时区间的请求数量等等，然后定时地，批量地打印到日志中。","link":"/2019/12/01/2019/2019-12-01-Write_Through(%E8%AF%BB%E7%A9%BF%E5%86%99%E7%A9%BF)%E7%AD%96%E7%95%A5/"},{"title":"缓存专题(一) 缓存概述","text":"缓存分类在我们日常开发中，常见的缓存主要就是静态缓存、分布式缓存和热点本地缓存这三种。 静态缓存在 Web 1.0 时期是非常著名的，它一般通过生成 Velocity 模板或者静态 HTML 文件来实现静态缓存，在 Nginx 上部署静态缓存可以减少对于后台应用服务器的压力。例如，我们在做一些内容管理系统的时候，后台会录入很多的文章，前台在网站上展示文章内容，就像新浪，网易这种门户网站一样。 当然，我们也可以把文章录入到数据库里面，然后前端展示的时候穿透查询数据库来获取数据，但是这样会对数据库造成很大的压力。即使我们使用分布式缓存来挡读请求，但是对于像日均 PV 几十亿的大型门户网站来说，基于成本考虑仍然是不划算的。 所以我们的解决思路是每篇文章在录入的时候渲染成静态页面，放置在所有的前端 Nginx 或者 Squid 等 Web 服务器上，这样用户在访问的时候会优先访问 Web 服务器上的静态页面，在对旧的文章执行一定的清理策略后，依然可以保证 99% 以上的缓存命中率。 这种缓存只能针对静态数据来缓存，对于动态请求就无能为力了。那么我们如何针对动态请求做缓存呢？这时你就需要分布式缓存了。 分布式缓存的大名可谓是如雷贯耳了，我们平时耳熟能详的 Memcached、Redis 就是分布式缓存的典型例子。它们性能强劲，通过一些分布式的方案组成集群可以突破单机的限制。所以在整体架构中，分布式缓存承担着非常重要的角色。 对于静态的资源的缓存你可以选择静态缓存，对于动态的请求你可以选择分布式缓存，那么什么时候要考虑热点本地缓存呢？ 答案是当我们遇到极端的热点数据查询的时候。热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。 比如某一位明星在微博上有了热点话题，“吃瓜群众”会到他 (她) 的微博首页围观，这就会引发这个用户信息的热点查询。这些查询通常会命中某一个缓存节点或者某一个数据库分区，短时间内会形成极高的热点查询。 那么我们会在代码中使用一些本地缓存方案，如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中，优势是不需要跨网络调度，速度极快，所以可以来阻挡短时间内的热点查询。来看个例子。 比方说你的垂直电商系统的首页有一些推荐的商品，这些商品信息是由编辑在后台录入和变更。你分析编辑录入新的商品或者变更某个商品的信息后，在页面的展示是允许有一些延迟的，比如说 30 秒的延迟，并且首页请求量最大，即使使用分布式缓存也很难抗住，所以你决定使用 Guava Cache 来将所有的推荐商品的信息缓存起来，并且设置每隔 30 秒重新从数据库中加载最新的所有商品。 首先，我们初始化 Guava 的 Loading Cache： 123456789CacheBuilder&lt;String, List&lt;Product&gt;&gt; cacheBuilder = CacheBuilder.newBuilder().maximumSize(maxSize).recordStats(); // 设置缓存最大值cacheBuilder = cacheBuilder.refreshAfterWrite(30, TimeUnit.Seconds); // 设置刷新间隔 LoadingCache&lt;String, List&lt;Product&gt;&gt; cache = cacheBuilder.build(new CacheLoader&lt;String, List&lt;Product&gt;&gt;() { @Override public List&lt;Product&gt; load(String k) throws Exception { return productService.loadAll(); // 获取所有商品 }}); 这样，你在获取所有商品信息的时候可以调用 Loading Cache 的 get 方法，就可以优先从本地缓存中获取商品信息，如果本地缓存不存在，会使用 CacheLoader 中的逻辑从数据库中加载所有的商品。 由于本地缓存是部署在应用服务器中，而我们应用服务器通常会部署多台，当数据更新时，我们不能确定哪台服务器本地中了缓存，更新或者删除所有服务器的缓存不是一个好的选择，所以我们通常会等待缓存过期。因此，这种缓存的有效期很短，通常为分钟或者秒级别，以避免返回前端脏数据。 缓存的不足通过了解上面的内容，你不难发现，缓存的主要作用是提升访问速度，从而能够抗住更高的并发。那么，缓存是不是能够解决一切问题？显然不是。事物都是具有两面性的，缓存也不例外，我们要了解它的优势的同时也需要了解它有哪些不足，从而扬长避短，将它的作用发挥到最大。 首先，缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。这是因为缓存毕竟会受限于存储介质不可能缓存所有数据，那么当数据有热点属性的时候才能保证一定的缓存命中率。比如说类似微博、朋友圈这种 20% 的内容会占到 80% 的流量。所以，一旦当业务场景读少写多时或者没有明显热点时，比如在搜索的场景下，每个人搜索的词都会不同，没有明显的热点，那么这时缓存的作用就不明显了。 其次，缓存会给整体系统带来复杂度，并且会有数据不一致的风险。当更新数据库成功，更新缓存失败的场景下，缓存中就会存在脏数据。对于这种场景，我们可以考虑使用较短的过期时间或者手动清理的方式来解决。 再次，之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的。因此，我们在使用缓存的时候要做数据存储量级的评估，对于可预见的需要消耗极大存储成本的数据，要慎用缓存方案。同时，缓存一定要设置过期时间，这样可以保证缓存中的会是热点数据。 最后，缓存会给运维也带来一定的成本，运维需要对缓存组件有一定的了解，在排查问题的时候也多了一个组件需要考虑在内。 虽然有这么多的不足，但是缓存对于性能的提升是毋庸置疑的，我们在做架构设计的时候也需要把它考虑在内，只是在做具体方案的时候需要对缓存的设计有更细致的思考，才能最大化的发挥缓存的优势。","link":"/2019/12/01/2019/2019-12-01-%E7%BC%93%E5%AD%98%E4%B8%93%E9%A2%98(%E4%B8%80)_%E7%BC%93%E5%AD%98%E6%A6%82%E8%BF%B0/"},{"title":"缓存专题(二) Cache Aside（旁路缓存）策略","text":"我们来考虑一种最简单的业务场景，比方说在你的电商系统中有一个用户表，表中只有 ID 和年龄两个字段，缓存中我们以 ID 为 Key 存储用户的年龄信息。那么当我们要把 ID 为 1 的用户的年龄从 19 变更为 20，要如何做呢？ 你可能会产生这样的思路：先更新数据库中 ID 为 1 的记录，再更新缓存中 Key 为 1 的数据。 这个思路会造成缓存和数据库中的数据不一致。比如，A 请求将数据库中 ID 为 1 的用户年龄从 19 变更为 20，与此同时，请求 B 也开始更新 ID 为 1 的用户数据，它把数据库中记录的年龄变更为 21，然后变更缓存中的用户年龄为 21。紧接着，A 请求开始更新缓存数据，它会把缓存中的年龄变更为 20。此时，数据库中用户年龄是 21，而缓存中的用户年龄却是 20。 为什么产生这个问题呢？因为变更数据库和变更缓存是两个独立的操作，而我们并没有对操作做任何的并发控制。那么当两个线程并发更新它们的时候，就会因为写入顺序的不同造成数据的不一致。 另外，直接更新缓存还存在另外一个问题就是丢失更新。还是以我们的电商系统为例，假如电商系统中的账户表有三个字段：ID、户名和金额，这个时候缓存中存储的就不只是金额信息，而是完整的账户信息了。当更新缓存中账户金额时，你需要从缓存中查询完整的账户数据，把金额变更后再写入到缓存中。 这个过程中也会有并发的问题，比如说原有金额是 20，A 请求从缓存中读到数据，并且把金额加 1，变更成 21，在未写入缓存之前又有请求 B 也读到缓存的数据后把金额也加 1，也变更成 21，两个请求同时把金额写回缓存，这时缓存里面的金额是 21，但是我们实际上预期是金额数加 2，这也是一个比较大的问题。 那我们要如何解决这个问题呢？其实，我们可以在更新数据时不更新缓存，而是删除缓存中的数据，在读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。 这个策略就是我们使用缓存最常见的策略，Cache Aside 策略（也叫旁路缓存策略），这个策略数据以数据库中的数据为准，缓存中的数据是按需加载的。它可以分为读策略和写策略，其中读策略的步骤是： 从缓存中读取数据； 如果缓存命中，则直接返回数据； 如果缓存不命中，则从数据库中查询数据； 查询到数据后，将数据写入到缓存中，并且返回给用户。 写策略的步骤是： 更新数据库中的记录； 删除缓存记录。 你也许会问了，在写策略中，能否先删除缓存，后更新数据库呢？答案是不行的，因为这样也有可能出现缓存数据不一致的问题，我以用户表的场景为例解释一下。 假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21，这就造成了缓存和数据库的不一致。 那么像 Cache Aside 策略这样先更新数据库，后删除缓存就没有问题了吗？其实在理论上还是有缺陷的。假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中，造成缓存和数据库数据不一致。 不过这种问题出现的几率并不高，原因是缓存的写入通常远远快于数据库的写入，所以在实际中很难出现请求 B 已经更新了数据库并且清空了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 清空缓存之前更新了缓存，那么接下来的请求就会因为缓存为空而从数据库中重新加载数据，所以不会出现这种不一致的情况。 Cache Aside 策略是我们日常开发中最经常使用的缓存策略，不过我们在使用时也要学会依情况而变。比如说当新注册一个用户，按照这个更新策略，你要写数据库，然后清理缓存（当然缓存中没有数据给你清理）。可当我注册用户后立即读取用户信息，并且数据库主从分离时，会出现因为主从延迟所以读不到用户信息的情况。 而解决这个问题的办法恰恰是在插入新数据到数据库之后写入缓存，这样后续的读请求就会从缓存中读到数据了。并且因为是新注册的用户，所以不会出现并发更新用户信息的情况。 Cache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案： 一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响； 另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快地过期，对业务的影响也是可以接受。","link":"/2019/12/01/2019/2019-12-01-%E7%BC%93%E5%AD%98%E4%B8%93%E9%A2%98(%E4%BA%8C)_Cache%20Aside(%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98)%E7%AD%96%E7%95%A5/"},{"title":"[片段] Mybatis ParameterHandler实践","text":"用来批量加密用@Decrypted注解的String字段，可能还有一些坑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229import com.google.common.cache.CacheBuilder;import com.google.common.cache.CacheLoader;import com.google.common.cache.LoadingCache;import com.ke.zhaopin.manage.server.config.mybatis.interceptor.anno.Decrypted;import com.lianjia.ctt.kinko.spi.CipherSpi;import com.sun.istack.internal.NotNull;import lombok.Getter;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.StringUtils;import org.apache.ibatis.binding.MapperMethod;import org.apache.ibatis.executor.parameter.ParameterHandler;import org.apache.ibatis.plugin.*;import org.apache.ibatis.reflection.MetaObject;import org.apache.ibatis.scripting.defaults.DefaultParameterHandler;import org.apache.ibatis.session.Configuration;import org.apache.ibatis.session.defaults.DefaultSqlSession;import org.joor.Reflect;import reactor.core.publisher.Flux;import java.lang.reflect.Array;import java.lang.reflect.Field;import java.sql.PreparedStatement;import java.util.*;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeUnit;import java.util.function.Function;import java.util.stream.Collectors;@Intercepts({ @Signature(type = ParameterHandler.class, method = &quot;setParameters&quot;, args = {PreparedStatement.class}),})@Slf4jpublic class EncryptInterceptor implements Interceptor { private static final String COLLECTION_KEY = &quot;collection&quot;; private static final String ARRAY_KEY = &quot;array&quot;; private final LoadingCache&lt;Class, List&lt;String&gt;&gt; decryptFieldCaches = CacheBuilder.newBuilder() .maximumSize(200) .expireAfterAccess(10L, TimeUnit.MINUTES) .build(new CacheLoader&lt;Class, List&lt;String&gt;&gt;() { @Override public List&lt;String&gt; load(Class key) { return Arrays.stream(key.getDeclaredFields()) .filter(f -&gt; f.getAnnotation(Decrypted.class) != null) .filter(f -&gt; { boolean isString = f.getType() == String.class; if (!isString) { log.warn(f.getName() + &quot;is not String, actual type is &quot; + f.getType().getSimpleName() + &quot; ignored&quot;); } return isString; }) .map(Field::getName) .collect(Collectors.toList()); } } ); private CipherSpi cipherSpi; public EncryptInterceptor(CipherSpi cipherSpi) { this.cipherSpi = cipherSpi; } @Override public Object intercept(Invocation invocation) throws Throwable { Flux&lt;CryptContext&gt; contextFlux = Flux.empty(); do { if (!(invocation.getTarget() instanceof DefaultParameterHandler)) break; final Reflect parameterHandler = Reflect.on(invocation.getTarget()); final Object parameterObject = parameterHandler.get(&quot;parameterObject&quot;); final Configuration configuration = parameterHandler.get(&quot;configuration&quot;); if (parameterObject instanceof DefaultSqlSession.StrictMap) { // 单个Collection/Map/Array参数 DefaultSqlSession.StrictMap&lt;?&gt; paramMap = (DefaultSqlSession.StrictMap&lt;?&gt;) parameterObject; Collection&lt;?&gt; collection = null; Class&lt;?&gt; componentType = null; if (paramMap.containsKey(COLLECTION_KEY)) { collection = (Collection&lt;?&gt;) paramMap.get(COLLECTION_KEY); componentType = collection.iterator().next().getClass(); } else if (paramMap.containsKey(ARRAY_KEY)) { Object[] array = (Object[]) paramMap.get(ARRAY_KEY); componentType = array.getClass().getComponentType(); collection = Arrays.asList(array); } if (!isUserDefinedClass(componentType)) break; contextFlux = collection(configuration, collection, componentType); } else if (parameterObject instanceof MapperMethod.ParamMap) { // 多个参数 MapperMethod.ParamMap&lt;?&gt; paramMap = (MapperMethod.ParamMap&lt;?&gt;) parameterObject; final List&lt;?&gt; params = paramMap.values().stream().filter(Objects::nonNull).distinct().collect(Collectors.toList()); for (Object parameter : params) { if (parameter instanceof Collection) { Collection&lt;?&gt; collection = (Collection&lt;?&gt;) parameter; if (collection.isEmpty()) { continue; } Class&lt;?&gt; componentType = collection.iterator().next().getClass(); if (!isUserDefinedClass(componentType)) { continue; } final Flux&lt;CryptContext&gt; collectionFlux = collection(configuration, collection, componentType); contextFlux = contextFlux.concatWith(collectionFlux); } else if (parameter.getClass().isArray()) { if (Array.getLength(parameter) == 0) continue; final Class&lt;?&gt; componentType = parameter.getClass().getComponentType(); if (!isUserDefinedClass(componentType)) { continue; } Collection&lt;?&gt; collection = Arrays.asList((Object[]) parameter); final Flux&lt;CryptContext&gt; collectionFlux = collection(configuration, collection, componentType); contextFlux = contextFlux.concatWith(collectionFlux); } else if (isUserDefinedClass(parameter.getClass())) { final Flux&lt;CryptContext&gt; singleFlux = collection(configuration, Collections.singletonList(parameter), parameter.getClass()); contextFlux = contextFlux.concatWith(singleFlux); } } } else if (isUserDefinedClass(parameterObject.getClass())) { // 单个非Collection/Map/Array参数 contextFlux = collection(configuration, Collections.singletonList(parameterObject), parameterObject.getClass()); } else { // 不是用interface的情况 } } while (false); final List&lt;CryptContext&gt; cryptContexts = encrypt(contextFlux); invocation.proceed(); restore(cryptContexts); return null; } private void restore(List&lt;CryptContext&gt; cryptContexts) { for (CryptContext cryptContext : cryptContexts) { cryptContext.metaObject.setValue(cryptContext.fieldName, cryptContext.value); } } private Flux&lt;CryptContext&gt; collection(Configuration configuration, Collection&lt;?&gt; collection, Class&lt;?&gt; componentType) throws ExecutionException { final List&lt;String&gt; fieldNames = this.getDecryptFields(componentType); return Flux.fromIterable(collection) .map(configuration::newMetaObject) .flatMapIterable(metaObject -&gt; fieldNames.stream().map(fieldName -&gt; new CryptContext(metaObject, fieldName)).collect(Collectors.toList())); } private List&lt;CryptContext&gt; encrypt(Flux&lt;CryptContext&gt; contextFlux) { return contextFlux .filter(context -&gt; StringUtils.isNotBlank(context.value)) .buffer(1000) .doOnNext(contexts -&gt; { Map&lt;String, String&gt; secretMap = Collections.emptyMap(); try { secretMap = cipherSpi.batchEncrypt(contexts.stream().map(CryptContext::getValue).distinct().collect(Collectors.toList())); } catch (Exception e) { } for (CryptContext context : contexts) { context.secret = secretMap.get(context.value); } }) .flatMapIterable(Function.identity()) .doOnNext(context -&gt; context.metaObject.setValue(context.fieldName, context.secret)) .collectList() .block(); } @NotNull private List&lt;String&gt; getDecryptFields(Class&lt;?&gt; modelClazz) throws ExecutionException { return this.decryptFieldCaches.get(modelClazz); } private boolean isUserDefinedClass(Class&lt;?&gt; clazz) { return !clazz.isPrimitive() &amp;&amp; !clazz.getPackage().getName().startsWith(&quot;java&quot;); } @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } @Override public void setProperties(Properties properties) { }}@Getterclass CryptContext { CryptContext(MetaObject metaObject, String fieldName) { this.metaObject = metaObject; this.fieldName = fieldName; this.value = (String) metaObject.getValue(fieldName); if (StringUtils.isBlank(value)) { this.secret = StringUtils.EMPTY; } } final MetaObject metaObject; final String fieldName; final String value; String secret;}","link":"/2019/12/04/2019/2019-12-04-Mybatis_ParameterHandler%E5%AE%9E%E8%B7%B5/"},{"title":"缓存专题(五) 如何解决缓存穿透","text":"什么是缓存穿透缓存穿透其实是指从缓存中没有查到数据，而不得不从后端系统（比如数据库）中查询的情况。你可以把数据库比喻为手机，它是经受不了太多的划痕和磕碰的，所以你需要给它贴个膜再套个保护壳，就能对手机起到一定的保护作用了。 不过，少量的缓存穿透不可避免，对系统也是没有损害的，主要有几点原因： 一方面，互联网系统通常会面临极大数据量的考验，而缓存系统在容量上是有限的，不可能存储系统所有的数据，那么在查询未缓存数据的时候就会发生缓存穿透。 另一方面，互联网系统的数据访问模型一般会遵从“80/20 原则”。“80/20 原则”又称为帕累托法则，是意大利经济学家帕累托提出的一个经济学的理论。它是指在一组事物中，最重要的事物通常只占 20%，而剩余的 80% 的事物确实不重要的。把它应用到数据访问的领域，就是我们会经常访问 20% 的热点数据，而另外的 80% 的数据则不会被经常访问。比如你买了很多衣服，很多书，但是其实经常穿的，经常看的，可能也就是其中很小的一部分。 既然缓存的容量有限，并且大部分的访问只会请求 20% 的热点数据，那么理论上说，我们只需要在有限的缓存空间里存储 20% 的热点数据就可以有效地保护脆弱的后端系统了，也就可以放弃缓存另外 80% 的非热点数据了。所以，这种少量的缓存穿透是不可避免的，但是对系统是没有损害的。 那么什么样的缓存穿透对系统有害呢？答案是大量的穿透请求超过了后端系统的承受范围，造成了后端系统的崩溃。如果把少量的请求比作毛毛细雨，那么一旦变成倾盆大雨，引发洪水，冲倒房屋，肯定就不行了。 产生这种大量穿透请求的场景有很多，接下来，我就带你解析这几种场景以及相应的解决方案。 缓存穿透的解决方案先来考虑这样一种场景：在你的电商系统的用户表中，我们需要通过用户 ID 查询用户的信息，缓存的读写策略采用 Cache Aside 策略。 那么，如果要读取一个用户表中未注册的用户，会发生什么情况呢？按照这个策略，我们会先读缓存，再穿透读数据库。由于用户并不存在，所以缓存和数据库中都没有查询到数据，因此也就不会向缓存中回种数据（也就是向缓存中设置值的意思），这样当再次请求这个用户数据的时候还是会再次穿透到数据库。在这种场景下，缓存并不能有效地阻挡请求穿透到数据库上，它的作用就微乎其微了。 那如何解决缓存穿透呢？一般来说我们会有两种解决方案：回种空值以及使用布隆过滤器。 我们先来看看第一种方案。 回种空值回顾上面提到的场景，你会发现最大的问题在于数据库中并不存在用户的数据，这就造成无论查询多少次，数据库中永远都不会存在这个用户的数据，穿透永远都会发生。 类似的场景还有一些：比如由于代码的 bug 导致查询数据库的时候抛出了异常，这样可以认为从数据库查询出来的数据为空，同样不会回种缓存。 那么，当我们从数据库中查询到空值或者发生异常时，我们可以向缓存中回种一个空值。但是因为空值并不是准确的业务数据，并且会占用缓存的空间，所以我们会给这个空值加一个比较短的过期时间，让空值在短时间之内能够快速过期淘汰。下面是这个流程的伪代码： 1234567891011Object nullValue = new Object();try { Object valueFromDB = getFromDB(uid); // 从数据库中查询数据 if (valueFromDB == null) { cache.set(uid, nullValue, 10); // 如果从数据库中查询到空值，就把空值写入缓存，设置较短的超时时间 } else { cache.set(uid, valueFromDB, 1000); }} catch(Exception e) { cache.set(uid, nullValue, 10);} 回种空值虽然能够阻挡大量穿透的请求，但如果有大量获取未注册用户信息的请求，缓存内就会有有大量的空值缓存，也就会浪费缓存的存储空间，如果缓存空间被占满了，还会剔除掉一些已经被缓存的用户信息反而会造成缓存命中率的下降。 所以这个方案，我建议你在使用的时候应该评估一下缓存容量是否能够支撑。如果需要大量的缓存节点来支持，那么就无法通过通过回种空值的方式来解决，这时你可以考虑使用布隆过滤器。 使用布隆过滤器1970 年布隆提出了一种布隆过滤器的算法，用来判断一个元素是否在一个集合中。这种算法由一个二进制数组和一个 Hash 算法组成。它的基本思路如下： 我们把集合中的每一个值按照提供的 Hash 算法算出对应的 Hash 值，然后将 Hash 值对数组长度取模后得到需要计入数组的索引值，并且将数组这个位置的值从 0 改成 1。在判断一个元素是否存在于这个集合中时，你只需要将这个元素按照相同的算法计算出索引值，如果这个位置的值为 1 就认为这个元素在集合中，否则则认为不在集合中。 下图是布隆过滤器示意图，我来带你分析一下图内的信息。 A、B、C 等元素组成了一个集合，元素 D 计算出的 Hash 值所对应的的数组中值是 1，所以可以认为 D 也在集合中。而 F 在数组中的值是 0，所以 F 不在数组中。 那么我们如何使用布隆过滤器来解决缓存穿透的问题呢？ 还是以存储用户信息的表为例进行讲解。首先，我们初始化一个很大的数组，比方说长度为 20 亿的数组，接下来我们选择一个 Hash 算法，然后我们将目前现有的所有用户的 ID 计算出 Hash 值并且映射到这个大数组中，映射位置的值设置为 1，其它值设置为 0。 新注册的用户除了需要写入到数据库中之外，它也需要依照同样的算法更新布隆过滤器的数组中，相应位置的值。那么当我们需要查询某一个用户的信息时，我们首先查询这个 ID 在布隆过滤器中是否存在，如果不存在就直接返回空值，而不需要继续查询数据库和缓存，这样就可以极大地减少异常查询带来的缓存穿透。 布隆过滤器拥有极高的性能，无论是写入操作还是读取操作，时间复杂度都是 O(1)，是常量值。在空间上，相对于其他数据结构它也有很大的优势，比如，20 亿的数组需要 2000000000/8/1024/1024 = 238M 的空间，而如果使用数组来存储，假设每个用户 ID 占用 4 个字节的空间，那么存储 20 亿用户需要 2000000000 * 4 / 1024 / 1024 = 7600M 的空间，是布隆过滤器的 32 倍。 不过，任何事物都有两面性，布隆过滤器也不例外，它主要有两个缺陷： 它在判断元素是否在集合中时是有一定错误几率的，比如它会把不是集合中的元素判断为处在集合中； 不支持删除元素。 关于第一个缺陷，主要是 Hash 算法的问题。因为布隆过滤器是由一个二进制数组和一个 Hash 算法组成的，Hash 算法存在着一定的碰撞几率。Hash 碰撞的含义是不同的输入值经过 Hash 运算后得到了相同的 Hash 结果。 本来，Hash 的含义是不同的输入，依据不同的算法映射成独一无二的固定长度的值，也就是我输入字符串“1”，根据 CRC32 算法，值是 2212294583。但是现实中 Hash 算法的输入值是无限的，输出值的值空间却是固定的，比如 16 位的 Hash 值的值空间是 65535，那么它的碰撞几率就是 1/65535，即如果输入值的个数超过 65535 就一定会发生碰撞。 那么你可能会问为什么不映射成更长的 Hash 值呢？ 因为更长的 Hash 值会带来更高的存储成本和计算成本。即使使用 32 位的 Hash 算法，它的值空间长度是 2 的 32 次幂减一，约等于 42 亿，用来映射 20 亿的用户数据，碰撞几率依然有接近 50%。 Hash 的碰撞就造成了两个用户 ID ，A 和 B 会计算出相同的 Hash 值，那么如果 A 是注册的用户，它的 Hash 值对应的数组中的值是 1，那么 B 即使不是注册用户，它在数组中的位置和 A 是相同的，对应的值也是 1，这就产生了误判。 布隆过滤器的误判有一个特点，就是它只会出现“false positive”的情况。这是什么意思呢？当布隆过滤器判断元素在集合中时，这个元素可能不在集合中。但是一旦布隆过滤器判断这个元素不在集合中时，它一定不在集合中。这一点非常适合解决缓存穿透的问题。为什么呢？ 你想，如果布隆过滤器会将集合中的元素判定为不在集合中，那么我们就不确定，被布隆过滤器判定为不在集合中的元素，是不是在集合中。假设在刚才的场景中，如果有大量查询未注册的用户信息的请求存在，那么这些请求到达布隆过滤器之后，即使布隆过滤器判断为不是注册用户，那么我们也不确定它是不是真的不是注册用户，那么就还是需要去数据库和缓存中查询，这就使布隆过滤器失去了价值。 所以你看，布隆过滤器虽然存在误判的情况，但是还是会减少缓存穿透的情况发生，只是我们需要尽量减少误判的几率，这样布隆过滤器的判断正确的几率更高，对缓存的穿透也更少。一个解决方案是： 使用多个 Hash 算法为元素计算出多个 Hash 值，只有所有 Hash 值对应的数组中的值都为 1 时，才会认为这个元素在集合中。 布隆过滤器不支持删除元素的缺陷也和 Hash 碰撞有关。给你举一个例子，假如两个元素 A 和 B 都是集合中的元素，它们有相同的 Hash 值，它们就会映射到数组的同一个位置。这时我们删除了 A，数组中对应位置的值也从 1 变成 0，那么在判断 B 的时候发现值是 0，也会判断 B 是不在集合中的元素，就会得到错误的结论。 那么我是怎么解决这个问题的呢？我会让数组中不再只有 0 和 1 两个值，而是存储一个计数。比如如果 A 和 B 同时命中了一个数组的索引，那么这个位置的值就是 2，如果 A 被删除了就把这个值从 2 改为 1。这个方案中的数组不再存储 bit 位，而是存储数值，也就会增加空间的消耗。所以，你要依据业务场景来选择是否能够使用布隆过滤器，比如像是注册用户的场景下，因为用户删除的情况基本不存在，所以还是可以使用布隆过滤器来解决缓存穿透的问题的。 讲了这么多，关于布隆过滤器的使用上，我也给你几个建议： 选择多个 Hash 函数计算多个 Hash 值，这样可以减少误判的几率； 布隆过滤器会消耗一定的内存空间，所以在使用时需要评估你的业务场景下需要多大的内存，存储的成本是否可以接受。 总的来说，回种空值和布隆过滤器是解决缓存穿透问题的两种最主要的解决方案，但是它们也有各自的适用场景，并不能解决所有问题。比方说当有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力，我们把这个场景叫做“dog-pile effect”（狗桩效应）， 这是典型的缓存并发穿透的问题，那么，我们如何来解决这个问题呢？解决狗桩效应的思路是尽量地减少缓存穿透后的并发，方案也比较简单： 在代码中，控制在某一个热点缓存项失效之后启动一个后台线程，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都不再穿透而直接返回。 通过在 Memcached 或者 Redis 中设置分布式锁，只有获取到锁的请求才能够穿透到数据库。 分布式锁的方式也比较简单，比方说 ID 为 1 的用户是一个热点用户，当他的用户信息缓存失效后，我们需要从数据库中重新加载数据时，先向 Memcached 中写入一个 Key 为”lock.1”的缓存项，然后去数据库里面加载数据，当数据加载完成后再把这个 Key 删掉。这时，如果另外一个线程也要请求这个用户的数据，它发现缓存中有 Key 为“lock.1”的缓存，就认为目前已经有线程在加载数据库中的值到缓存中了，它就可以重新去缓存中查询数据，不再穿透数据库了。","link":"/2019/12/04/2019/2019-12-04-%E7%BC%93%E5%AD%98%E4%B8%93%E9%A2%98(%E4%BA%94)_%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"},{"title":"缓存专题(四) 分布式缓存高可用","text":"分布式缓存的高可用方案主要选择的方案有客户端方案、中间代理层方案和服务端方案三大类： 客户端方案就是在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。 中间代理层方案是在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。 服务端方案就是 Redis 2.4 版本后提出的 Redis Sentinel 方案。 掌握这些方案可以帮助你，抵御部分缓存节点故障导致的，缓存命中率下降的影响，增强你的系统的鲁棒性。 客户端方案在客户端方案中，你需要关注缓存的写和读两个方面： 写入数据时，需要把被写入缓存的数据分散到多个节点中，即进行数据分片； 读数据时，可以利用多组的缓存来做容错，提升缓存系统的可用性。关于读数据，这里可以使用主从和多副本两种策略，两种策略是为了解决不同的问题而提出的。 下面我就带你一起详细地看一下到底要怎么做。 1. 缓存数据如何分片 单一的缓存节点受到机器内存、网卡带宽和单节点请求量的限制，不能承担比较高的并发，因此我们考虑将数据分片，依照分片算法将数据打散到多个不同的节点上，每个节点上存储部分数据。 这样在某个节点故障的情况下，其他节点也可以提供服务，保证了一定的可用性。这就好比不要把鸡蛋放在同一个篮子里，这样一旦一个篮子掉在地上，摔碎了，别的篮子里还有没摔碎的鸡蛋，不至于一个不剩。 一般来讲，分片算法常见的就是 Hash 分片算法和一致性 Hash 分片算法两种。 Hash 分片的算法就是对缓存的 Key 做哈希计算，然后对总的缓存节点个数取余。你可以这么理解： 比如说，我们部署了三个缓存节点组成一个缓存的集群，当有新的数据要写入时，我们先对这个缓存的 Key 做比如 crc32 等 Hash 算法生成 Hash 值，然后对 Hash 值模 3，得出的结果就是要存入缓存节点的序号。 这个算法最大的优点就是简单易理解，缺点是当增加或者减少缓存节点时，缓存总的节点个数变化造成计算出来的节点发生变化，从而造成缓存失效不可用。所以我建议你，如果采用这种方法，最好建立在你对于这组缓存命中率下降不敏感，比如下面还有另外一层缓存来兜底的情况下。 当然了，用一致性 Hash 算法可以很好地解决增加和删减节点时，命中率下降的问题。在这个算法中，我们将整个 Hash 值空间组织成一个虚拟的圆环，然后将缓存节点的 IP 地址或者主机名做 Hash 取值后，放置在这个圆环上。当我们需要确定某一个 Key 需要存取到哪个节点上的时候，先对这个 Key 做同样的 Hash 取值，确定在环上的位置，然后按照顺时针方向在环上“行走”，遇到的第一个缓存节点就是要访问的节点。比方说下面这张图里面，Key 1 和 Key 2 会落入到 Node 1 中，Key 3、Key 4 会落入到 Node 2 中，Key 5 落入到 Node 3 中，Key 6 落入到 Node 4 中。 这时如果在 Node 1 和 Node 2 之间增加一个 Node 5，你可以看到原本命中 Node 2 的 Key 3 现在命中到 Node 5，而其它的 Key 都没有变化；同样的道理，如果我们把 Node 3 从集群中移除，那么只会影响到 Key 5 。所以你看，在增加和删除节点时，只有少量的 Key 会“漂移”到其它节点上，而大部分的 Key 命中的节点还是会保持不变，从而可以保证命中率不会大幅下降。 不过，事物总有两面性。虽然这个算法对命中率的影响比较小，但它还是存在问题： 缓存节点在圆环上分布不平均，会造成部分缓存节点的压力较大；当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成压力。 一致性 Hash 算法的脏数据问题。 极端情况下，比如一个有三个节点 A、B、C 承担整体的访问，每个节点的访问量平均，A 故障后，B 将承担双倍的压力（A 和 B 的全部请求），当 B 承担不了流量 Crash 后，C 也将因为要承担原先三倍的流量而 Crash，这就造成了整体缓存系统的雪崩。 说到这儿，你可能觉得很可怕，但也不要太担心，我们程序员就是要能够创造性地解决各种问题，所以你可以在一致性 Hash 算法中引入虚拟节点的概念。 它将一个缓存节点计算多个 Hash 值分散到圆环的不同位置，这样既实现了数据的平均，而且当某一个节点故障或者退出的时候，它原先承担的 Key 将以更加平均的方式分配到其他节点上，从而避免雪崩的发生。 其次，就是一致性 Hash 算法的脏数据问题。为什么会产生脏数据呢？比方说，在集群中有两个节点 A 和 B，客户端初始写入一个 Key 为 k，值为 3 的缓存数据到 Cache A 中。这时如果要更新 k 的值为 4，但是缓存 A 恰好和客户端连接出现了问题，那这次写入请求会写入到 Cache B 中。接下来缓存 A 和客户端的连接恢复，当客户端要获取 k 的值时，就会获取到存在 Cache A 中的脏数据 3，而不是 Cache B 中的 4。 所以，在使用一致性 Hash 算法时一定要设置缓存的过期时间，这样当发生漂移时，之前存储的脏数据可能已经过期，就可以减少存在脏数据的几率。 很显然，数据分片最大的优势就是缓解缓存节点的存储和访问压力，但同时它\b也让缓存的使用\b更加复杂。在 MultiGet（批量获取）场景下，单个节点的访问量并没有减少，同时节点数太多会造成缓存访问的 SLA（即“服务等级协议”，SLA 代表了网站服务可用性）得不到很好的保证，因为根据木桶原则，SLA 取决于最慢、最坏的节点的情况，节点数过多也会增加出问题的概率，因此我推荐 4 到 6 个节点为佳。 中间代理层方案虽然客户端方案已经能解决大部分的问题，但是只能在单一语言系统之间复用。例如微博使用 Java 语言实现了这么一套逻辑，我使用 PHP 就难以复用，需要重新写一套，很麻烦。而中间代理层的方案就可以解决这个问题。你可以将客户端解决方案的经验移植到代理层中，通过通用的协议（如 Redis 协议）来实现在其他语言中的复用。 如果你来自研缓存代理层，你就可以将客户端方案中的高可用逻辑封装在代理层代码里面，这样用户在使用你的代理层的时候就不需要关心缓存的高可用是如何做的，只需要依赖你的代理层就好了。 除此以外，业界也有很多中间代理层方案，比如 Facebook 的Mcrouter，Twitter 的Twemproxy，豌豆荚的Codis。它们的原理基本上可以由一张图来概括： 看这张图你有什么发现吗？ 所有缓存的读写请求都是经过代理层完成的。代理层是无状态的，主要负责读写请求的路由功能，并且在其中内置了一些高可用的逻辑，不同的开源中间代理层方案中使用的高可用策略各有不同。比如在 Twemproxy 中，Proxy 保证在某一个 Redis 节点挂掉之后会把它从集群中移除，后续的请求将由其他节点来完成；而 Codis 的实现略复杂，它提供了一个叫 Codis Ha 的工具来实现自动从节点提主节点，在 3.2 版本之后换做了 Redis Sentinel 方式，从而实现 Redis 节点的高可用。 服务端方案Redis 在 2.4 版本中提出了 Redis Sentinel 模式来解决主从 Redis 部署时的高可用问题，它可以在主节点挂了以后自动将从节点提升为主节点，保证整体集群的可用性，整体的架构如下图所示： Redis Sentinel 也是集群部署的，这样可以避免 Sentinel 节点挂掉造成无法自动故障恢复的问题，每一个 Sentinel 节点都是无状态的。在 Sentinel 中会配置 Master 的地址，Sentinel 会时刻监控 Master 的状态，当发现 Master 在配置的时间间隔内无响应，就认为 Master 已经挂了，Sentinel 会从从节点中选取一个提升为主节点，并且把所有其他的从节点作为新主的从节点。Sentinel 集群内部在仲裁的时候，会根据配置的值来决定当有几个 Sentinel 节点认为主挂掉可以做主从切换的操作，也就是集群内部需要对缓存节点的状态达成一致才行。 Redis Sentinel 不属于代理层模式，因为对于缓存的写入和读取请求不会经过 Sentinel 节点。Sentinel 节点在架构上和主从是平级的，是作为管理者存在的，所以可以认为是在服务端提供的一种高可用方案。","link":"/2019/12/04/2019/2019-12-04-%E7%BC%93%E5%AD%98%E4%B8%93%E9%A2%98(%E5%9B%9B)_%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"title":"消息队列(一)-如何解决消息丢失","text":"消息会丢失的环节消息从被写入到消息队列，到被消费者消费完成，这个链路上会有哪些地方存在丢失消息的可能呢？其实，主要存在三个场景： 消息从生产者写入到消息队列的过程。 消息在消息队列中的存储场景。 消息被消费者消费的过程。 1. 在消息生产的过程中丢失消息消息的生产者一般是我们的业务服务器，消息队列是独立部署在单独的服务器上的。两者之间的网络虽然是内网，但是也会存在抖动的可能，而一旦发生抖动，消息就有可能因为网络的错误而丢失。 针对这种情况，我建议你采用的方案是消息重传：也就是当你发现发送超时后你就将消息重新发一次，但是你也不能无限制地重传消息。一般来说，如果不是消息队列发生故障，或者是到消息队列的网络断开了，重试 2～3 次就可以了。 不过，这种方案可能会造成消息的重复，从而导致在消费的时候会重复消费同样的消息。比方说，消息生产时由于消息队列处理慢或者网络的抖动，导致虽然最终写入消息队列成功，但在生产端却超时了，生产者重传这条消息就会形成重复的消息。 2. 在消息队列中丢失消息拿 Kafka 举例，消息在 Kafka 中是存储在本地磁盘上的，而为了减少消息存储时对磁盘的随机 I/O，我们一般会将消息先写入到操作系统的 Page Cache 中，然后再找合适的时机刷新到磁盘上。 比如，Kafka 可以配置当达到某一时间间隔，或者累积一定的消息数量的时候再刷盘，也就是所说的异步刷盘。 不过，如果发生机器掉电或者机器异常重启，那么 Page Cache 中还没有来得及刷盘的消息就会丢失了。那么怎么解决呢？ 你可能会把刷盘的间隔设置很短，或者设置累积一条消息就就刷盘，但这样频繁刷盘会对性能有比较大的影响，而且从经验来看，出现机器宕机或者掉电的几率也不高，所以我不建议你这样做。 如果你的系统对消息丢失的容忍度很低，那么你可以考虑以集群方式部署 Kafka 服务，通过部署多个副本备份数据，保证消息尽量不丢失。 那么它是怎么实现的呢？ Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower 负责数据的备份。Follower 中有一个特殊的集合叫做 ISR（in-sync replicas），当 Leader 故障时，新选举出来的 Leader 会从 ISR 中选择，默认 Leader 的数据会异步地复制给 Follower，这样在 Leader 发生掉电或者宕机时，Kafka 会从 Follower 中消费消息，减少消息丢失的可能。 由于默认消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机，那些还没有来得及复制到 Follower 的消息还是会丢失。为了解决这个问题，Kafka 为生产者提供一个选项叫做“acks”，当这个选项被设置为“all”时，生产者发送的每一条消息除了发给 Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 ISR 的确认后才被认为发送成功。这样，只有 Leader 和所有的 ISR 都挂了，消息才会丢失。 从上面这张图来看，当设置“acks=all”时，需要同步执行 1，3，4 三个步骤，对于消息生产的性能来说也是有比较大的影响的，所以你在实际应用中需要仔细地权衡考量。我给你的建议是： 如果你需要确保消息一条都不能丢失，那么建议不要开启消息队列的同步刷盘，而是需要使用集群的方式来解决，可以配置当所有 ISR Follower 都接收到消息才返回成功。 如果对消息的丢失有一定的容忍度，那么建议不部署集群，即使以集群方式部署，也建议配置只发送给一个 Follower 就可以返回成功了。 我们的业务系统一般对于消息的丢失有一定的容忍度，比如说以上面的红包系统为例，如果红包消息丢失了，我们只要后续给没有发送红包的用户补发红包就好了。 3. 在消费的过程中存在消息丢失的可能我还是以 Kafka 为例来说明。一个消费者消费消息的进度是记录在消息队列集群中的，而消费的过程分为三步：接收消息、处理消息、更新消费进度。 这里面接收消息和处理消息的过程都可能会发生异常或者失败，比如说，消息接收时网络发生抖动，导致消息并没有被正确的接收到；处理消息时可能发生一些业务的异常导致处理流程未执行完成，这时如果更新消费进度，那么这条失败的消息就永远不会被处理了，也可以认为是丢失了。 所以，在这里你需要注意的是，一定要等到消息接收和处理完成后才能更新消费进度，但是这也会造成消息重复的问题，比方说某一条消息在处理之后，消费者恰好宕机了，那么因为没有更新消费进度，所以当这个消费者重启之后，还会重复地消费这条消息。 4. 最佳实践 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。 设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。 设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。 设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。 设置 replication.factor &gt;= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。 设置 min.insync.replicas &gt; 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。 确保 replication.factor &gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。 确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。","link":"/2019/12/08/2019/2019-12-08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97(%E4%B8%80)-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/"},{"title":"消息队列(二)-消息幂等","text":"什么是幂等幂等是一个数学上的概念，它的含义是多次执行同一个操作和执行一次操作，最终得到的结果是相同的。 如果我们消费一条消息的时候，要给现有的库存数量减 1，那么如果消费两条相同的消息就会给库存数量减 2，这就不是幂等的。而如果消费一条消息后，处理逻辑是将库存的数量设置为 0，或者是如果当前库存数量是 10 时则减 1，这样在消费多条消息时，所得到的结果就是相同的，这就是幂等的。 说白了，你可以这么理解“幂等”：一件事儿无论做多少次都和做一次产生的结果是一样的，那么这件事儿就具有幂等性。 在生产、消费过程中增加消息幂等性的保证消息在生产和消费的过程中都可能会产生重复，所以你要做的是，在生产过程和消费过程中增加消息幂等性的保证，这样就可以认为从最终结果上来看，消息实际上是只被消费了一次的。 在消息生产过程中，在 Kafka0.11 版本和 Pulsar 中都支持“producer idempotency”的特性，翻译过来就是生产过程的幂等性，这种特性保证消息虽然可能在生产端产生重复，但是最终在消息队列存储时只会存储一份。 它的做法是给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一 ID，消息队列的服务端会存储 &lt; 生产者 ID，最后一条消息 ID&gt; 的映射。当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID 是否与存储的最后一条 ID 一致，如果一致，就认为是重复的消息，服务端会自动丢弃。 而在消费端，幂等性的保证会稍微复杂一些，你可以从通用层和业务层两个层面来考虑。 在通用层面，你可以在消息被生产的时候，使用发号器给它生成一个全局唯一的消息 ID，消息被处理之后，把这个 ID 存储在数据库中，在处理下一条消息之前，先从数据库里面查询这个全局 ID 是否被消费过，如果被消费过就放弃消费。 你可以看到，无论是生产端的幂等性保证方式，还是消费端通用的幂等性保证方式，它们的共同特点都是为每一个消息生成一个唯一的 ID，然后在使用这个消息的时候，先比对这个 ID 是否已经存在，如果存在，则认为消息已经被使用过。所以这种方式是一种标准的实现幂等的方式，你在项目之中可以拿来直接使用，它在逻辑上的伪代码就像下面这样： 12345678910111213boolean isIDExisted = selectByID(ID); // 判断 ID 是否存在if(isIDExisted) { return; // 存在则直接返回} else { process(message); // 不存在，则处理消息 saveID(ID); // 存储 ID} 不过这样会有一个问题：如果消息在处理之后，还没有来得及写入数据库，消费者宕机了重启之后发现数据库中并没有这条消息，还是会重复执行两次消费逻辑，这时你就需要引入事务机制，保证消息处理和写入数据库必须同时成功或者同时失败，但是这样消息处理的成本就更高了，所以，如果对于消息重复没有特别严格的要求，可以直接使用这种通用的方案，而不考虑引入事务。 在业务层面怎么处理呢？这里有很多种处理方式，其中有一种是增加乐观锁的方式。比如，你的消息处理程序需要给一个人的账号加钱，那么你可以通过乐观锁的方式来解决。 具体的操作方式是这样的：你给每个人的账号数据中增加一个版本号的字段，在生产消息时先查询这个账户的版本号，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，在执行更新账户金额 SQL 的时候带上版本号，类似于执行： 1update user set amount = amount + 20, version=version+1 where userId=1 and version=1; 你看，我们在更新数据时给数据加了乐观锁，这样在消费第一条消息时，version 值为 1，SQL 可以执行成功，并且同时把 version 值改为了 2；在执行第二条相同的消息时，由于 version 值不再是 1，所以这条 SQL 不能执行成功，也就保证了消息的幂等性。","link":"/2019/12/08/2019/2019-12-08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97(%E4%BA%8C)-%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89/"},{"title":"Boyer–Moore 字符搜索算法","text":"因为字符比较是从右往左比较的，所以第一层循环 needle.length + 1 &lt;= i &lt; haystack.length。 12345678910111213 start=needle.length - 1 end=haystack.length - 1 + + | | | | v-------------------------------------------------------------------v-&gt; 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+| t | h | i | s | | i | s | | a | | s | i | m | p | l | e | | e | x | a | m | p | l | e |+-------------------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---++---------------------------+| e | x | a | m | p | l | e |+---+---+---+---+---+---+---+ 第二层循环中i变量表示坏字符的位置、j表示搜索坏字符开始位置 12345678910111213141516 i + | v 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+| t | h | i | s | | i | s | | a | | s | i | m | p | l | e | | e | x | a | m | p | l | e |+-------------------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---++---------------------------+| e | x | a | m | p | l | e |+---+---+---+---+---+---+-+-+ ^ | + j i,j指针向左搜索,如果完全匹配直接返回i即可 12345for (j = needle.length - 1; needle[j] == haystack[i]; --i, --j) { if (j == 0) { return i; }} 坏字符规则和好字符规则坏字符:从右向左第一个不匹配的字符好字符:从坏字符下一个字符直到最后的字符 可以认为字符移动有两种策略：坏字符对齐和好字符对齐，然后选择字符移动距离大的策略即可 wiki实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * Returns the index within this string of the first occurrence of the * specified substring. If it is not a substring, return -1. * * There is no Galil because it only generates one match. * * @param haystack The string to be scanned * @param needle The target string to search * @return The start index of the substring */public static int indexOf(char[] haystack, char[] needle) { if (needle.length == 0) { return 0; } int charTable[] = makeCharTable(needle); int offsetTable[] = makeOffsetTable(needle); for (int i = needle.length - 1, j; i &lt; haystack.length;) { for (j = needle.length - 1; needle[j] == haystack[i]; --i, --j) { if (j == 0) { return i; } } // i += needle.length - j; // For naive method i += Math.max(offsetTable[needle.length - 1 - j], charTable[haystack[i]]); } return -1;}/** * Makes the jump table based on the mismatched character information. */private static int[] makeCharTable(char[] needle) { final int ALPHABET_SIZE = Character.MAX_VALUE + 1; // 65536 int[] table = new int[ALPHABET_SIZE]; for (int i = 0; i &lt; table.length; ++i) { table[i] = needle.length; } for (int i = 0; i &lt; needle.length - 2; ++i) { table[needle[i]] = needle.length - 1 - i; } return table;}/** * Makes the jump table based on the scan offset which mismatch occurs. * (bad character rule). */private static int[] makeOffsetTable(char[] needle) { int[] table = new int[needle.length]; int lastPrefixPosition = needle.length; for (int i = needle.length; i &gt; 0; --i) { if (isPrefix(needle, i)) { lastPrefixPosition = i; } table[needle.length - i] = lastPrefixPosition - i + needle.length; } for (int i = 0; i &lt; needle.length - 1; ++i) { int slen = suffixLength(needle, i); table[slen] = needle.length - 1 - i + slen; } return table;}/** * Is needle[p:end] a prefix of needle? */private static boolean isPrefix(char[] needle, int p) { for (int i = p, j = 0; i &lt; needle.length; ++i, ++j) { if (needle[i] != needle[j]) { return false; } } return true;}/** * Returns the maximum length of the substring ends at p and is a suffix. * (good suffix rule) */private static int suffixLength(char[] needle, int p) { int len = 0; for (int i = p, j = needle.length - 1; i &gt;= 0 &amp;&amp; needle[i] == needle[j]; --i, --j) { len += 1; } return len;}","link":"/2020/01/10/2020/2020-01-10-Boyer%E2%80%93Moore_%E5%AD%97%E7%AC%A6%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"},{"title":"高性能MySql 4至6章读书笔记","text":"第四章 Schema设计选择优化的数据类型更小的通常更好，但是要确保没有低估需要存储的值的范围，因为在schema中的多个地方增加数据类型范围是一个十分耗时的操作。 简单就好简单的数据类型的操作通常需要更少的cpu时间。 尽量避免NULL可为NULL的列使得索引、索引比统计和值比较都更为复杂。 当然也有例外，InnoDB使用单独的位存储NULL值， 所以对于稀疏数据有很好的空间效率。 选择标识符一旦选定一种类型，要确保在所有的关联表中都使用同样的类型。类型之间需要精确匹配，包括像UNSIGNED这样的属性。尽量只用整型定义标识符。 注意可变长字符串其在临时表和排序时可能导致悲观的按最大长度分配内存 范式与反范式范式是好的，但是反范式有时也是必须的，并且能带来好处。 第五章 创建高性能索引B-Tree 索引的查询类型 全值匹配： 指的是和索引的所有列进行匹配 匹配最左前缀： 查找索引前几列进行匹配 匹配列前缀: 只匹配某一列的值的开头部分 匹配范围值： 查找索引某一范围的值 精确匹配某一列并范围匹配另外一列 只访问索引的查询：覆盖索引 B-Tree 索引的限制 如果不是按照索引的最左列开始查找，则无法使用索引 不能跳过索引中的列 如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引：例如查询 索引为key(last_name, fisrt_name, dob)1where last_name = 'a' and first_name like 'J%' and dob = '1877-12-23' 索引的优点 大大减少服务器需要扫描的数据量 帮助服务器避免排序和临时表 将随机I/O变为顺序I/O 高性能索引-独立的列如果查询中列不是独立的，则mysql不会使用索引 12select actor_id from sakila.actor where actor_id + 1 = 5; 高性能索引-前缀索引和索引选择性有时候需要索引很长的字符列，通常可以索引开始部分的字符，同时也会降低索引的选择性。 索引的选择性指的是，不重复的索引值和数据表的记录总数的比值。索引的选择性越高表示查询效率越高，因为选择性高的索引可以过滤掉更多的行。 前缀索引是一种能使索引更小，更快的有效方法，但是也有其缺点：前缀索引无法做order by 和 group by，也无法使用前缀索引做覆盖索引。 高性能索引-多列索引最容易遇到的困惑是多列索引的顺序，正确的顺序依赖于使用索引的查询，同时需要考虑如何更好的满足排序和分组需要。对于如何选择索引的列顺序有一个经验法则：将选择性最高的列放在索引的最前列。只有不需要考虑排序和分组时，将选择性跟高的列放在最前面通常是最好的，但是考虑问题需要更全面，避免随机I/O和排序更加重要。 高性能索引-覆盖索引如果一个索引包含所需要查询的字段的值，我们就可以称之为“覆盖索引” 覆盖索引的好处： 索引条目通常远小于数据行大小，所以如果只需要读取索引，那mysql就会极大的减少数据访问量。 因为索引是按照列值顺序存储的，所以对于I/O密集型范围查询回避随机从磁盘读取每一行数据的I/O要小的多 由于Innodb的聚簇索引，覆盖索引对Innodb表特别有用，可以避免对主键索引的二次查询。 覆盖索引的陷阱： 1select * from products where actor = 'SEAN CARREY' and title like '%APOLLO%'; 没有索引能够覆盖这个查询，因为查询从表中选择了所有的列 mysql不能再索引中执行like操作，只能做最左前缀匹配 高性能索引-使用索引扫描来做排序 mysql有两种方式可以生成有序的结果：通过排序操作；或者使用索引顺序扫描。mysql可以使用同一个索引既满足排序，有用于查找行。 只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向都一样时，mysql才能使用索引来对结果做排序。如果查询需要关联多张表，则只有当ORDER BY子句引用的字段全部为第一个表时，才能用索引做排序。ORDER BY子句和查询的限制是一样的：需要满足索引的最左前缀的要求。 有一种情况下ORDER BY子句可以不满足索引的最左前缀要求： 12select rental_id, staff_id from sakila.rental where rental_date = '2005-05-25'order by inventory_id, customer_id; 索引为key(rental_date, inventory_id, customer_id)，前导列为常量的时候，如果where子句或者join子句中对这些列指定了常量，就可以弥补ORDER BY的不足。 12where rental_date &gt; '2005-12-25' order by inventory_id, customer_id;where rental_date = '2005-12-25' and inventory_id in (1, 2) order by cusomter_id; 对于索引上是范围查询，mysql无法使用之后的索引列 高性能索引-使用索引扫描减少锁索引可以让查询锁定更少的行，如果你的查询从不访问那些不需要的行，那么就会锁定更少的行。但这只有当innoDB在存储引擎层能够过滤掉所有不需要的行是才有效。如果索引无法过滤掉无效的行，那么innoDB检索到数据并返回给服务器层后，innoDB已经锁定这些行了（mysql 5.6后没有这个问题）。 高性能索引-避免多个范围条件下面的查询： 1where last_online &gt; date_sub(now(), interval 7 day) and age bwtween 18 and 25 这个查询有一个问题：它有两个范围条件,last_online和age列，mysql可以使用last_online的索引或者是age列的索引，但是无法同时使用它们。 高性能索引-延迟关联优化分页如果一个查询匹配结果有上百万行的话会怎样？ 1select * from profiles where sex = 'm' order by rating limit 10; 即使有索引，如果用户界面需要翻页，并且翻页到比较靠后的地方也会非常慢，如： 1select * from profiles where sex = 'm' order by rating limit 1000000, 10; 无论如何创建索引，这种查询都是个严重的问题，mysql需要花费大量时间来扫描需要丢弃的数据。其中一个解决的办法是限制能够翻页的数量。 优化这类索引的另一个比较好的策略是使用延迟关联，通过使用覆盖索引返回需要的主建，再根据这些主建回主表获得需要的行，这样可以减少mysql扫描需要丢弃的行数。 123456select * from profiles innner join ( select id fomr profiles p where p.sex = 'm' order by rating limit 1000000, 10) as t using (id); 第六章 慢查询优化优化数据访问查询性能低下最基本的原因是访问数据太多。某些查询可能不可避免的需要筛选大量数据，单这并不常见。大部分性能低下的查询都可以通过减少访问的数据量的方式进行优化。对于低效的查询，我们发现通过下面几个步骤来分析总是很有效： 确认应用程序时候检索大量超过需要的数据。 确认mysql服务层是否在分许大量超过需要的数据行。 第一种情况可以使用limit和选择需要的列来解决。在确定查询只返回需要的数据之后，接下来应该看看查询为了返回结果是否扫描了过多的数据，对于mysql有三个衡量查询开销的指标： 响应时间 扫描的行数 返回的行数 没有那个指标能完美地衡量查询的开销，但它们大致反映了mysql内部查询时需要访问多少数据，并可以大概推算出查询运行的时间。 在评估查询开销的时候，需要考虑一下从表中找到某一行数据的成本。mysql有好几种访问方式可以查找并返回一行结果。有些访问方式可能需要扫描很多行才能返回一行结果，也有些访问方式可能无需扫描就能返回结果。 在explain语句中的type列反应了访问类型。访问类型有很多种，从全表扫描到索引扫描、范围扫描、唯一索引查询、常数引用等。这里列的这些，速度是从慢到快，扫描行数也是从大到小。如果查询没有办法找到合适是访问类型，那么解决的最好办法通常是增加一个合适的索引。 一般mysql能够使用如下三种方式应用where条件，从好到坏依次为： 从索引中使用where条件吗来过滤不匹配的记录，这是在存储引擎层完成的。 使用索引覆盖扫描来返回记录（extra出现using index），直接从索引中过滤不需要的数据并返回命中结果。这是在mysql服务层完成的，但无需再回表查询记录。 从数据表中返回数据，然后过滤不满足条件的记录（extra出现using where）。这是在mysql服务器层完成，mysql需要从数据表中读出记录然后过滤。 如果发现查询需要扫描大量的数据但只返回少数的行，那么可以使用下面的技巧去优化它： 使用覆盖索引，把需要用的列都放到索引中 改变库表结构。例如使用单独的汇总表 重写复杂的查询， 让mysql优化器能够以更加高效的方式执行这个查询 重构查询方式-切分查询有时候对于一个大查询我们需要分而治之，将大查询分成小查询。删除旧数据是一个很好的例子，如果用一个大的语句一次性完成，则可能一次需要锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞恨到重要的查询。 重构查询方式-分解关联查询例如下面这个查询： 1234select * from tagjoin tag_post on tag_post.tag_id = tag.idjoin post on tag_post.post_id = post.idwhere tag.tag = 'mysql'; 可以分解成下面这个查询来代替： 12345select * from tag where tag = 'mysql';select * from tag_post where tag_id = 1234;select * from post where post.id in (123,456,567); 用分解关联查询的方式重构查询有如下的优势： 让缓存效率更高。许多应用程序可以方便地缓存单表查询对应的结果对象。 将查询分解后，执行单个查询可以减少锁的竞争。 在应用层做关联，可以更容易对数据库进行拆分，更容易做到高性能和高扩展。 查询本身效率可能提升，使用in代替关联查询，可能比随机关联更高效。 减少冗余记录的查询 相当于在应用层实现了哈希关联 重构查询方式-优化关联查询 确保on或者using子句上的列上有索引。 确保任何group by和 order by 的表达式中只涉及到一个表中的列，这样mysql才有可能使用索引来优化这个过程","link":"/2020/01/28/2020/2020-01-28-%E9%AB%98%E6%80%A7%E8%83%BDMySql%204%E8%87%B36%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"title":"清醒思考的艺术-checklist","text":"幸存者偏差：高估了成功的概率 看清楚自己 是否高估自己 是否陷入从众心理 是否与沉没成本难舍难分 是否是互惠互利陷阱 摆脱确认偏差，不要证明自己是正确的 是否屈服于权威 是否依据对比来判断（请不要怎么做） 现成偏见 是否故意营造一种危机气氛 明确判断他人的能力范围 警惕控制错觉 警惕激励过敏 是否是平均值会起作用？ 警惕公地悲剧 切勿只以结果判断决定 面对选择，遵守自己的标准 排除对他人好感的影响 禀赋效应 let it go 无巧不成书，如果从不发生才令人感到意外 唱反调的人也许是最重要的人 0风险偏误 稀有性谬论 概率偏误-前车之鉴后事之师 独立事件-赌徒谬论 锚定效应，你的锚在哪里？ 警惕归纳法，警惕黑天鹅事件 厌恶风险，但不要无视损失 社会性懈怠 赢家诅咒-你会得到什么、失去什么 是否高估了人的影响 相互关系不等同于因果关系 避免光环效应过度影响总体印象 合理不一定真实 不要被框架效应限制注意力 遇到不明情况，就会发生行动偏误 不作为偏误，如果不解决问题，你就是问题的一部分 自利偏误，为什么你从来不自责 避免长时间负面影响 自我选择偏误 联想偏误，不要欠拟合也不要过拟合 认知失调，是否在自我安慰 即使行乐，只限周末，不要为了眼前的利益破坏未来的利益","link":"/2020/02/01/2020/2020-02-01-%E6%B8%85%E9%86%92%E6%80%9D%E8%80%83%E7%9A%84%E8%89%BA%E6%9C%AF-checklist/"},{"title":"IM系统关键点梳理","text":"","link":"/2020/03/23/2020/2020-02-23-IM%E7%B3%BB%E7%BB%9F%E5%85%B3%E9%94%AE%E7%82%B9%E6%A2%B3%E7%90%86/"},{"title":"奇怪的知识又增加了- BLNJ导致索引有序性失效","text":"先来看表结构： 1234567891011121314CREATE TABLE a ( `id`bigint AUTO_INCREMENT , `a` int, `b` int, PRIMARY KEY (`id`), KEY `idx_a_b` (`a`,`b`));CREATE TABLE b ( `id`bigint AUTO_INCREMENT , `b` int, `c` int, PRIMARY KEY (`id`)) 看一下join语句，因为b上没有索引，所以mysql用的BLNJ： 1234explain select * from a join b using(b)where a = 1order by a, b; id select_type table partitions type possible_keys key key_len ref rows filtered extra 1 SIMPLE a null ref idx_a_b idx_a_b 4 const 5206 100.00 Using temporary; Using filesort 1 SIMPLE b null ALL null null null Null 1000 100.00 Using where; Using join buffer (Block Nested Loop) 如果b表有索引的话： 1234567CREATE TABLE b ( `id`bigint AUTO_INCREMENT , `b` int, `c` int, PRIMARY KEY (`id`), KEY `idx_b` (`b`)) id select_type table partitions type possible_keys key key_len ref rows filtered extra 1 SIMPLE a null ref idx_a_b idx_a_b 8 Const 5206 100.00 Using index condition 1 SIMPLE b null Ref idx_b Idx_b 4 b.b 50 100.00 null 可以发现a表idx_a_b有序性没有利用上，至于原因，先看一下BNLJ执行的流程图: 执行过程为： 扫描表 t1，顺序读取数据行放入 join_buffer 中，直到 join_buffer 满了，继续第 2 步； 扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回； 清空 join_buffer； 继续扫描表 t1，顺序读取之后数据放入 join_buffer 中，继续执行第 2 步，直到所有数据读取完毕。 其中隐含的问题在于第二步：即使t1表的数据是有序读取到join_buffer中的，由于是先扫描t2表再关联join_buffer数据，导致join_buffer中的有序性失效。 如果表b有索引idx_b,那么使用BKA算法第二步的关联顺序与BNLJ相反，是先扫描join_buffer后通过索引关联t2,则可以利用join_buffer中的有序数据。","link":"/2020/03/12/2020/2020-03-12-%E5%A5%87%E6%80%AA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%8F%88%E5%A2%9E%E5%8A%A0%E4%BA%86-BLNJ%E5%AF%BC%E8%87%B4%E7%B4%A2%E5%BC%95%E6%9C%89%E5%BA%8F%E6%80%A7%E5%A4%B1%E6%95%88/"},{"title":"高并发系统-数据库关键点梳理","text":"在线脑图","link":"/2020/03/23/2020/2020-03-23-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%B3%E9%94%AE%E7%82%B9%E6%A2%B3%E7%90%86/"},{"title":"[片段] 方法参数收集","text":"以前的代码，用于收集当前方法的所有参数，放在map中方便调取 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import com.google.common.collect.ImmutableMap;import lombok.Data;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.stereotype.Component;import java.util.Arrays;import java.util.Collections;import java.util.HashMap;import java.util.Map;import java.util.stream.IntStream;@Aspect@Componentpublic class ArgumentsCollector { private static final ThreadLocal&lt;Map&lt;String, Object&gt;&gt; ARGUMENTS = ThreadLocal.withInitial(ImmutableMap::of); static Map&lt;String, Object&gt; getArgs() { return ARGUMENTS.get(); } private Object[] args(Object[] args, int exceptLength) { if (exceptLength == args.length) { return args; } return Arrays.copyOf(args, exceptLength); } @Pointcut(&quot;@annotation(CollectArguments)&quot;) void collectArgumentsAnnotationPointCut() { } @Before(&quot;collectArgumentsAnnotationPointCut()&quot;) public void doAccessCheck(JoinPoint joinPoint) { final String[] parameterNames = ((MethodSignature) joinPoint.getSignature()).getParameterNames(); final Object[] args = args(joinPoint.getArgs(), parameterNames.length); ARGUMENTS.set(Collections.unmodifiableMap((IntStream.range(0, parameterNames.length) .mapToObj(idx -&gt; Tuple2.of(parameterNames[idx], args[idx])) .collect(HashMap::new, (m, t) -&gt; m.put(t.getT1(), t.getT2()), HashMap::putAll)))); } @After(&quot;collectArgumentsAnnotationPointCut()&quot;) public void remove() { ARGUMENTS.remove(); } @Data private static class Tuple2&lt;T1, T2&gt; { private T1 t1; private T2 t2; Tuple2(T1 t1, T2 t2) { this.t1 = t1; this.t2 = t2; } public static &lt;T1, T2&gt; Tuple2&lt;T1, T2&gt; of(T1 t1, T2 t2) { return new Tuple2&lt;&gt;(t1, t2); } }} 附送一段代码，用于将方法中收集的参数转换成Bean 12345678910111213141516import org.springframework.beans.BeanUtils;import org.springframework.beans.MutablePropertyValues;import org.springframework.validation.DataBinder;public class BinderUtil { BinderUtil() { } @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; T getTarget(Class&lt;T&gt; beanClazz) { final DataBinder binder = new DataBinder(BeanUtils.instantiate(beanClazz)); binder.bind(new MutablePropertyValues(ArgumentsCollector.getArgs())); return (T) binder.getTarget(); }} 使用实例： 12345678910@Override@CollectArgumentspublic List&lt;PsJobSequenceVO&gt; findJobSequence( String jobSeqGroupId, String jobSeqId, Integer state, Date endDate) { return jobSequenceHandler.findJobSequence(BinderUtil.getTarget(PsJobSequenceFindRO.class)).getData();}","link":"/2020/03/27/2020/2020-03-27-%5B%E7%89%87%E6%AE%B5%5D%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0%E6%94%B6%E9%9B%86/"},{"title":"消息队列基础概念","text":"消息队列提供的功能 异步处理 流量控制 消息解耦 队列和主题的区别最初的消息队列，就是一个严格意义上的队列。在计算机领域，“队列（Queue）”是一种数据结构，有完整而严格的定义。在维基百科中，队列的定义是这样的： 队列是先进先出（FIFO, First-In-First-Out）的线性表（Linear List）。在具体应用中通常用链表或者数组来实现。队列只允许在后端（称为 rear）进行插入操作，在前端（称为 front）进行删除操作。 早期的消息队列，就是按照“队列”的数据结构来设计的。我们一起看下这个图，生产者（Producer）发消息就是入队操作，消费者（Consumer）收消息就是出队也就是删除操作，服务端存放消息的容器自然就称为“队列”。 这就是最初的一种消息模型：队列模型。 如果需要将一份消息数据分发给多个消费者，要求每个消费者都能收到全量的消息，例如，对于一份订单数据，风控系统、分析系统、支付系统等都需要接收消息。这个时候，单个队列就满足不了需求，一个可行的解决方式是，为每个消费者创建一个单独的队列，让生产者发送多份。 为了解决这个问题，演化出了另外一种消息模型：“发布 - 订阅模型（Publish-Subscribe Pattern）”。 在发布 - 订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic）。发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。“订阅”在这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。 保障消息队列不丢失其实，现在主流的消息队列产品都提供了非常完善的消息可靠性保证机制，完全可以做到在消息传递过程中，即使发生网络中断或者硬件故障，也能确保消息的可靠传递，不丢消息。 绝大部分丢消息的原因都是由于开发者不熟悉消息队列，没有正确使用和配置消息队列导致的。虽然不同的消息队列提供的 API 不一样，相关的配置项也不同，但是在保证消息可靠传递这块儿，它们的实现原理是一样的。 检测消息丢失的方法 分布式链路跟踪系统 根据生产者标示+分区号+递增消息号判断 生产者保存需要核对是否丢失的数据，消费者消费完之后需要与生产者核对数据 像 Kafka 和 RocketMQ 这样的消息队列，它是不保证在 Topic 上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。 如果你的系统中 Producer 是多实例的，由于并不好协调多个 Producer 之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。 Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。 如何确保消息不丢失一条消息从生产到消费完成这个过程，可以划分三个阶段： 生产阶段 在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。 只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。 你在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。 存储阶段 在存储阶段正常情况下，只要 Broker 在正常运行，就不会出现丢失消息的问题，但是如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。 如果对消息的可靠性要求非常高，可以通过配置 Broker 参数来避免因为宕机丢消息。 对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。例如，在 RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘。 如果是 Broker 是由多个节点组成的集群，需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失。 消费阶段 消费阶段采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。 你在编写消费代码时需要注意的是，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。 对于kafka的相关使用可以参考之前的一篇文章【消息队列(一)-如何解决消息丢失】 解决消息重复问题消息重复的情况必然存在在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是： At most once: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。 At least once: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。 Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。 这个服务质量标准不仅适用于 MQTT，对所有的消息队列都是适用的。我们现在常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息队列很难保证消息不重复。 利用幂等性解决重复消息问题 利用数据库的唯一约束实现幂等 不光是可以使用关系型数据库，只要是支持类似“INSERT IF NOT EXIST”语义的存储类系统都可以用于实现幂等，比如，你可以用 Redis 的 SETNX 命令来替代数据库中的唯一约束，来实现幂等消费。 为更新的数据设置前置条件 另外一种实现幂等的思路是，给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。 但是，如果我们要更新的数据不是数值，或者我们要做一个比较复杂的更新操作怎么办？用什么作为前置判断条件呢？更加通用的方法是，给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新。 记录并检查操作 如果上面提到的两种实现幂等方法都不能适用于你的场景，还有一种通用性最强，适用范围最广的实现幂等性方法：记录并检查操作，也称为“Token 机制或者 GUID（全局唯一 ID）机制”，实现的思路特别简单：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。 具体的实现方法是，在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。 原理和实现是不是很简单？其实一点儿都不简单，在分布式系统中，这个方法其实是非常难实现的，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug。 对于这个问题，当然我们可以用事务来实现，也可以用锁来实现，但是在分布式系统中，无论是分布式事务还是分布式锁都是比较难解决问题。 对于kafka的相关使用可以参考之前的一篇文章【消息队列(二)-消息幂等】 处理消息积压优化消息收发性能，预防消息积压的方法有两种，增加批量或者是增加并发，在发送端这两种方法都可以使用，在消费端需要注意的是，增加并发需要同步扩容分区数量，否则是起不到效果的。 对于系统发生消息积压的情况，需要先解决积压，再分析原因，毕竟保证系统的可用性是首先要解决的问题。快速解决积压的方法就是通过水平扩容增加 Consumer 的实例数量。","link":"/2020/04/02/2020/2020-04-02-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"title":"消息队列基础补充","text":"在线脑图","link":"/2020/04/08/2020/2020-04-08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%84%91%E5%9B%BE/"},{"title":"IM系统基础-IM系统结构","text":"从一个 IM 系统开发者的角度看，聊天系统大概由这几大部分组成：客户端、接入服务、业务处理服务、存储服务和外部接口服务。 客户端。客户端一般是用户用于收发消息的终端设备，内置的客户端程序和服务端进行网络通信，用来承载用户的互动请求和消息接收功能。 接入服务。接入服务可以认为是服务端的门户，为客户端提供消息收发的出入口。发送的消息先由客户端通过网络给到接入服务，然后再由接入服务递交到业务层进行处理。 接入服务主要有四块功能： 连接保持 当服务端有消息需要推送给客户端时，也是将经过业务层处理的消息先递交给接入层，再由接入层通过网络发送到客户端。 协议解析 在很多基于私有通信协议的 IM 系统实现中，接入服务还提供协议的编解码工作，编解码实际主要是为了节省网络流量，系统会针对传输的内容进行紧凑的编码（比如 Protobuf），为了让业务处理时不需要关心这些业务无关的编解码工作，一般由接入层来处理。 Session 维护 session 的作用是标识“哪个用户在哪个 TCP 连接”，用于后续的消息推送能够知道，如何找到接收人对应的连接来发送。 消息推送 接入服务还负责最终消息的推送执行，也就是通过网络连接把最终的消息从服务器传输送达到用户的设备上。 业务处理服务。业务处理服务是真正的消息业务逻辑处理层，比如消息的存储、未读数变更、更新最近联系人等，这些内容都是业务处理的范畴。 我们可以想象得到，业务处理服务是整个 IM 系统的中枢大脑，负责各种复杂业务逻辑的处理。 就好比你的信到达分拨中心后，分拨中心可能需要给接收人发条短信告知一下，或者分拨中心发现接收人告知过要拒绝接收这个发送者的任何信件，因此会在这里直接把信件退回给发信人。 存储服务。这个比较好理解，账号信息、关系链，以及消息本身，都需要进行持久化存储。 另外一般还会有一些用户消息相关的设置，也会进行服务端存储，比如：用户可以设置不接收某些人的消息。我们可以把它理解成辖区内所有人的通信地址簿，以及储存信件的仓库。 外部接口服务。由于手机操作系统的限制，以及资源优化的考虑，大部分 App 在进程关闭，或者长时间后台运行时，App 和 IM 服务端的连接会被手机操作系统断开。这样当有新的消息产生时，就没法通过 IM 服务再触达用户，因而会影响用户体验。 为了让用户在 App 未打开时，或者在后台运行时，也能接收到新消息，我们会将消息给到第三方外部接口服务，来通过手机操作系统自身的公共连接服务来进行操作系统级的“消息推送”，通过这种方式下发的消息一般会在手机的“通知栏”对用户进行提醒和展示。 这种最常用的第三方系统推送服务有苹果手机自带的 APNs（Apple Push Notification service）服务、安卓手机内置的谷歌公司的 GCM（Google Cloud Messaging）服务等。 但 GCM 服务在国内无法使用，为此很多国内手机厂商在各自手机系统中，也提供类似的公共系统推送服务，如小米、华为、OPPO、vivo 等手机厂商都有相应的 SDK 提供支持。","link":"/2020/04/13/2020/2020-04-13-IM%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80-IM%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"},{"title":"为什么引入间隙锁","text":"为了便于说明问题，我们先使用一个小一点儿的表，建表和初始化语句如下： 123456789101112131415CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB; insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25); 这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。 下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？ 1select * from t where d = 5 for update; 比较好理解的是，这个语句会命中 d = 5 的这一行，对应的主键 id = 5，因此在 select 语句执行完成后，会在id = 5 这一行主键上加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。 由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？ 我们知道，InnoDB 的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。 幻读是什么？现在，我们就来分析一下，假设只在 id = 5 这一行加锁，而其他行的不加锁的话，会怎么样。 下面先来看一下这个场景（这个结果是建立在前面假设之上，实际上是错误的）： 假设只在 id = 5 这一行加行锁，可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * fom t where d=5 for update。我们来看一下这三条 SQL 语句，分别会返回什么结果。 Q1 只返回 id = 5 这一行； 在 T2 时刻，session B 把 id = 0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id = 0 和 id = 5 这两行； 在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id = 0、id = 1 和 id = 5 的这三行。 其中，Q3 读到 id = 1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 这里，我需要对“幻读”做一个说明： 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在当前读下才会出现。 上面 session B 的修改结果，被 session A 之后的 select 语句用当前读看到，不能称为幻读。幻读仅专指新插入的行。 如果只从我们学到的事务可见性规则来分析的话，上面这三条 SQL 语句的返回结果都没有问题。 因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。 幻读有什么问题？首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。所以我们假设只锁了id = 5这一行的语义与select * from t where d = 5 for update 不同。 其次，是数据一致性的问题。 这个数据不一致到底是怎么引入的？肯定是前面的假设有问题。 我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。 由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。 这样对于 id = 0 这一行，在数据库里的最终结果还是 (0,5,5)。在 binlog 里面，执行序列是这样的： 1234567insert into t values(1,1,5); /*(1,1,5)*/update t set c=5 where id=1; /*(1,5,5)*/ update t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/ update t set d=5 where id=0; /*(0,0,5)*/update t set c=5 where id=0; /*(0,5,5)*/ 可以看到，按照日志顺序执行，id = 0 这一行的最终结果也是 (0,5,5)。所以，id = 0 这一行的问题解决了。 但同时你也可以看到，id = 1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都上了锁，还是阻止不了 id = 1 这一行的插入和更新呢？ 原因很简单。在 T3 时刻，我们给所有行加锁的时候，id = 1 这一行还不存在，不存在也就加不上锁。 也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。 如何解决幻读？现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。 顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。 这样，当你执行 select * from t where d=5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。 也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。 现在你知道了，数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。 比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。 也就是说，跟行锁有冲突关系的是“另外一个行锁”。 但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。 这句话不太好理解，我给你举个例子： 这里 session B 并不会被堵住。因为表 t 里并没有 c = 7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。 备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。 你可能会问说，这个 supremum 从哪儿来的呢？ 这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样才符合我们前面说的“都是前开后闭区间”。 间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。 对应到我们这个例子的表来说，业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下： 123456789begin;select * from t where id=N for update; /* 如果行不存在 */insert into t values(N,N,N);/* 如果行存在 */update t set d=N set id=N; commit; 这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用 for update 锁起来，已经是最严格的模式了，怎么还会有死锁呢？ 这里，我用两个 session 来模拟并发，并假设 N=9。 图 8 间隙锁导致的死锁 你看到了，其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下： session A 执行 select … for update 语句，由于 id = 9 这一行并不存在，因此会加上间隙锁 (5,10); session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功； session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待； session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。 至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。 你现在知道了，间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。 你可能会说，为了解决幻读的问题，我们引入了这么一大串内容，有没有更简单一点的处理方法呢。 我在文章一开始就说过，如果没有特别说明，今天和你分析的问题都是在可重复读隔离级别下的，间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。","link":"/2020/02/27/2020/2020-02-27-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BC%95%E5%85%A5%E9%97%B4%E9%9A%99%E9%94%81/"},{"title":"排查docker oomkillded问题","text":"年前docker oomkilled 问题一直在困扰我们项目组，大致现象为java堆Xmx配置了6G，但运行一段时间后常驻内存RSS从5G逐渐增长到8G容器阈值，最后报出om killed 之后重启。因为我们业务对内存需求不是很迫切，所以占用8G内存明显不合理，所以之后有了一场漫长的排查问题之旅。 基础中的基础-JVM内存模型开始逐步对堆外内存进行排查，首先了解一下JVM内存模型。根据JVM规范，JVM运行时数据区共分为虚拟机栈、堆、方法区、程序计数器、本地方法栈五个部分。￼ PC 寄存器，也叫程序计数器。可以看成是当前线程所执行的字节码的行号指示器。不是重点。 虚拟机栈，描述Java方法执行的内存区域，它是线程私有的，栈帧在整个JVM体系中的地位颇高,包括局部变量表、操作栈、动态连接、方法返回地址等。当申请不到空间时，会抛出 OutOfMemoryError。 本地方法栈，和虚拟机栈实现的功能与抛出异常几乎相同。 堆内存。堆内存是 JVM 所有线程共享的部分，在虚拟机启动的时候就已经创建。所有的对象和数组都在堆上进行分配。这部分空间可通过 GC 进行回收。当申请不到空间时会抛出 OutOfMemoryError。 Metaspace（元空间）在JDK 1.8开始，方法区实现采用Metaspace代替，这些元数据信息直接使用本地内存来分配。元空间与永久代之间最大的区别在于：元空间不属于JVM使用的内存，而是使用（进程中的）直接内存。当申请不到空间时会抛出 OutOfMemoryError。 直接内存java 8下是指除了Xmx设置的java堆外，java进程使用的其他内存。主要包括：DirectByteBuffer分配的内存，JNI里分配的内存，线程栈分配占用的系统内存，jvm本身运行过程分配的内存，codeCache，metaspace元数据空间。 JVM监控分析 可以看到重启前堆内存、栈内存、元空间、直接内存占用空间都没有异常，多数问题通过监控就能定位大致方向，可惜这次监控大法没有生效，怀疑是JVM问题转向JVM原生内存使用方向排查。 使用NMT排查JVM原生内存使用Native Memory Tracking（NMT）使用NMT是Java7U40引入的HotSpot新特性，可用于监控JVM原生内存的使用，但比较可惜的是，目前的NMT不能监控到JVM之外或原生库分配的内存。java进程启动时指定开启NMT（有一定的性能损耗），输出级别可以设置为“summary”或“detail”级别。如： 12-XX:NativeMemoryTracking=summary 或者 -XX:NativeMemoryTracking=detail 开启后，通过jcmd可以访问收集到的数据。 1jcmd &lt;pid&gt; VM.native_memory [summary | detail | baseline | summary.diff | detail.diff 如：jcmd 1 VM.native_memory，输出如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Native Memory Tracking:Total: reserved=12259645KB（保留内存）, committed=11036265KB （提交内存）堆内存使用情况，保留内存和提交内存和Xms、Xmx一致，都是8G。- Java Heap (reserved=8388608KB, committed=8388608KB) (mmap: reserved=8388608KB, committed=8388608KB)用于存储类元数据信息使用到的原生内存，总共12045个类，整体实际使用了79M内存。- Class (reserved=1119963KB, committed=79751KB) (classes #12045) (malloc=1755KB #29277) (mmap: reserved=1118208KB, committed=77996KB)总共2064个线程，提交内存是2.1G左右，一个线程1M，和设置Xss1m相符。- Thread (reserved=2130294KB, committed=2130294KB) (thread #2064) (stack: reserved=2120764KB, committed=2120764KB) (malloc=6824KB #10341) (arena=2706KB #4127)JIT的代码缓存，12045个类JIT编译后代码缓存整体使用79M内存。- Code (reserved=263071KB, committed=79903KB) (malloc=13471KB #15191) (mmap: reserved=249600KB, committed=66432KB)GC相关使用到的一些堆外内存，比如GC算法的处理锁会使用一些堆外空间。118M左右。- GC (reserved=118432KB, committed=118432KB) (malloc=93848KB #453) (mmap: reserved=24584KB, committed=24584KB)JAVA编译器自身操作使用到的一些堆外内存，很少。- Compiler (reserved=975KB, committed=975KB) (malloc=844KB #1074) (arena=131KB #3)Internal：memory used by the command line parser, JVMTI, properties等。- Internal (reserved=117158KB, committed=117158KB) (malloc=117126KB #44857) (mmap: reserved=32KB, committed=32KB)Symbol：保留字符串（Interned String）的引用与符号表引用放在这里，17M左右- Symbol (reserved=17133KB, committed=17133KB) (malloc=13354KB #145640) (arena=3780KB #1)NMT本身占用的堆外内存，4M左右- Native Memory Tracking (reserved=4402KB, committed=4402KB) (malloc=396KB #5287) (tracking overhead=4006KB)不知道啥，用的很少。- Arena Chunk (reserved=272KB, committed=272KB) (malloc=272KB)其他未分类的堆外内存占用，100M左右。- Unknown (reserved=99336KB, committed=99336KB) (mmap: reserved=99336KB, committed=99336KB) 保留内存（reserved）：reserved memory 是指JVM 通过mmaped PROT_NONE 申请的虚拟地址空间，在页表中已经存在了记录（entries），保证了其他进程不会被占用，且保证了逻辑地址的连续性，能简化指针运算。 提交内存（commited）：committed memory 是JVM向操做系统实际分配的内存（malloc/mmap）,mmaped PROT_READ | PROT_WRITE,仍然会page faults，但是跟 reserved 不同，完全内核处理像什么也没发生一样。 这里需要注意的是：由于malloc/mmap的lazy allocation and paging机制，即使是commited的内存，也不一定会真正分配物理内存。 malloc/mmap is lazy unless told otherwise. Pages are only backed by physical memory once they’re accessed. Tips：由于内存是一直在缓慢增长，因此在使用NMT跟踪堆外内存时，一个比较好的办法是，先建立一个内存使用基线，一段时间后再用当时数据和基线进行差别比较，这样比较容易定位问题。 1jcmd 1 VM.native_memory baseline 同时pmap看一下物理内存的分配，RSS占用了10G。 1pmap -x 1 | sort -n -k3 ￼ 运行一段时间后，做一下summary级别的diff，看下内存变化，同时再次pmap看下RSS增长情况。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748jcmd 1 VM.native_memory summary.diffNative Memory Tracking:Total: reserved=13089769KB +112323KB, committed=11877285KB +117915KB- Java Heap (reserved=8388608KB, committed=8388608KB) (mmap: reserved=8388608KB, committed=8388608KB)- Class (reserved=1126527KB +2161KB, committed=85771KB +2033KB) (classes #12682 +154) (malloc=2175KB +113KB #37289 +2205) (mmap: reserved=1124352KB +2048KB, committed=83596KB +1920KB)- Thread (reserved=2861485KB +94989KB, committed=2861485KB +94989KB) (thread #2772 +92) (stack: reserved=2848588KB +94576KB, committed=2848588KB +94576KB) (malloc=9169KB +305KB #13881 +460) (arena=3728KB +108 #5543 +184)- Code (reserved=265858KB +1146KB, committed=94130KB +6866KB) (malloc=16258KB +1146KB #18187 +1146) (mmap: reserved=249600KB, committed=77872KB +5720KB)- GC (reserved=118433KB +1KB, committed=118433KB +1KB) (malloc=93849KB +1KB #487 +24) (mmap: reserved=24584KB, committed=24584KB)- Compiler (reserved=1956KB +253KB, committed=1956KB +253KB) (malloc=1826KB +253KB #2098 +271) (arena=131KB #3)- Internal (reserved=203932KB +13143KB, committed=203932KB +13143KB) (malloc=203900KB +13143KB #62342 +3942) (mmap: reserved=32KB, committed=32KB)- Symbol (reserved=17820KB +108KB, committed=17820KB +108KB) (malloc=13977KB +76KB #152204 +257) (arena=3844KB +32 #1)- Native Memory Tracking (reserved=5519KB +517KB, committed=5519KB +517KB) (malloc=797KB +325KB #9992 +3789) (tracking overhead=4722KB +192KB)- Arena Chunk (reserved=294KB +5KB, committed=294KB +5KB) (malloc=294KB +5KB)- Unknown (reserved=99336KB, committed=99336KB) (mmap: reserved=99336KB, committed=99336KB ￼ 发现这段时间pmap看到的RSS增长了3G多，但NMT观察到的内存增长了不到120M，还有大概2G多常驻内存不知去向，因此也基本排除了由于JVM自身管理的堆外内存的嫌疑。 gdb分析内存块内容上面提到使用pmap来查看进程的内存映射，pmap命令实际是读取了/proc/pid/maps和/porc/pid/smaps文件来输出。发现一个细节，pmap取出的内存映射发现很多64M大小的内存块。这种内存块逐渐变多且占用的RSS常驻内存也逐渐增长到reserved保留内存大小，内存增长的2G多基本上也是由于这些64M的内存块导致的，因此看一下这些内存块里具体内容。 pmap -x 1看一下实际内存分配情况：￼ 找一块内存块进行dump： 1gdb --batch --pid 1 -ex &quot;dump memory a.dump 0x7fd488000000 0x7fd488000000+56124000&quot; 简单分析一下内容，发现绝大部分是乱码的二进制内容，看不出什么问题。strings a.dump | less或者： hexdump -C a.dump | less或者： view a.dump 没啥思路的时候，随便搜了一下发现貌似很多人碰到这种64M内存块的问题，了解到glibc的内存分配策略在高版本有较大调整： 从glibc 2.11（为应用系统在多核心CPU和多Sockets环境中高伸缩性提供了一个动态内存分配的特性增强）版本开始引入了per thread arena内存池，Native Heap区被打散为sub-pools ，这部分内存池叫做Arena内存池。也就是说，以前只有一个main arena，目前是一个main arena（还是位于Native Heap区） + 多个per thread arena，多个线程之间不再共用一个arena内存区域了，保证每个线程都有一个堆，这样避免内存分配时需要额外的锁来降低性能。main arena主要通过brk/sbrk系统调用去管理，per thread arena主要通过mmap系统调用去分配和管理。 一个32位的应用程序进程，最大可创建 2 CPU总核数个arena内存池（MALLOC_ARENA_MAX），每个arena内存池大小为1MB，一个64位的应用程序进程，最大可创建 8 CPU总核数个arena内存池（MALLOC_ARENA_MAX），每个arena内存池大小为64MB ptmalloc2内存分配和释放 当某一线程需要调用 malloc()分配内存空间时， 该线程先查看线程私有变量中是否已经存在一个分配区，如果存在， 尝试对该分配区加锁，如果加锁成功，使用该分配区分配内存，如果失败， 该线程搜索循环链表试图获得一个没有加锁的分配区。如果所有的分配区都已经加锁，那么 malloc()会开辟一个新的分配区，把该分配区加入到全局分配区循环链表并加锁，然后使用该分配区进行分配内存操作。在释放操作中，线程同样试图获得待释放内存块所在分配区的锁，如果该分配区正在被别的线程使用，则需要等待直到其他线程释放该分配区的互斥锁之后才可以进行释放操作。用户 free 掉的内存并不是都会马上归还给系统，ptmalloc2 会统一管理 heap 和 mmap 映射区域中的空闲的chunk，当用户进行下一次分配请求时， ptmalloc2 会首先试图在空闲的chunk 中挑选一块给用户，这样就避免了频繁的系统调用，降低了内存分配的开销。 ptmalloc2的内存收缩机制 业务层调用free方法释放内存时，ptmalloc2先判断 top chunk 的大小是否大于 mmap 收缩阈值(默认为 128KB)，如果是的话，对于主分配区，则会试图归还 top chunk 中的一部分给操作系统。但是最先分配的 128KB 空间是不会归还的，ptmalloc 会一直管理这部分内存，用于响应用户的分配 请求;如果为非主分配区，会进行 sub-heap 收缩，将 top chunk 的一部分返回给操 作系统，如果 top chunk 为整个 sub-heap，会把整个 sub-heap 还回给操作系统。做 完这一步之后，释放结束，从 free() 函数退出。可以看出，收缩堆的条件是当前 free 的 chunk 大小加上前后能合并 chunk 的大小大于 64k，并且要 top chunk 的大 小要达到 mmap 收缩阈值，才有可能收缩堆。 ptmalloc2的mmap分配阈值动态调整 M_MMAP_THRESHOLD 用于设置 mmap 分配阈值，默认值为 128KB，ptmalloc 默认开启 动态调整 mmap 分配阈值和 mmap 收缩阈值。当用户需要分配的内存大于 mmap 分配阈值，ptmalloc 的 malloc()函数其实相当于 mmap() 的简单封装，free 函数相当于 munmap()的简单封装。相当于直接通过系统调用分配内存， 回收的内存就直接返回给操作系统了。因为这些大块内存不能被 ptmalloc 缓存管理，不能重用，所以 ptmalloc 也只有在万不得已的情况下才使用该方式分配内存。 如何优化解决三种方案：第一种：控制分配区的总数上限。默认64位系统分配区数为：cpu核数*8，如当前环境40核系统分配区数为320个，每个64M上限的话最多可达20G，限制上限后，后续不够的申请会直接走mmap分配和munmap回收，不会进入ptmalloc2的buffer池。所以第一种方案调整一下分配池上限个数到4： 1export MALLOC_ARENA_MAX=4 第二种：之前降到ptmalloc2默认会动态调整mmap分配阈值，因此对于较大的内存请求也会进入ptmalloc2的内存buffer池里，这里可以去掉ptmalloc的动态调整功能。可以设置 M_TRIM_THRESHOLD，M_MMAP_THRESHOLD，M_TOP_PAD 和 M_MMAP_MAX 中的任意一个。这里可以固定分配阈值为128K，这样超过128K的内存分配请求都不会进入ptmalloc的buffer池而是直接走mmap分配和munmap回收（性能上会有损耗）： 1234export MALLOC_MMAP_THRESHOLD_=131072export MALLOC_TRIM_THRESHOLD_=131072export MALLOC_TOP_PAD_=131072export MALLOC_MMAP_MAX_=65536 第三种：使用tcmalloc来替代默认的ptmalloc2。google的tcmalloc提供更优的内存分配效率，性能更好，ThreadCache会阶段性的回收内存到CentralCache里。 解决了ptmalloc2中arena之间不能迁移导致内存浪费的问题。 总结收获 定位问题，一定要了解问题的领域范围，在这次排查中，定位OOM问题领域顺序就是 jvm内存 -&gt; jvm内部内存 -&gt; 进程内存。 操作系统知识不能丢，扎实的基础知识可以节省非常多百度的时间和推理问题的时间 知识领域是相同的，比如这次的ptmalloc内存分配基本原理和metaspace内存分配、netty的内存分配原理非常相似 当时排查问题时因为已经定位到是内存分配问题，所以没有留下问题排查中间过程的相关数据。最近偶然看到一篇博客的记录和我的经历极为相似，于是我参考博客和自己的排查经验整合了这篇排查问题记录。结果和过程都很重要，只有结果，没有过程容易招致他人的不理解，能被人理解也是一门学问～","link":"/2020/05/10/2020/2020-05-10-%E6%8E%92%E6%9F%A5docker_oomkillded%E9%97%AE%E9%A2%98/"},{"title":"使用Visual Studio Code阅读Switch Homebrew程序源码","text":"Visual Studio Code是当之无愧的代码利器，我看重的正是它独到的代码提示和Intellisense功能，这能有效帮助我阅读和学习别人编写的源码。而破解后的Switch上可以安装格式为“nro”的自制程序，它们使用C语言编写，为了方便阅读其源代码，我对VS Code进行如下配置。 第一步：搭建编译环境DevKitPro组织维护着为任天堂系列主机做开发的工具集，这使得下载开发Switch上的程序更为简便。**在这里下载包管理工具dkp-pacman**，然后安装下列包： 1sudo dkp-pacman -S switch-dev 使用Root权限安装，默认会装到/opt/devkitpro。 如果MacOS 版本为 Catalina 会报错： 123error: Partition / is mounted read onlyerror: not enough free disk spaceerror: failed to commit transaction (not enough free disk space) 因为Catalina 的根分区是只读的，所以可以用下面的命令指定安装位置: 1sudo dkp-pacman -S switch-dev -r /System/Volumes/Data 第二步：配置Code在Code中打开Homebrew程序的源码目录，按Ctrl+Alt+P呼出命令面板，找到“C/C++: Edit configurations”，点击打开C/C++扩展的配置文件“c_cpp_properties.json”。 然后将以下路径添加到“includePath”列表中。添加过程注意遵循JSON语法： 12345678910111213141516171819202122{ &quot;configurations&quot;: [ { &quot;name&quot;: &quot;switch&quot;, &quot;includePath&quot;: [ &quot;${workspaceFolder}/**&quot;, &quot;/opt/devkitpro/devkitA64/aarch64-none-elf/include/**&quot;, &quot;/opt/devkitpro/libnx/include/**&quot;, &quot;/opt/devkitpro/portlibs/switch/include/**&quot; ], &quot;defines&quot;: [], &quot;macFrameworkPath&quot;: [ &quot;/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks&quot; ], &quot;compilerPath&quot;: &quot;/opt/devkitpro/devkitA64/bin/aarch64-none-elf-gcc&quot;, &quot;cStandard&quot;: &quot;c11&quot;, &quot;cppStandard&quot;: &quot;c++17&quot;, &quot;intelliSenseMode&quot;: &quot;clang-x64&quot; } ], &quot;version&quot;: 4} 即刻生效。 第三步：测试可以遵循以下的方法检验代码提示功能是否生效： 将鼠标移到任意一个对象名上，可以清楚看到它的定义； 按Ctrl键，将鼠标指针指向对象名或头文件名，它们会变成超链接，点进去即可跳转到它们的定义处。","link":"/2020/06/28/2020/2020-06-28-SwitchHomeBrew/"},{"title":"Hash冲突解决方式","text":"Hash冲突主要有两种解决办法，开放寻址法和链表法。这两种冲突解决办法在实际的软件开发中都非常常用。比如，Java 中 LinkedHashMap 就采用了链表法解决冲突，ThreadLocalMap 是通过线性探测的开放寻址法来解决冲突。那么这两种冲突解决方法各有什么优势和劣势，又各自适用哪些场景吗？ 开放寻址法我们先来看看，开放寻址法的优点有哪些。 开放寻址法不像链表法，需要拉很多链表。散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。而且，这种方法实现的散列表，序列化起来比较简单。链表法包含指针，序列化起来就没那么容易。你可不要小看序列化，很多场合都会用到的。我们后面就有一节会讲什么是数据结构序列化、如何序列化，以及为什么要序列化。 我们再来看下，开放寻址法有哪些缺点。 上一节我们讲到，用开放寻址法解决冲突的散列表，删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据。而且，在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。所以，使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。 所以，我总结一下，当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。 链表法首先，链表法对内存的利用率比开放寻址法要高。因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好。实际上，这一点也是链表优于数组的地方。 链表法比起开放寻址法，对大装载因子的容忍度更高。开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。但是对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。 链表因为要存储指针，所以对于比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍。而且，因为链表中的结点是零散分布在内存中的，不是连续的，所以对 CPU 缓存是不友好的，这方面对于执行效率也有一定的影响。 当然，如果我们存储的是大对象，也就是说要存储的对象的大小远远大于一个指针的大小（4 个字节或者 8 个字节），那链表中指针的内存消耗在大对象面前就可以忽略了。 实际上，我们对链表法稍加改造，可以实现一个更加高效的散列表。那就是，我们将链表法中的链表改造为其他高效的动态数据结构，比如跳表、红黑树。这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 O(logn)。这样也就有效避免了前面讲到的散列碰撞攻击。 所以，我总结一下，基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。","link":"/2020/07/11/2020/2020-07-11-Hash%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F/"},{"title":"数据库数据迁移方案","text":"更换数据库这个事儿，是一个非常大的技术挑战，因为我们需要保证整个迁移过程中，既不能长时间停服，也不能丢数据。 实际上，无论是新版本的程序，还是新的数据库，即使我们做了严格的验证测试，做了高可用方案，刚刚上线的系统，它的稳定性总是没有那么好的，需要一个磨合的过程，才能逐步达到一个稳定的状态，这是一个客观规律。这个过程中一旦出现故障，如果不能及时恢复，造成的损失往往是我们承担不起的。 所以我们在设计迁移方案的时候，一定要做到，每一步都是可逆的。要保证，每执行一个步骤后，一旦出现问题，能快速地回滚到上一个步骤。这是很多同学在设计这种升级类技术方案的时候，容易忽略的问题。 第一步-复制旧库数据首先要做的就是，把旧库的数据复制到新库中。对于大规模数据可以使用自增字段（自增主键/创建时间）作为复制的区间，在业务低谷期分批复制数据到新库中。 第二步-同步数据因为旧库还在服务线上业务，所以不断会有数据写入旧库，我们不仅要往新库复制数据，还要保证新旧两个库的数据是实时同步的。所以，我们需要用一个同步程序来实现新旧两个数据库实时同步。 我们可以使用 Binlog 实时同步数据。如果源库不是 MySQL 的话，就麻烦一点儿，但也可以参考复制状态机理论来实现。这一步不需要回滚，原因是，只增加了一个新库和一个同步程序，对系统的旧库和程序都没有任何改变。即使新上线的同步程序影响到了旧库，只要停掉同步程序就可以了。 第三步-双写然后，我们需要改造一下业务，业务逻辑部分不需要变，DAO 层需要做如下改造： 支持双写新旧两个库，并且预留热切换开关，能通过开关控制三种写状态：只写旧库、只写新库和同步双写。 支持读新旧两个库，同样预留热切换开关，控制读旧库还是新库。 然后上线新版的业务服务，这个时候业务服务仍然是只读写旧库，不读写新库。让这个新版的服务需要稳定运行至少一到二周的时间，期间除了验证新版服务的稳定性以外，还要验证新旧两个库中的数据是否是一致的。这个过程中，如果新版服务有问题，可以立即下线新版服务，回滚到旧版本的服务。 稳定一段时间之后，就可以开启服务的双写开关了。开启双写开关的同时，需要停掉同步程序。这里面有一个问题需要注意一下，就是这个双写的业务逻辑，一定是先写旧库，再写新库，并且以写旧库的结果为准。旧库写成功，新库写失败，返回写成功，但这个时候要记录日志，后续我们会用到这个日志来验证新库是否还有问题。旧库写失败，直接返回失败，就不写新库了。这么做的原因是，不能让新库影响到现有业务的可用性和数据准确性。上面这个过程如果出现问题，可以关闭双写，回滚到只读写旧库的状态。 第四步-对比补偿切换到双写之后，新库与旧库的数据可能会存在不一致的情况，原因有两个：一是停止同步程序和开启双写，这两个过程很难做到无缝衔接，二是双写的策略也不保证新旧库强一致，这时候我们需要上线一个对比和补偿的程序，这个程序对比旧库最近的数据变更，然后检查新库中的数据是否一致，如果不一致，还要进行补偿。 开启双写后，还需要至少稳定运行至少几周的时间，并且期间我们要不断地检查，确保不能有旧库写成功，新库写失败的情况出现。对比程序也没有发现新旧两个库的数据有不一致的情况，这个时候，我们就可以认为，新旧两个库的数据是一直保持同步的。 第五步-流量切换接下来就可以用类似灰度发布的方式，把读请求一点儿一点儿地切到新库上。同样，期间如果出问题的话，可以再切回旧库。全部读请求都切换到新库上之后，这个时候其实读写请求就已经都切换到新库上了，实际的切换已经完成了，但还有后续的收尾步骤。 第六步-下线历史逻辑再稳定一段时间之后，就可以停掉对比程序，把服务的写状态改为只写新库。到这里，旧库就可以下线了。注意，整个迁移过程中，只有这个步骤是不可逆的。但是，这步的主要操作就是摘掉已经不再使用的旧库，对于在用的新库并没有什么改变，实际出问题的可能性已经非常小了。 到这里，我们就完成了在线更换数据库的全部流程。双写版本的服务也就完成了它的历史使命，可以在下一次升级服务版本的时候，下线双写功能。 如何实现对比和补偿程序？在上面的整个切换过程中，如何实现这个对比和补偿程序，是整个这个切换设计方案中的一个难点。这个对比和补偿程序的难度在于，我们要对比的是两个都在随时变换的数据库中的数据。这种情况下，我们没有类似复制状态机这样理论上严谨实际操作还很简单的方法，来实现对比和补偿。但还是可以根据业务数据的实际情况，来针对性地实现对比和补偿，经过一段时间，把新旧两个数据库的差异，逐渐收敛到一致。 像订单这类时效性强的数据，是比较好对比和补偿的。因为订单一旦完成之后，就几乎不会再变了，那我们的对比和补偿程序，就可以依据订单完成时间，每次只对比这个时间窗口内完成的订单。补偿的逻辑也很简单，发现不一致的情况后，直接用旧库的订单数据覆盖新库的订单数据就可以了。 这样，切换双写期间，少量不一致的订单数据，等到订单完成之后，会被补偿程序修正。后续只要不是双写的时候，新库频繁写入失败，就可以保证两个库的数据完全一致。 比较麻烦的是更一般的情况，比如像商品信息这类数据，随时都有可能会变化。如果说数据上有更新时间，那我们的对比程序可以利用这个更新时间，每次在旧库取一个更新时间窗口内的数据，去新库上找相同主键的数据进行对比，发现数据不一致，还要对比一下更新时间。如果新库数据的更新时间晚于旧库数据，那可能是对比期间数据发生了变化，这种情况暂时不要补偿，放到下个时间窗口去继续对比。另外，时间窗口的结束时间，不要选取当前时间，而是要比当前时间早一点儿，比如 1 分钟前，避免去对比正在写入的数据。如果数据连时间戳也没有，那只能去旧库读取 Binlog，获取数据变化，然后去新库对比和补偿。 有一点需要说明的是，上面这些方法，如果严格推敲，都不是百分之百严谨的，都不能保证在任何情况下，经过对比和补偿后，新库的数据和旧库就是完全一样的。但是，在大多数情况下，这些实践方法还是可以有效地收敛新旧两个库的数据差异，你可以酌情采用。 小结设计在线切换数据库的技术方案，首先要保证安全性，确保每一个步骤一旦失败，都可以快速回滚。此外，还要确保迁移过程中不丢数据，这主要是依靠实时同步程序和对比补偿程序来实现。 我把这个复杂的切换过程的要点，按照顺序总结成下面这个列表： 上线同步程序，从旧库中复制数据到新库中，并实时保持同步； 上线双写服务，只读写旧库； 开启双写，同时停止同步程序； 开启对比和补偿程序，确保新旧数据库数据完全一样； 逐步切量读请求到新库上； 下线对比补偿程序，关闭双写，读写都切换到新库上； 下线旧库和服务的双写功能。","link":"/2020/08/18/2020/2020-08-18-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E6%96%B9%E6%A1%88/"},{"title":"接口延迟问题排查整理","text":"问题接口流程梳理根据报错信息,可以看出调用PersonnelSpi.getEmployeeInfo超时,且调用时长超过5s 1com.netflix.hystrix.exception.HystrixRuntimeException: PersonnelSpi.getEmployeeInfo timed-out and fallback disabled 先梳理出PersonnelSpi.getEmployeeInfo执行流程 先从网关获取oauthToken 通过网关调用人事cr/employee/info接口 目前可以得出结论是这两步耗时大于5s 排除人事接口问题通过报警的data_trace字段,可以在fast7层中查询Proxy的access日志: 查询结果类似这样: 可以看到Proxy的accesslog中 Proxy返回cr/employee/info耗时5ms 排除oauth/token接口问题通过时间+clientIP 筛选方式,找到fast7层日志中 oauth/token的日志 比如13:20:15 调用了cr/employee/info接口 通过时间+clientIP+接口筛选,找到oauth/token的日志 从中可以得出两个结论: o auth/token接口耗时6ms o auth/tocken 和 cr/employee/info接口访问延迟在1s以内 如图,绿色部分是有日志证明没有问题的部分 检查DNS问题从上图可以看到,出现问题的部分只可能出现在sm-ps-server解析域名过程中 查看jk上DNS监控发现:idc-aroute.ke.com解析存在5s超时情况,但是发生超时时间和报错时间不一致 查看代码发现,jk的dns监控并不是调用接口解析域名耗时,而是定时任务去检查域名解析耗时,所以报错时DNS监控数据正常并不说明当时DNS解析没有超时 通过DNS监控可以得出结论: DNS解析超时5s的情况存在,并且会影响oauth client真实请求延迟5s,并导致接口超时 结论 优化oauthclient, 减少调用auth/token接口次数可以减少超时情况发生 解决在容器环境中DNS解析超时问题","link":"/2021/03/18/2021/2021-03-18-%E6%8E%A5%E5%8F%A3%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E6%95%B4%E7%90%86/"},{"title":"Eureka服务发现机制","text":"Eureka服务发现机制 注册: 服务提供者启动后发送注册请求到Eureka-Server，默认注册信息生效时长为30秒。 续约: 服务提供者定时发送心跳给Eureka-Service，默认30秒一次，以刷新注册信息过期时间。若服务提供方不能续约，eureka-server将会注销该微服务节点（默认三个心跳周期90s) 注销: 服务提供者停机时发送注销请求到Eureka-Server。 调用: 服务消费者定时从Eureka-Server拉取服务注册表，并刷新本地缓存，默认30秒一次。服务消费者的负载均衡器(如Ribbon)向Eureka-Client获取服务提供者信息后，即可向服务提供者发送HTTP请求。 Eureka缓存机制 读写缓存定时刷新信息到只读缓存。刷新间隔：eureka.responseCacheUpdateIntervalMs，默认为30秒。 是否启用只读缓存可配：eureka.shouldUseReadOnlyResponseCache，默认开启。 Client定时从Eureka-Server拉取注册表，刷新本地缓存。拉取频率：eureka.client.registry-fetch-interval-seconds，默认为30秒。 LoadBalancer定时同步Client里的服务列表。同步间隔：ribbon.ServerListRefreshInterval，默认为30秒。可优化为实时刷新 服务下线不主动通知，则依赖剔除任务清除过期数据的机制。相关参数：续约间隔：eureka.instance.lease-renewal-interval-in-seconds，默认为30秒；节点有效期：eureka.instance.lease-expiration-duration-in-seconds，默认为90秒；清理时间间隔：eureka.server.eviction-interval-timer-in-ms，默认为60秒。 Eureka缓存机制造成的问题在Client未同步到服务提供方下线信息前,流量仍会请求到下线节点上,导致Client报错,影响上游服务稳定性 多级缓存造成的同步延迟: eureka.responseCacheUpdateIntervalMs+eureka.client.registry-fetch-interval-seconds+ribbon.ServerListRefreshInterval 默认为90s 解决方案 Server端 关闭eureka.shouldUseReadOnlyResponseCache 或 缩短eureka.responseCacheUpdateIntervalMs Client端 缩短eureka.client.registry-fetch-interval-seconds ribbon配置 优化为实时从Client获取 延迟关闭服务,等待未同步的Client同步完成","link":"/2021/03/30/2021/2021-03-30-Eureka%E5%8F%91%E7%8E%B0%E6%9C%BA%E5%88%B6/"}],"tags":[{"name":"java","slug":"java","link":"/tags/java/"},{"name":"代码","slug":"代码","link":"/tags/%E4%BB%A3%E7%A0%81/"},{"name":"读书","slug":"读书","link":"/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"工作","slug":"工作","link":"/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"感悟","slug":"感悟","link":"/tags/%E6%84%9F%E6%82%9F/"},{"name":"团队","slug":"团队","link":"/tags/%E5%9B%A2%E9%98%9F/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"aop","slug":"aop","link":"/tags/aop/"},{"name":"搜索","slug":"搜索","link":"/tags/%E6%90%9C%E7%B4%A2/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"缓存","slug":"缓存","link":"/tags/%E7%BC%93%E5%AD%98/"},{"name":"消息","slug":"消息","link":"/tags/%E6%B6%88%E6%81%AF/"},{"name":"中间件","slug":"中间件","link":"/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"消息队列","link":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"IM系统","slug":"IM系统","link":"/tags/IM%E7%B3%BB%E7%BB%9F/"},{"name":"架构","slug":"架构","link":"/tags/%E6%9E%B6%E6%9E%84/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"categories":[{"name":"Java并发","slug":"Java并发","link":"/categories/Java%E5%B9%B6%E5%8F%91/"},{"name":"读书","slug":"读书","link":"/categories/%E8%AF%BB%E4%B9%A6/"},{"name":"工作","slug":"工作","link":"/categories/%E5%B7%A5%E4%BD%9C/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Java框架","slug":"Java框架","link":"/categories/Java%E6%A1%86%E6%9E%B6/"},{"name":"挑战","slug":"工作/挑战","link":"/categories/%E5%B7%A5%E4%BD%9C/%E6%8C%91%E6%88%98/"},{"name":"Java基础","slug":"Java基础","link":"/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"中间件","slug":"中间件","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"字符串","slug":"算法/字符串","link":"/categories/%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"总结","slug":"工作/总结","link":"/categories/%E5%B7%A5%E4%BD%9C/%E6%80%BB%E7%BB%93/"},{"name":"Mybatis","slug":"Java框架/Mybatis","link":"/categories/Java%E6%A1%86%E6%9E%B6/Mybatis/"},{"name":"Spring","slug":"Java框架/Spring","link":"/categories/Java%E6%A1%86%E6%9E%B6/Spring/"},{"name":"二叉树","slug":"算法/二叉树","link":"/categories/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"排序","slug":"算法/排序","link":"/categories/%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F/"},{"name":"缓存","slug":"中间件/缓存","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E7%BC%93%E5%AD%98/"},{"name":"搜索引擎","slug":"中间件/搜索引擎","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"},{"name":"消息队列","slug":"中间件/消息队列","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"mysql","slug":"中间件/mysql","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/mysql/"},{"name":"架构","slug":"架构","link":"/categories/%E6%9E%B6%E6%9E%84/"},{"name":"resilience4j","slug":"中间件/resilience4j","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/resilience4j/"},{"name":"DevKitPro","slug":"DevKitPro","link":"/categories/DevKitPro/"},{"name":"hash","slug":"算法/hash","link":"/categories/%E7%AE%97%E6%B3%95/hash/"},{"name":"nosql","slug":"中间件/nosql","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/nosql/"}]}